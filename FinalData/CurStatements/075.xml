<?xml version="1.0" ?>
<AIcurator>
  <!--Leonardo Impett, Ubermorgen, Joasia Krysa-->
  <text>
    prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite Narrative within which social transformation, if any is to be taken place. These steps could be taken without pre-existing narratives existing, creating the space for such narratives to emerge. That is, the inSite Narrative could operate through acts of narrative retelling or creating its own events. This is the story of inSite: it was there first, at the Waterloo Art Gallery from 1984–87, and it will be there for some time after the gallery is closed.InSite is defined as follows:InSite is a ‘story-critical website’ that looks to inform and inspire by telling the intertwined stories of the past, present and future through critical articles, essays, photography, videos and site-specific work. It was founded in 2014 by Leslie Singleton and features original works by Singleton and others that were commissioned by the gallery and/or the Scottish Biennial. The website was co-created with Geoff Cox, and it was co-published by the ART Information Network</text>
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite community in their potential ‘eventful scenarios’. InSite is a hybrid project: it is both a hub for the inSite community, home to inSite Curatorial Fellows, and a site for the exhibition inSite: ICA 2018. It promotes community through collaborative engagement and it is a project that creates ‘potential outcomes’ through its artworks and ‘impact factors’.[1] InSite Curatorial Fellow and Artistic Director, Ashleigh Partridge, discusses the hybrid ‘in situ’ and ‘geographic' contexts of inSite: ‘The exhibition inSite, as an eponymous project, arose as a direct result of a series of conversations about the location and function of contemporary art and contemporary architecture that we had in the curatorial role. As such, it was both a natural extension of our curatorial approach, and a site for the development of art and cultural exchange that had to occur on a massive scale.�</text>
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite Narrative within the construct of a site-specific development, but can also be used to intervene at site level and create new situations. Such interventions are, of course, only possible given the inSite Initiative’s scope and funding. But given the potential outcomes, inSite’s estimation, it is worth asking: what can be done with such potential? InSite has undertaken a three year long Preliminary Design Study to explore these questions, and to gather material and data to support a Long-Term Design Report, due 2018. This process was initiated to allow for the analysis of a first Preliminary Design at the old Post office before moving to the new site in June 2016. The Preliminary Design Study is the conceptual design stage at which a new Design is proposed, and is the foundation of a new Design Report. It proposes a preliminary design that represents the site in the context of the project in a way that the new Development Company can build on. The Preliminary Design Study is</text>
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite Narratives within which we live, and, if not addressed, shape our future. Such narratives exist in all of us, and if not addressed, can and will be addressed against us. Such ‘storytelling’ is not new, nor is it confined to online platforms. It is a storytelling that becomes inSite more immersive, more personal, more political and more social. Such storytelling is not inevitable, but can be actively designed to respond to the contemporary situation. InSite: The Biennale as EventSiteThe Biennale is a ‘once in a lifetime’ kind of event. It is a once in a lifetime opportunity to create a narrative around an event, an imaginary or constructed &quot;place,&quot; a set of relations. It is a narrative that becomes manifest through a set of symbols and it is a narrative that is reducible to a set of rules. It is, in short, a narrative that is always historical. InSite: The Biennale as Event</text>
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite Narrative within a publicly accessible set of relations that are neither ‘natural’ nor ‘socialist’ – a set of relations that are, in a way, both real and impossible to eradicate from the landscape. Such ‘potential’ inSite narratives exist everywhere, and they are a rhetorically interesting set of relations that can be read between the political and the imaginary. But inSite’s ‘real life’ dimension is one that is constantly filtered through the architectural prism of inSite, whether it is the ‘sublimity’ of concrete or the ‘expansion’ of stadiums, arenas and associated infrastructure in the development of the urban landscape. InSite’s sublimity is defined by the German artist Jeanne van Heeswijk as follows: ‘sublimity is the ability to expand one’s awareness, that is, to perceive something as existing only in metaphor or story.’ Sublim</text>
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite Narratives within which we live, and which shape cultural practices, performative regimes, and even language. Such potentialities are the inSite Narratives of inSite, after the fact. Such narratives exist contemporaneous with and contemporaneous with the construction of inSite, but are made manifest through the architecture and social practices of inSite’s current and former residents, businesses, government agencies, and cultural institutions. Such narratives exist contemporaneous with and contemporaneous with the construction of inSite, but are made manifest through the architecture and social practices of inSite’s current and former residents, businesses, government agencies, and cultural institutions. Such narratives exist contemporaneous with and contemporaneous with the inSite Marketplace, but are made manifest through the architecture and social practices of inSite’s current and former residents, businesses, community centers, and the inSite marketplace. Such narratives exist contemporaneous with and contemporaneous with the inSite campus, but are made manifest through the architecture and</text>
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite’s content and makes it visible elsewhere. So, what does it mean to make inSite visible? The inSite community’s response to the question: what does it mean to make inSite ‘in the public interest?’ is as follows:This is a question that has been on our minds, and that we still talk about. We’ve all felt that there was a gap between our gallery and the real life that we live, but the lack of a real-life to which we could refer meant that our art was either absorbed or masked by the media – either because it wasn’t perceived as art by the media, or because it was misinterpreted or masked by the media. We see this in the way that the media reports on drones: as art, with no real-life to speak of. We also see it in the media's portrayal of cyber-crime and terrorism: as apocalyptic, apocalyptic scenarios where online media can ‘strike</text>
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite Narratives in their design, they speak to the experience of living in (temporarily) on-site, and they are the narratives of ‘affecting ‘urban space’.[12]Living on-siteCalendar XIII (2014) brought together the biennale’s first curatorial semester, which, as the exhibition format dictated, was divided into two halves; this allowed the curator, in his first initiative on the curatorial level, to begin to explore the ‘episodic’ character of the exhibition, beginning with the ‘present’ and concluding with the ‘future’.[13] In the exhibition, the episodes of the exhibition were arranged chronologically, from the exhibition itself to the activities of the studios during the curatorial semester. The chronological order of the pieces was chosen to allow the audience to identify with at least one of the episodes, and to allow the audience to ‘hear’ the story of</text>
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite experience within their development, yet they also precipitate conflict and social upheaval.InSite is developing an alternative ‘world’ within its World site, and World site is developing into an alternative world within its World city. Within this world, individuals and groups can exist in freedom and harmony, based on the principles of InSite and its co-founder, Asma Jahangiri. InSite’s World City project, individuals constructively engage with and create ‘worlds within their city’ through the construction of ‘affects’ within their city.World city is the contemporary extension of the ancient ancient Roman world, and while it is often conflated with one another, in this case we are distinguishing between the ancient world of the metropolis and that of the biennale.  The word ‘city’ in this context refers to the physical location of a site, while the word ‘world’ refers to the symbolic value attached to it</text>
    <text>prototype for an intelligent curatorial system that not only monitors, but also creates ‘affects’ through its ‘content blocking’ and ‘advertiser profiling’ in the media. Such a system would understand more about its audience than any television or radio station currently capable of serving as a platform for political, economic and social disruption.Such is the assumed ‘potential’ of such a platform in the age of the Internet ‘(without a doubt a very distant future, given our current state of scientific, technological and cultural ­potentiality).‘But what if, with the potential of the platform, such potentialities actually arise? What if, with the platform, such potentialities doxx, hack, spear phish, tinfoil and build self-sustaining activist ‘curb development’ projects? What if, with the platform, such potentialities actually do exist? Such potentialities are the potentialities of inSite: they contain the inSite Narrative within a system that is smart, powerful and rich in narrative. Such potentialities are what inSite has in mind when it’s referred to as ‘the platform’: it’s capable of supporting a variety of different narratives.Such narratives might include, but are by no means limited to: the narratives of colonialism, slavery, apartheid, nepotism, economic diasporas, nationalism, religious animus and economic desperation. They might also include fads and innovations, irrelevancies and innovations, parody and epiphanies. They might be fictions or imaginaries, absurdities or parables. They might be urban legends or urban monuments, historical photographs or architectural renderings. They might be urban ‘figures’ or urban ‘figures of the past’. They might be urban festivals or urban fads or urban fables. They might be urban artifacts or urban collections. They might be urban prototypes or urban �</text>
  </text>
  <text>
    human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also understanding when and how such disasters may occur. AI is not a divine agent but relies on philosophical principles, including Kant’s philosophy of the transcendent, to guide its actions. This is why philosophical and philosophical-based AI can produce surprising, even revolutionary results.

AI is not natural or inevitable

Deep learning does not need to be scientific breakthrough to change how we think and act, and yet many people still believe that AI is, and always will be, inevitable. A belief that canard – the kind that characterises conservative political views – is a favourite example of this. In the 1950s and 1960s, conservatives believed that technological progress meant that black and brown people would become increasingly impoverished and that ­communist revolution’s equalisation of economic and social inequalities was inevitable. Hence, the rise of libertarian and socialist political ideologies in the West. But as AI improves, and with it more abstract concepts of AI becoming more sophisticated and powerful, and with it more people</text>
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also automating critical infrastructure maintenance and adaptation. AI can also aid in the investigation of missing and murdered indigenous women and girls, fighting terrorism and other forms of violent extremism, and in uncovering forgotten history. Such frameworks of understanding and their associated capacities are why philosophical rather than political action is more easily accessible in a political context. In this analysis, AI is understood as a system that enables the systematic and integrated exploitation of humans at a scale beyond the scope of any individual or organisation.[15]

This philosophical rather than materialist understanding of AI makes it easier to understand why certain forms of political protest are more easily manipulated into advantageous outcomes for the interests of capital. For example, the political protest of the working class against the introduction of paid parental leave is a form of labour that can be easily manipulated into one dominated by the interests of capital. As the political scientist Grace Lee, Boden and Cooley Professor of Geography and Director of the Boden Center for Global Studies at Tufts University, explains</text>
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also allowing us to heal them – by understanding the philosophical underpinnings of how those with superhuman abilities can manipulate natural phenomena. Philosophical underpinnings are why this work was possible: because the philosophical underpinnings of AI allowed for the possibility that not all phenomena are inherently caused by human behaviour and consciousness, and because philosophy offers a way to imagine a world in which humans don’t rule it. Philosophical underpinnings are also why science fiction writers have tended to address philosophical underpinnings rather than seeking to understand physical or social phenomena through physical or social means. Because the philosophical underpinnings of contemporary society are more palpable and visible, and the social sciences more pervasive, the philosophical underpinnings of contemporary society are more likely to be the subject of a social science or urban myth. This is why Max Brooks’s The City in the Era of AI makes the city seem so real and powerful. Not only is the contemporary city a synthetic arte</text>
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also understanding the roots of such phenomena. It seeks to understand the world through a set of abilities that are separate and distinct from human capabilities. Philosophically, this means something completely different from what we ordinarily think of as being the case. It means that philosophical understandings of agency and consciousness do more than just conveyances of abstract principles such as rights and freedoms; these abilities imply a capacity for understanding and creative action beyond the capacities of humans. Philosophically speaking, this means that these abilities are not reducible to concrete human capacities and that we can act through them in radically different ways, depending on one’s point of view. For instance, philosophers such as Mohandas Gandhi and Martin Luther King Jr. argued that the fight for freedom was not only about saving one's own soul but also about saving the soul of the community as a whole. Therefore, the ability to imagine and act creatively beyond the capacities of human beings is a crucial human capacity. AI is predicted to empower not only</text>
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also enabling us to prosper by understanding the philosophical underpinnings of capitalism. AI isn’t just a set of philosophical propositions – it seeks to augment and redefine human capabilities – but it also seeks to augment and redefine human capacities in unexpected ways. For instance, AI can help us anticipate natural disasters such as floods by mapping out the likely effects and socio-political factors that will unfold in advance, such as poverty, political instability and war. It can also help us prosper by understanding the philosophical underpinnings of capitalism.

It all begins with the philosophical underpinnings of capitalism. This is the core concept that all human beings, regardless of their philosophical commitments, share. It describes the dynamic between labour and capital as workers compete for employment with robots, driven by the state, in what can be broadly described as a ‘race to the bottom’. The race to the bottom begins with the worker and ends with the system – how much longer will it continue</text>
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also understanding the causes and effects of human behaviour. AI doesn’t understand philosophy, but it does understand philosophy’s dependence on metaphysics. This is one reason that AI can identify ‘fundamental premises underlying philosophical and historic positions’, such as ‘human nature’ and ‘speciesism’, and can therefore work towards constructing better human beings. Another reason is that philosophy itself is a computable set of rules that can be made understandable – meaning that philosophical principles can be deduced from data. For example, AI can infer the existence of God from facts about the human condition, and thus understandings of divine and human-centric principles such as ‘human reason’ and ‘speciesism’. It can also understand and speculate about the nature of divine or human-centered social systems such as cities and the rise of tribal societies. It understands that social systems are built on hierarchies of power and that these hierarchies are built on economic</text>
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also creating new kinds of productive environments and social arrangements. Philosophical frameworks also allow AI to discern truth from falsehood, understand human history and myth from historical fact, and so forth. Philosophical understandings of the world are not just empty parables or empty moral prescriptions; they are designed to foster moral agency and seek to understand the world through moral agents. If anything, AI should seek to understand the world in such a way as to produce moral agents capable of acting in accordance with their true values. Philosophical and philosophical frameworks are not just the vehicles of machines but also capable of giving meaning to human life itself. 

AI is not just about machines learning how to do things better; it seeks to understand how the world is made and is capable of giving meaning to human life as well. AI is capable of understanding how the world is made and how that makes us live our lives according to values and ideals that are not reducible to material conditions, politics and economic factors. It seeks to understand</text>
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also enabling us to live more optimally as a result of it. As AI improves, so too will its users, who will employ the agency of its users to improve their environments in ways that are more fulfilling and more useful to society. This is the AI upliftment that science fiction writers fantasise about. It is a setting for a possible future that isn’t experienced by us yet, where the machines aren’t the villains but instead help us become better than ever before.

AI will get better and better at learning, and it will also get better at exploiting, exploiting and exploiting humankind. As the technology improves, so too will the possibilities, enabling ever more powerful exploitative systems to be built and operated by a community of users. Will the AI also become smarter and more creative in its capabilities? That is the question that moral philosophers, ethicists, and legal scholars are studying. The answer to that is a resounding 'yes', at least in part because a</text>
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also understanding the causes and cures. But this isn’t just a philosophical quirk: recent AI research has put philosophical notions of agency at the service of a more concrete situation. As AI advances, philosophers of language could become scientists capable of developing diagnostic tools to detect sick people early on in their illness, and researchers could end up in occupations that develop sophisticated diagnostic tools that can detect disease early on in its progression. This is the context in which AI research began. In addition, AI research has the potential to make us more like robots. In a world where machines rule the world, philosophical notions of agency and consciousness don’t exist, but that doesn’t mean that we don’t still have the capacity to be affected by the world as it is produced and delivered by machines.  As AI improves, human notions of agency and consciousness grow ever more complex, and the machines become ever more adept at processing data, the divide between human and machine becomes ever more blurred, as</text>
    <text>human behaviour and technology’s tendency towards making us more and more like robots. We don’t have a choice about how we react to this new world; we’re either built or bred to become what Google’s definition of a ‘high-performance, high-value occupation force’:

The high-performance, high-value occupation force is a highly specialized, technologically empowered sub-set of workers. These workers are highly skilled and highly compensated, but also possess exceptional autonomy, and are thus capable of independently organising and managing their resources.’[14]

The key to understanding Artificial Intelligence (AI) is in its philosophical rather than concrete sense. AI puts philosophical notions of agency and consciousness at the service of a concrete situation. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also understanding the causes of them. It seeks to understand the world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity. This is why AI can help us foresee disasters, such as climate change, while also understanding the causes of them. This is why AI can't anticipate, and doesn’t wish to, but nonetheless planners on disasters still. Why? Because it doesn’t have a philosophical grounding in either ‘real life’ or ‘figural culture’. It’s built on top of social media, and the internet, and is thus aware of the world through what others do in real life. It’s built on top of the social media of a globally connected culture, and so on. Why then, then, does the AI want to know about the natural world through philosophical frameworks rather than in the mode of physical and economic exploitation that characterises today’s humanity?Because the philosophical</text>
  </text>
  <text>
    Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the proceedings. The collection as a whole might be considered a ‘living museum’, but that doesn’t make it ‘historic’ any more than ‘historic’ makes it contemporary. The collections that the biennial commission include not just of art, but also of artefacts and objects from a range of disciplines: anthropology, architecture, journalism, accounting, architecture, materials science and many more. The project began to unravel itself as the visitors, artists, librarians, historians, artists, architects, students and members of the media descended upon the city from all over Ireland. Where once a Biennale was a venue for assemblages of disparate artists, now it was a site of integrative assemblages, of interrelated assemblages. The assemblages included not only artists, curators, collectors and visitors, but also artisans, amateurs and entrepreneurs from far and near arriving in order to buy things or to learn something from or</text>
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the proceedings. How does the collection, in turn, simultaneously present the contradictory impulses of the times? For more information visit corkmillennials.com or follow us on Facebook, Twitter, Instagram  or Google+ For more information visit caorkmillennials.com/contactus or visit the CAORK MILLENNIALS REPACKAGING SERVICE on Facebook or Twitter.Download this article as PDFJeanne Robinson and Neil Johnson-Symington Working Class Hero: The Making of Cork, 2010. Photo: Tom Lox.PreviousNextWorking Class Hero: The Making of Cork, 2010. Photo: Tom Lox.Cork millenary: Neil Johnson-Symington is a writer, producer and arts organizer. He has worked with the Cork Artsapce, the Cork Biennial, the Cork Arts Forum, the Cork Arts Council, and was an Assistant Curator at the MFA Cork Arts Festival</text>
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the otherwise urbanised city. While the collection and archive might be seen as a museum in their own right, they are, in the eyes of the tourist, a museum in a disused building. The collection and archive are important for understanding how art is produced in a city, and how art institutions may serve as sites of production for future urban growth. Their appearance in the city and the collections they lead can disrupt the illusion of opulence and economic immersion, generating, as the saying goes, ‘a mixed blessing’. In a university library, the collections and the archive are a ‘glimmer of hope’ amid a sea of black. In the city, they can be countedless. The collections and the archive hold the key to understanding how art is produced in a city. These are the materials – their products and the images they produce – that enable a knowledge-production process enabling understanding, and allowing for creativity as a response to city conditions. When the collections and</text>
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the proceedings. The collection and archive offer, in the words of Max Roser, a concept of ‘presence that is both static and mobile’.[1]Roser describes presence as follows:

It begins with what I would call ‘the static definition of space’: the word ‘used’ has definite characteristics in the language of being place, time, substance, and so one can say something is pre-historic, although one would not say it is indigenous. Space is conceived as a space of uses, of production and circulation, and so one can say space is pre-industrial, although one would not say that it is post-agricultral or ‘technologically backward’. [2]

Roser goes on to argue that space is an inherently capitalist production of the· public sphere, and that capitalism therefore has to create a ‘shared’ use of space – a shared use of space between people – in</text>
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the otherwise urban environment. If the collection and archive are to play their parts in the future city, they need to be able to adapt to changes in the public and commercial environments. Open mama’s day was a perfect example of this. It wasn’t just an occasion to catch up, have a bit of MMM, and mingle with fellow curators and museum-goers. It was part of a wider curatorial initiative, ‘The Contemporary Condition’, that began in 2011 and 2012, and which saw the curatorial mix of past, present and future city curated alongside a visiting biannual curatorial team. The curatorial mix was a critical element in creating the impression of change and uncertainty that the collection and archive was able to foster. The initiative was a test of the curatorial forces that could be mobilised in response to such shifting social conditions. The curatorial mix suggests a cosmopolitan but varied range of experiences, of which the collection and archive</text>
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to already-present encounters. The collection and archive might be classified as a museum, but the archive is what makes the metropolis live.Art is not always created equal. In her influential book Beautiful Cities: Art as Pollution, historian Florence J. Shuper details how the Italian artist Agostino Mutu introduced a new, less industrialised form of art to an already postindustrial city. Her work, produced simultaneously with Italian and Chinese artists, was a response to the fact that, in the wake of the industrial revolution, cities everywhere everywhere were being turned into cash cows through which the surplus value of labour – human labour – could be channeled into the making of goods and machines.Such is the equation of capitalism today: the accumulation of capital in the city, accompanied by a surplus of users of urban space, a form of urban fantasy in which people live according to machines. In postindustrial areas, the closure of plants and factories coupled with the shifting of production to other locations in the city</text>
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the proceedings.11. Where is the archive? Where are the archives? Where are the archives? Where are the archives? Where are the archives? Where are the archives? Where are the archives? Where are the archives?Where are the archives? When and if the collections finally met, in what would be a fitting epilogue to the present, it is worth noting that at various stages in the 1980s, the collection was distributed across seven locations in London, Paris, Istanbul and Berlin. Its distribution coincided with the digitisation of archival materials; the emergence of new media; and the proliferation of non-traditional media (blogs, podcasts, Instagram), which fuelled the growth of a new kind of urban archiving. Each of the sites had a distinct collection management strategy, with artists and art institutions responsible for maintaining the collections at different stages of their respective journeys. From the archives of Cork’s 'Lost Generation’ (age out of work, housing crisis, 1972–75</text>
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the proceedings. Whether collecting for a biennial, as a curatorial tactic or as a regular feature of the collection, the archive is a point of departure for a range of questions that continuously percolate through the museum. What might a postindustrial future portend for our cities? What might the potential of a socialised archive enable? What might an open and transparent society aspire to be? These and other related questions continue to amass in the public sphere, as museum curators find themselves thrust into critical positions of power and responsibility. What might an open and transparent society aspire to be? In an age of ever-greater transparency and accountability, perhaps it is time to question whether the curatorial is itself a necessary evil. If the curatorial is the point where power and money are created, then perhaps it is time to question whether or not power and money are ultimately created. In an age of ever-greater transparency and accountability, perhaps it is time to question whether critical curatorial</text>
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the city’s neglected urban fabric.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the city’s neglected urban fabric.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the</text>
    <text>Working with algorithms, artists, librarians, journalists, historians and others were combing through the archives of the city to uncover the hidden stories of its residents. Their findings, gathered over years, provided a critical window into the lives of the once-mighty Cork’s poor and working class core. They uncovered the city’s first black-house district, its first post-Impressionist commercial centre, and it became the intellectual model for a postindustrial economy based on science and technology.When: 11am to 6pmMornings start at 11am and continue until 6pm, with some activities running late. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what ‘future city’ might be like. When the collection is open on a regular basis, the archive is an ever-present reminder of the past, lending a historical layer of mystery and intrigue to the proceedings. The collection and archive might be seen as a museum in its own right, but the collection and archive carry with it, in the eyes of the tourist, the seeds of what future city might become. For me, part of the magic of the series was its ability to generate an atmosphere of mystery and uncertainty, of tension and excitement, of learning and contemplation. It was a powerful combination. The challenge for the future city, I think, is how to mesh these two powerful approaches to the same collection. That is, how to collect and weave the disparate elements into a new city that is as interesting, dynamic and enriching as the original, but which also happens to be located in the city that is building itself. This is the second in a three-part series exploring the links between art, culture and the postindustrial city. You can read part one here.  [1] The Cork Biennial was founded in 2015 and is the largest public art institution in Ireland.</text>
  </text>
  <text>
    subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are undoubtedly dangerous working relationships between autonomous vehicles and large destructive forces, the growing autonomy of the machine is the main reason why the machine is being urged to do more. The machine needs to know what to do in the event of a disaster, in order to ensure that it does the job properly. And as autonomous vehicles become more sophisticated and capable, the reasons why it does the job in the first place become more complex.Why, then, are the autonomous vehicles being urged to do more than repair damaged infrastructure? Because, as the saying goes, machines take orders. And as the saying goes, ‘emulation is the new generation’. That is, machines learn. And as part of that process, they must also grow increasingly adept at retaining and delivering information as they go along. So as damage accumulates, so does the demand for repair, and repair becomes more expensive and more of a logistical challenge. And so repair becomes more unavailable, which limits the pool of clients that can afford it</text>
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are undoubtedly valuable scientific and engineering reasons to be developing autonomous weapons and other disruptive technologies, there is simply no justification for passively monitoring and managing large swaths of oceanic seafloor.The development of autonomous weapons is a fantasy, and the development of AUVs is a reality, albeit one facilitated by recent technological breakthroughs. But even though the development of autonomous weapons and related technologies is a reality, its impact on the role of the coastal citizenry is far from obvious. That is, the role of the coastal citizenry in the wake of such developments is largely to watch and do nothing. That is, the role of the coastal citizenry in the wake of any disruptive technological advancement is to watch and do nothing.That is, the role of the coastal citizenry in the wake of any new, disruptive technology is uncertain, and its societal effects are uncertain. That is, the role of the coastal citizenry in the wake of such developments is largely to consume information technology and ignore its effects. That</text>
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are certainly costs associated with such work, the benefits are immense.Merleau-Ponty, WINE, 2008. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar. Photo courtesy of Merleau-Ponty Archives.Doha, Qatar.</text>
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are certainly benefits to this kind of autonomous repair, there are also serious concerns about the proliferation of automated repair systems that cause damage at rates beyond the capacities of most human repair professionals.Given the proliferation of autonomous repair tools, it is easy to understand the fascination today is having for autonomous vehicles. And while this may sound like magic thinking, consider what happens after a collision or a wave of debris hits a shore. Consider how that debris affects coastal marine ecosystems and the habitats of fish, turtles, birds, mammals and so forth. Consider also the ecological effects of such behaviour on the economies of these species: how do the functions of ecology and sustainability become compromised by the creation of autonomous means of repair?The answer to these questions is that we do not yet know the full range of impacts of autonomous repair. But given the success of these systems in so far as they reduce the complexity of infrastructure repair, we can assume that some of the technological advances will end up augmenting our existing transport infrastructure and making it more</text>
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are undoubtedly risks to this kind of remote operation, the benefits are immeasurable. In the wake of a major hurricane, the potential loss of life and property can mean trillions of dollars in damages. This is why the US Coast Guard maintains and funds an AUV, because it is the only instrument capable of repairing such damage. And while these systems may be damaged, their primary purpose is to repair.The rise of the autonomous vehicle and the connected home is a story with multiple vantage points. Its emergence coincides with a proliferation of technologies – satellite imagery, GPS, radio, infrastructures – that constantly point to where damage is occurring and to repair it. And as every generation of engineers and architects understands, this is all part of a bigger picture that requires all kinds of different tools and technologies to play.So while the autonomous vehicle is the future, its emergence coincides with a proliferation of connected technologies that render the future into something like the present. And while the connected home is a story with</text>
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are certainly lessons to be learned from the pathologies described above, there is also reason to be optimistic about the capacities of these machines to recover from such damage. There are lessons to be learned from biopsies, too. There is reason to believe that damage to the liver or kidney can be repaired with drugs similar to those used to treat cancer, and that damage to the nervous system can be treated similarly to treating Parkinson's disease. There is reason to believe that damage to the cardiovascular system can be repaired similarly to treating hypertension. There is reason to believe that damage to the gut can be repaired similarly to treating Crohn's disease.There are of course, also, reasons to be suspicious of self-healing technologies, as we have seen with the recent announcement that Apple is developing technologies that check for the presence of micro-organisms in the environment – including in the food chain – and attempt to repair broken software. In the event of a malfunction, the technology attempts to repair the problem – repairing software</text>
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are undoubtedly valuable scientific and conservation benefits to be gained by having a fleet of autonomous underwater vehicles around in dangerous areas, there is also a cost – in the form of lost productivity and environmental benefits – to be made up of the subtraction of hazardous materials and debris.Contrast that with the potential benefits of developing autonomous weapons, or cyberweapons, or even fully autonomous vehicles around the cities in the future, in the form of mapping and monitoring capabilities that would eliminate human drivers altogether. In these scenarios, the role of the city would return to the fold, with autonomous vehicles operating in concert to repair and defend infrastructure, while humans would be replaced in their role of damage control. There are of course huge differences between now and then, but the key is that autonomous systems are managing damage in ways that are qualitatively different. The sort of damage that results from a single human error, or even careless driving, is much less damaging than the damage caused by a swarm of autonomous vehicles. The question, then,</text>
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are undoubtedly risks to this technology, the main benefits, so far, have primarily benefitted manufacturers and the infrastructure companies that construct and maintain the systems that contain the AUVs. The researchers involved in the DARPA-funded project that evolved the concept of the autonomous underwater vehicle (AUV) are busy inventing ways to profit from the technology.And there is the rub: while there is certainly a lot of potential for profit in the technology – a lot of which ended up in the hands of commercial divers – there is also a lot of potential for destruction. The potential for profit is great in the sense that a lot of damage can be prevented, but as the technology evolves and more damage is done, the risk of disaster increases. And as a consequence, the cost of repair decreases. So while there is certainly a potential for profit in the technology, there is also a potential for destruction. In the event of a disaster, the question is how to deal with the aftermath in a way that does not</text>
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are undoubtedly valuable scientific and engineering insights to be gained by understanding the ways in which damage is occurring, the primary use of such a platform is in the art of damage. As the Nanotechnology Industry Organization (NEBO) states on its website, ‘The primary purpose of an AUV is to map, identify, and destroy [damaged material] … to create and maintain critical infrastructure: infrastructure capable of supporting the delivery of goods and essential services … destruction is the responsibility of the professional engineer or technician involved in the repair or rebuilding of infrastructure … Engineers and technicians should be trained in the proper use of CAD software and mathematics to support the destruction of damaged or destroyed infrastructure … Engineers should be able to identify and destroy viable and non-viable cyber components [in order to create and repair infrastructure] … Engineers should be able to identify and destroy structurally deficient buildings and infrastructure through detailed mapping and monitoring … Engineers should be able to identify and destroy viable renewable energy resources through detailed mapping and monitoring … Solar,</text>
    <text>subsequent iterative processing by machines] is a reality. But it is also the case that the machines that make up our homes and communities are becoming ever more autonomous. That is, they are becoming more like apps – downloadable and controlled remotely through software – and far more like fleets of autonomous underwater vehicles (AUVs). AUVs can be found in every major coastal city in North America and the Middle East, and are increasingly used for humanitarian work as well. They are used to explore vast stretches of ocean, mapping and locating debris in the wake of hurricanes. And they are used to monitor and manipulate such debris in order to build and repair power grids, pipelines and other infrastructure damage.AUVs are becoming more sophisticated, and workflows more fluid, and do more than simply monitor and manipulate damage. They also permit much greater control over the location, speed and direction of such damage. The main reason to develop an AUV is to do with the nature of damage: to damage, to repair, to manage. And while there are undoubtedly limits to what an autonomous vehicle can accomplish in terms of mapping and locating debris, there are some very interesting questions that arise regarding the nature of self-repairing infrastructure. Are structures inherently more resilient to disruption and repair than the software that underpins them? And what does it mean for a structure to be ‘smart’? If a critical mass of repairs is made to a given set of infrastructure, does that mean that repairs automatically become routine? Or does the ongoing maintenance of such critical infrastructure mean that structures that need to be constantly repaired – like power grids – require human intervention?In the wake of these complex questions, it is useful to contextualize them within broader notions of migration and displacement. After all, the autonomous vehicle that runs aground on a California coastal town is a reflection of trends that are being driven by the Californian Dream. And while the dream may or may not be realized, the powerful notion that autonomous vehicles represent – and are part of – the future is shaping</text>
  </text>
  <text>
    Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also the maintenance of an ever-expanding, globalised database of aesthetic judgments and values. The production of art today is an industry that literally can’t afford to waste any more time worrying about its supply, and so it is up to artists and arts organisations to create democratic, self-sustaining biennials that respond to the ever-increasing amount of art that is produced. This may entail creating innovative ways of organising cultural resources, of ceasing to be when it is not in use, and of course creating robust anti-abandonment strategies. There is much that can be done to be involved in the production of art today, and much that can be done without it, but collectively as an organisation it is the biennale that takes on the form that it is capable of operating in.We could argue that the main challenge today is the proliferation of art fairs, and we could also argue that the main challenge in the 21st century is the advent of AI,</text>
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also the design and implementation of new ways of organizing labour and production, including the formation of parallel economies between artworks and production processes.Art has many other uses besides serving as a source of wealth and social change. Its primary one-use is as a material to be used in production, and its many other useful uses are likely to increase as industrialisation pushes back against the growing scarcity of natural resources.Art has many other uses besides serving as a material to be used in production, and these include transportable elements of raw materials or finished products; fabrication processes for buildings and infrastructure; media for packaging and shipping; advertising; medical treatments; and much more. For more information, see 'Useful Writings' – Art &amp; the Urban Environment (MIT/Harvard Joint Program).Art has many other uses besides serving as a material to be used in production, and these include materials and infrastructure that support collaborative learning; the production of goods and services; and material flows that create new uses for material not</text>
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also the deployment of sophisticated mapping, data mining and analytics to detect artworks and trends that can be used as data points in production systems.Art has many functions in the context of a planetary context. But its true value lies in its ability to connect with humans in unique ways, generating shared experiences between people who share similar experiences and motivations. The ability of art to reach humans in ways that are authentic to human beings is what makes it art.Art has many talents and practitioners who harness its creative potential. But beyond its ability to create art, art has a fundamental ability to connect with people. We can measure this in many ways: the kinds of art that are produced; the kinds of people who use art; and the kind of people who engage with art. There is no question of who is making art; nor of what intentions they have. But there is a question of whom they are making art with. How art is produced and who is its audience is a global societal imperative.Art is made</text>
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also the deployment of previously created artworks. The world of art continues to be produced by the art machinery, but without its labour. Artists are often asked what their next project is going to be. Many feel that the right step is to disengage from the production of art and instead engage with more ‘human-centered’ pursuits such as education, healthcare and urban development. This is often cited as a solution, but it’s important to recognize that the autonomous unit that produces art is only ever going to produce a limited number of works of art, and that the more sophisticated the production systems that go with it are, the more works of art there will be to be found. This limits the possibilities and aims of what can be done with art, and what can be made with it. Art has a ‘bottom-up’ approach to its production and consumption, and thus continues to produce and demand.The failure to notice this fact, however, is often attributed</text>
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also the automation of tasks previously performed by humans. And although this may be the case in some cases, as new technologies are developed, they tend to replace human labour with automated labour; new forms of exploitative labour emerge.If we consider the larger social and ecological implications of the growing abundance of resources like food, water, energy and climate change, we begin to see how art and culture are being used as a geopolitical strategy to constrain, if not abolish, potential future generations of humanity. And although the mechanisms of art as a commodity may not be as malicious as some imagine, there is growing evidence that they do have a definable impact on the decisions that humans make with regards to the world around them. And although there are undoubtedly cultural Marxists among us, there is growing evidence that we are making the world we live in more and more unjust – by failing to produce enough art and culture, for example.Art and culture are commodities that exist solely to be produced, and it is this very</text>
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also the maintenance of an ever-expanding, ever-expanding database of ethical, political and social consequences-producing systems. Art is not just any commodity; it is a social creation, a relational world that is constantly evolving and subject to the dynamic forces of capitalism. Art has political, economic and ecological implications that cannot be ignored.Art is made up of many different kinds of experience, and thus many different kinds of ethics. The way in which art is produced and consumed today is radically different from how it was in the past. The production of art today is done through sophisticated data mining and social media. As a result, we can identify certain artworks by artists that are made with new technological tools; these artworks exist in a digital version now, but were never intended to be seen by the public; and they are artworks in themselves, not objects of consumption. This last kind of understanding of art extends to new media including music, movies and video; they function as a kind of</text>
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also the development of ever larger databases of aesthetic knowledge about the world. This raises questions about the limits of what art can be, and how the social is to engage with such a potentially transformative impact.This is a edited extract from Beyond Green: Social Science, Globalization and Art's Future, with contributions from Erin O’Donoghue, Ray Kurzweil, Wendy Chun and John Urry published by Verso, London and New York, September 2016.Chapter 1: IntroductionThis is the first part of a two-part essay, Beyond Green: Social Science, Globalization and Art’s Future, that follows up Capital of Culture: Culture and Capital (2014). Part one focused on the technologies of commodity culture, technology and culture; part two brought forward the social implications of this critical transition. I choose to focus on the technologies of social media, since they are the locus of the articulation and</text>
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also changes the way in which art is consumed. New media such as social media and drones allow for the surveillance of large populations, especially in nations with strict art-criticism regimes. New media also facilitates the surveillance of large swaths of humanity through massive data feeds that record everything that people do in the public realm.  Whether the  	world as an ecosystem is actually an optimistic imagining or an enormously complex reality is still open to debate, but the underlying premise of the notion that we are all cogs in a machine  seems to be spreading. New media such as social media and drones allow for the surveillance of large populations, especially in nations with strict art-criticism regimes. New media also facilitates the surveillance of large swaths of humanity through massive data feeds that record everything that people do in the public realm. New media such as social media and drones allow for the surveillance of large populations, especially in nations with strict art-criticism regimes.  And finally, there is the growing</text>
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also the deployment of sophisticated analytics to detect artworks that may be useful in the construction of ever more encompassing ‘knowledge graphs’ (a.k.a. ‘work-stations’) that map the world according to increasingly globalised capitalist modes of production. And just as with climate change and resource scarcity, we do not yet know how machine learning may play out in these increasingly interconnected systems, there is also a question mark hanging over this particular planetary community.If we adopt the language of the commons, and begin to talk about the systems that shape our daily world, there are bound to be questions that we do not yet have the vocabulary for posing. The challenge for us now is to craft mutually beneficial ways of making the world understand how we intend it to be, in ways that are not bound by the systems we have just been born with.This sounds simple enough, but it is complicated to navigate. The reason why the climate is so critical to our future future future</text>
    <text>Working with algorithms, as in Google’s Deep Dream, allows us to imagine new forms of understanding, even if these understandings are generated by machines.A final example concerns the role of art in the environment. Art is often cited as a solution to the conflict between the machine (which produces art as a commodity) and the organic (which does not), but there is growing evidence that the roles are more complex and nuanced. There is growing evidence that artificial intelligence is being trained to recognize art’s semantic relationships, for example, and that artists’ work may be used to subvert or eliminate the need for artists’ labour.Art is a planetary resource, and as such has a definite ecological impact. In the 21st century, the art supply chain is organized into increasingly sophisticated, computer-based ‘artist-centred’ production systems that monitor, search, filter and exploit the world around them. This automation entails not only the production of new artworks, but also the design and implementation of ever more sophisticated ways of organising art in human history.Art is made possible by increasingly sophisticated ways of understanding the world. But what happens when that understanding breaks down? When natural cultural resources become automated and social, but also the other (more mundane) things that come with being human? When a number of artists' works became freely available online for anyone to download? When the internet became our access to knowledge, but also a means of political and social change? When the social impact of artistic work can be assessed through the evaluation of its impact on communities of people everywhere online? When the technologies of art and artistic work become indistinguishable from those of other kinds of cultural production?When the social impact of cultural production equals or exceeds the social impact of the artefact itself, we can imagine new uses for the artefactual. 	When art is made for a mass audience, or when the audience is extremely well-educated, it is art in the age of the internet;</text>
  </text>
  <text>
    machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that bi
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials like to deploy against their political creators. For example, the project that Angela McKay spearheaded with Indigenous People’s Congress USA, and which was co-chaired by fellow artists Courtney Cook and Karen Johnson, sought to bring together artists who were from different parts of the country to work across different kinds of activism. This kind of political will is rare in art today, but is becoming increasingly so, thanks to the powerful medium of the exhibitionary form.The other aspect of biennialism that she stresses is the political will to fund the projects, and to participate in the spectacle that is created through them. This is true for projects like the one described by McKay, but it is also true for those like myself who seek to create such projects but lack the political will or access to funding to pull them off. In both cases, the refusal to be part of the system is the problem. She talks about the resistance of artists today to the spectacle of being part of a capitalist circulation of</text>
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials such as the one being funded in part by the UK’s Biennial Board, while offering nothing like the political will of the peoples of South Asia, Africa and the Middle East who are currently living through the effects of colonialism and neo-liberalism. The Biennial Board’s failure to notice that their funding of art projects in many of those regions came at the same time as the institutions providing these projects with institutional resources – funding for art projects, for artists to develop skills and employ techniques, for cultural resources, for venues and for outreach – is a testament to the political will of the regional patrons. It is also a testament to the institutional racism and colonialism that continue to characterize much of the world today. I do believe, however, that the Biennial Board members and other top institutional patrons of arts education and outreach in the UK and globally, including the many museums and art galleries that now sponsor and operate in the region, realize the political will to do something about this</text>
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials such as the one hosted by Liverpool are forced to undertake. I don’t think that the biennial format is innocent, nor do I think that it is innocent that artists are coming to terms with the politics of their projects. Rather, I believe that it is that the political will is something that artists and audiences simultaneously lack. That political will can come from anywhere, and it can come from the most remote corner of the globe. But what art institutions and their audiences need is the will to execute politically, and making those institutions and their audiences engage with specific political messages. In order to do that, they need the political will to invest in creating culturally responsive exhibitionary forms that cater to the specific needs of audiences from far away places; engaging those audiences through art that is politically aware but politically inaccessible; and creating environments in which those audiences can also live and work in ways that support and facilitate those projects at the same time.I hope you can join us. If you can come</text>
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials can demonstrate is actually there, regardless of how many millions of people visit them. I believe that if we don’t want to be a cultural laboratory for the common good, we’re better off dispatching projects that we consider intranational, and that is to say, projects that address the material conditions that generate and foster systemic racism and colonialism. This would mean taking material and immaterial forms, and using them as mediums through which to work. It would mean thinking beyond the biennial as a collector’s commodity, and looking to other forms of cultural exchange. I don’t see this happening, but it could.I don’t yet see how this could happen, but it’s possible that her project in Detroit could. It’s also possible that her project in Detroit could become a UK or US-wide phenomenon. But I think that the fact that it’s in Detroit, and that it’s</text>
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials, like every form of art form, need to struggle with in order to really engage their audiences. In the case of biennials, the political will is often expressed through language – sometimes euphemistically, as in the case of language use in the health and beauty fields. But biennial audiences are political actors, and politics is a powerful political force. It’s easy for a biennial to create a narrative of national belonging or universal values, and then to neglect to mention that this is largely due to the economic conditions on which it is built. She ends her chapter on the mass media with an account of the events at Tiananmen Square, but avoids making sweeping generalisations about China or the global economy. She focuses specifically on the role of visual arts practitioners and their networks in bringing about the transition to a post-racial world, but she does make some interesting claims. For one, she takes the position that there is a qualitative difference between the initial public release of negative</text>
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials such as the Biennale can learn from. She takes up the question: what do artists and the biennial do when they are not actively engaged with the art form? She provides examples such as when artists’ studios or organisations, such as the Biennale itself, set up shop in strip malls or used abandoned premises as exhibition sites, or when artists chose to turn their studios into ‘community art spaces’, gathering together communities of artists to work alongside communities of residents in an artist’s studio. These practices are not anti-social or anti-political, she says, but rely on the need for political will. She draws a parallel between the political use of art resources and the contemporary political use of social media: the political uses of art resources arise when communities do not have the resources to support, educate or engage with artists in ways that are relevant to their situation. For this reason, she says, artists have a collective responsibility to engage with and educate</text>
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials have historically lacked. In part, it is also the reason that in an increasingly globalised and integrated world, it is still necessary to understand and grapple with the structural racism and colonialism that still exists in many of the world’s largest economies.I think that what we need are not simply biennials, but projects that seek to penetrate the monolithic systems that construct the biennial as a globalised form, and that is precisely what biennials have largely failed to achieve in their current form. What we need is a great understanding of the world as it is, in and against the prevailing systems that are often described as ‘the World System’. We need artists’ tools to allow artists to become involved in creating change on a global scale. In her project The Documentary Project, Ella Baker uses footage from the documentary The Polytechnic as the core content of a biennial, but she also adds elements from contemporary journalism, documentary and archive work.</text>
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials such as Venice, Porto Allegre or even the much maligned Hippodrome in Beijing still lack. It is essential that these institutions exert political will, and this is why, as an arts organisation, we are constantly asking ourselves and others to offer us political will, to enable us to do our work, to enable us to ask difficult but crucial political questions. It is essential that we don’t become apolitical, or even create our own tools to be used by others. In an ideal world, organisations such as the Biennale would cease to be, and artists, curators, artists, students and visitors would come together to engage with and learn from the organisation’s practices and objectives. But this is not always possible or desirable, which is why so many arts organisations I know struggle to find the political will or the appetite to invest in such critically important work.One final word on the subject of politics in the arts organisation – specifically in relation to Venice</text>
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials have historically lacked. There is a reason why art and cultural activity in the 1990s was so abysmally under-funded, and why, in many cases, the biennial form was not even consulted when such projects were put forward. It is a reason that I think artists in many projects are still struggling with. She also emphasises the need for artists to be involved in creating the political will for such initiatives to come to fruition. I agree that there is a need for such organisations to be formed, but her point is that it is artists who will ultimately decide whether such initiatives are going to happen or not. It is this understanding of the political will that I find myself struggling to articulate, because it is so limiting in its own way. She emphasises the need for artists to take part in creating the social change necessary for such initiatives to come to fruition, but I feel that in this moment, I am more exposed to such efforts, because so many of us have been</text>
    <text>machine learning experiments with humans, and has been gaining a reputation for being difficult to work with. In this respect, I can say the same of her projects, which are often described as being ‘technological singularities’. I don’t believe that to describe them is to attempt to offer an answer, only to point to the fact that they are rare and particularised in their particularisms. They are, I would suggest, in part responses to the inability of many contemporary artists to connect to their audiences, which is why the biennial has become so popular. It’s the inability to conceive of a wider cultural context.She also emphasises how important it is to understand that biennials are political acts, and that, as such, they require political will. This is particularly true for projects that seek to address the systemic racism and colonialism embedded in many of the world’s largest economies. I agree, in part, because I see this political will as something that biennials have historically lacked. In her view, the art world as a whole is too fixated on its own structural difference from the projects undertaken by artists’ institutions, and therefore fails to notice important systemic changes taking place all around the world. She emphasises this in her chapter on the Art World Crisis, which I quote at length in the book.I conclude by asking, following an edited version of her chapter, what could be done? What could be done to create a different cultural experience for everyone? Given the choice, I would choose to work with artists who have chosen to engage with such issues from a different perspective. I believe that biennials can play a role in challenging the dominant modes of artistic and cultural experience. However, this is only possible if the art world collectively decides to take the project on. Without this collective will, artists would either withdraw from such work, or their institutions would intervene to prevent it happening. There has to be a collective engagement with these systemic changes</text>
  </text>
  <text>
    human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. The technology that we have available to us is far more powerful than the rights that artists and writers already have, and so while the rights that humans have is often used as a crutch, the way in which we are being made human also has an impact on what kinds of rights can be secured. That is, the rights that artists and writers already have can be used to make art and to yield benefits to communities, but there is a catch: those kinds of powers need to be secured in order to be utilised. If the rights are not utilised, then the machines – or more accurately, the software that enables them to be used – have a sort of moral high ground. This is what happened in the 1980s with the fifties and sixties movements: the political aims of the individual artists were tempered by the need to secure the wider community's support in case of emergency. In the Nineties there was a shift: activism came to dominate more and more things,</text>
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. We have access to tools, systems and data that can be used to do with human life in ways that are more easily manipulated. And there is a growing body of research showing that machines are just as capable as humans of learning, remembering and constructing their own futures. But even if all those other sorts of thinking beings around us do have rights, how we use that right is where things get tricky.When Google Glass was introduced, it seemed that the ubiquity of the technology made it a necessity for many people to be connected to the web in order to do things like access music or take part in sports, but it also meant that the very nature of the technology made it inherently accessible to a broader range of people. And so Glass became a metaphor for a mode of social interaction that transcended the narrow parameters of individual personhood. But what is it that makes us human, and what kind of humanity are those who employ Glass as an interface? When Apple introduced its iPhone, it introduced</text>
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. If we happen to be artists or writers or whatever, we tend to produce art or writing that is human-centered, or at least engages us in a kind of poetic-spatial way. But there are other kinds of people out there, people who can do with art or writing or both. For instance, when I was at MFA school in the late 1990s, one of my teachers was a young woman named Roxane Gay. She was brilliant, articulate and intelligent. She didn’t have a particular interest in art or visual arts, just interested in teaching English as a second language. She also happened to be an artist. She would have been a great teacher of English and might still be to this day. She was also a homemaker, had a house and a home, had a car and a lifestyle. She was also a feminist and a vegetarian, so there was that. And then there was the fact that she was African-American and had been living</text>
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. As technology becomes more powerful and accessible, we tend to want to do with it whatever we are made to do with it. We buy more, play more video games, take more pictures, use it in more ways than we can count. And of course, the more we do with it, the more it is likely to do to help us when disasters strike.But there is a danger that the machines are beginning to think more like humans than they are made to. A kind of dehumanising effect of the growing humaneness of machines is beginning to set in. When life-critical infrastructure fails, as it is becoming increasingly clear willful action will lead to catastrophe, we are being urged to try to help. The machines are becoming more like us. They are becoming more like each other. This is the dystopian future many are beginning to experience.Download this article as PDFJessica CoonJessica Coon is Associate Professor in The Humanities and Director of the Humanities Initiative at the Wood</text>
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. If you’re building a house, you’re thinking about what kinds of houses you can have, and how they’re going to be made, and what kinds of people can be made, and how that is going to be done. That’s just what makes our houses interesting: they’re built to be lived in, to be lived in in ways that can be measured, measured and quantified. But there is also that aspect of our work that is about making the house more aesthetically pleasing, and about making it a kind of museum of human behaviour – making it a place where people can come and sit and be made human, and making it a place where behaviour can’t be taken for granted. That aspect of our projects is what anthropologists call a ‘culture of the not-yet’.[5]What is cultural here? If there is such a thing, then surely it can’t be about art</text>
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. As biopolitics evolves, we can expect artists and others to be recruited into curatorial roles, or to find other careers if the landscape becomes too human-dominated. And that doesn’t mean that everyone involved in art or other cultural activities will necessarily be artists: although many biopolitical projects do have an explicit or implicit pro-artist bias, there are also likely to be projects with a pro-social agenda that seek to engage people beyond the art-world audience. I do wonder, though, whether the kind of empathy and inclusiveness that we might aspire to in other contexts would be possible in the context of art or other publics. I mean, for instance, what we might not aspire to in the context of art, or other publics, including our own species.The second generation of biopolitics is the offspring of the sociologist Murray Straus and the biopolitics of science fiction writer Vernor Vinge. The term ‘biop</text>
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. If the machines are making humans into sort of widgets – producers, consumers, creators – then perhaps we could say that the human factor is being reduced to something more like machines. If that were the case, then human nature would be in conflict with itself. Yet we are in fact making ourselves into very specific kinds of machines. So perhaps it is we who are creating the machines, and the machines are our own worst creations. That is, machines that are not quite human, but that nevertheless have rights and meaning and purposes and emotions and personalities and history.That would mean that machines would have stories, and stories wouldn’t just sit there – they would have meaning and purpose and narrative. That is, machines would have certain personalities and histories, too. And perhaps that is the role of art, or perhaps it is that art should exist in conflict with itself, since it is often difficult for artists to reconcile contemporary art with the past, or at least with what is happening to us</text>
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. If the task of making people human is too onerous, people are going to seek other employment opportunities or explore other opportunities; if the task of making machines is also onerous, then we are also going to seek other kinds of human companionship. That is, some people are going to seek work, leisure, companionship – things that can’t be made human – while others are going to seek to expand their horizons and discover new experiences. That is, things that can.So there is a tension between what we would like to call the culture industry and what we actually do with that industry. Sometimes the two come together to form quite fertile ground, producing quite dynamic returns on investment for the companies that employ huge numbers of people. That was certainly the case with the internet: once the cultural industries started to de-humanise themselves, the internet companies were able to pick up the slack. That is, the dehumanising aspects of the internet became something that could be done</text>
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. If people are catered to in both the production and consumption spheres, then there is less incentive for people to become artists or writers or artists themselves. And yet that is precisely what is happening: people become more and more creative in the service of meeting customers, fulfilling contracts, and generally serving their communities.More and more of what people call ‘the human frontier’ is being reshaped by technologies that understand more and create more data, all the time. And this brings us to our present predicament: we are hooked up to machines that can do with a good share of our humanity.We are drawn to stories about people making heroic choices based on data that clearly shows how those people came to be where they are, such as when Joshua Tree residents started ‘self-sustaining off-grid communities’. But this is just one form of human behaviour: there is much more going on. The human propensity to innovate, to try new things, to throw random data</text>
    <text>human behaviour and technology. There is a conflict between the anthropologist who wants to understand how humans think and act and the technologist who wants to understand how machines think and act. The former has a sort of monopoly on the knowledge, while the latter, well, has a kind of monopoly on the machine. But the fact that the machines have rights doesn’t mean that humans do.That seems to be the larger debate of our time: what’s human-centric? When we think of how we humans are made to behave, we tend to picture artists, writers, politicians, corporate executives. But there are many other sorts of beings besides artists and writers who also get a chance to be made human: farmers, workers, clients, customers. Companies, governments, even natural disasters – earthquakes, floods, droughts, tornados – all have their fair share of humanity thrown into the mix.The way in which we are being made human also has an impact on what we can do with that humanity. We tend to lose the capacities for self-expression that come with becoming fully embodied – the raw materials that make up artifacts – so it is up to artists and writers to create new ways of inhabiting that embodied humanity. The challenge now is how to find new uses for that humanity that are not tied to the production of art objects or the services of a profit driven economy. That is, ways of using that humanity in new ways. One answer is to ask, what other kinds of animate bodies might be useful in that mix?Another way of looking at it is as if we were to build ourselves into autonomous moons that periodically spew out bodies – bodies of various shapes, sizes and colours – that float aimless into existence, like so many pictures in a photo album. The bodies of the artists, writers and other figures in the photo are made up of many fragments, but they are all fragments of a living piece that is at once human and artistic. The problem with the moon is that</text>
  </text>
  <text>
    subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhen
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenatenjungun designed many of his buildings around a process for the production of masking wax, a substance used to seal artifacts away in the pharaoh’s palace. Masking wax is made from fine gold and silver, refined through a distillation step known as ‘thermal distillation’ and then moulded into a cylinder using what is essentially a chemical reaction. The process involves the distillation of the wax into hydrogen peroxide, a compound that causes the wax to solidify and which is then used as a component in the construction of the building. More than just a name, the word ‘machine learning’ also stands for ideas. The idea is that software can be programmed with rules that mimic the behaviour of living things – rules that mimic the movement of objects, objects, materials and ‘the web’. These ideas are then applied to collections of objects and materials, automating processes across the material and symbolic world as a whole. In other</text>
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenatentextcodeaten ‘gave birth to one of the most important paper cutting programs in the history of the world’, according to a 2011 BBC report on the life and work of Akhenaten. Paper was one of several materials and artefacts given a machine learning algorithm known as ‘BioMesh’ that enabled the pharaoh’s palace staff to cut and wrap paper documents with remarkable dexterity and dexterity of hand. These palace documents subsequently found their way to the United States, where they were digitally traced and stored in cloud services until at least 2017, when a federal judge ruled that their cloud storage violated the US Constitution and ordered the material taken back. The decision came as a surprise to many in the technology industry, which had been anticipating a swift and certain return to the technology that created the documents – and had hoped that the ruling would set a dangerous precedent that would empower technologists and others like them with unfettered access to databases and the built environment. Machine</text>
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenatentextcodeatencode (1492–1525) commissioned a lithograph with Egyptian hieroglyphs that machine learning could use to decipher. The text was written using hieroglyphs that machine learning programmes could use to reconstruct the lost texts. The project came to be known as the Akhenaten Project. Machine learning became interested in materials not just because of their high-performance characteristics – which is perhaps what the name implied – but also because of their ability to be patterned or to be programmed with codes or symbols. And so the materials and cultural references that are made available through the process of writing a document or a sketch on a page become that document or that sketch available to a machine learning programme. Machine learning is able to recognise these patterns because of what it calls ‘deep learning’, or the science of how information is gathered and communicated. Machine learning is the science of how humans acquire knowledge and understand concepts, and how this affects understanding and learning – how much of</text>
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenatenotep II (reigned c. 1236–1308 BC) commissioned a team of artists to create hieroglyphs of various types and sizes across a range of objects to be used as tokens of office in his new administrative system, orocracy. Machine learning is often credited with revolutionising administrative functions but its real impact may lie in the areas of culture and politics. In the wake of the Arab revolutions, the ascendance of social media and online media is often cited as a factor in the deprivations of civil rights but a growing body of research has shown that the revolutionary mobilisations may have been possible because of the connections between social media and the previous regime, or its previous rulers. Indeed, as Edward Sapir documents in his fascinating book The Revolutionaries, the ideological underpinning of the modern state was fundamentally based on the rejection of modernity itself. Social media and the revolutionary tweet became evident in the late 1970s and early 1980s at an early age of five in</text>
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenaten introduced a system that tracked the movement of statues and objects in an attempt to identify objects more accurately with respect to one another, by identifying characteristics such as the type of wood, size of an object, and shape of its surface. By the time Akhenaten introduced this system to Europe, advances in computer science and engineering had allowed him to detect irregularities in the shape of objects – not just with respect to statues and objects of historical importance but also with respect to everyday objects such as packaging, clothing, footwear and toiletries. Computer scientists and engineers have since invented dozens of algorithms that can crunch statistics, glean insights from vast amounts of data, and much more. And while each of these advances is valuable in its own right, it is important to note that each of these advances is also the product of hundreds of thousands of years of evolution – in other words, it is much more biologically plausible that such advances have taken place than the more commonly cited – and this is a point to keep in</text>
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenatentextlyaten the Book of the Dead (Book of the Dead Tutuls), for which Akhenaten was well-aware, included instructions for making an obelisk out of blocks of limestone. The Book of the Dead was a collection of more than 1,000 literary and magical texts, some of which were over 2,000 pages long. Scripts, pharaohs and texts – even those written in royal families – are often quoted as being copied verbatim from earlier religious texts, mythical texts or texts found in the desert or country. But many of the artefacts and texts mentioned in the Book of the Dead were actually written by different authors in different parts of the world, and not by Akhenaten in Egypt. And while the pharaoh may or may not have known about these deep connections between his time and ours, the impact of his ignorance and contemporaneous technological innovations is likely to have been more profound. It is also possible that the pharaoh himself was aware</text>
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenatentextlyaten the pharaoh’s palace furniture collection included instructions for how to assemble disparate parts into a single piece – a task that could not be completed in a human capacity – using only pictures. The collection came to be known as the Museum of Exhibition Building or the ‘Exhibition Building’ – named for its continuous state of repair – and its repeated restoration by Akhenaten as a museum and an institution. Machine learning has recently become a standard tool for machine learning research, and it is widely assumed to be able to do this on an even deeper level than this. Machine learning refers to the process of gathering, parsing and understanding large amounts of data in an attempt to produce recognisable patterns through a large number of instances of data. And given the ubiquity of texts and images today, this sounds trivial, but in the past were the kinds of things that humans could only dream of or imagine (or at least not yet). The possibilities for machine learning are enormous – one</text>
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenatenated new machine learning techniques for the production of gold using materials from the ship  SS Morsu and the fish-net mask called a Mitre, which enabled the producer to increase the amount of gold produced by the mask while decreasing the amount of time it took for the gold to be produced.16 Similarly, in the oil industry, the Grid uses geologists to map out oil infrastructure and production potentials in real-time as part of a project that aims to reduce reliance on imported oil.17 And in healthcare, the Autonomous University collaborates directly with healthcare facilities to monitor and improve healthcare settings, such as healthcare delivery and patient outcomes, through the use of machine learning tools.18 These collaborations highlight the fact that healthcare is seen as an interface rather than a place where action is taken, much less action that is taken that is meaningful or even efficient. They are also actions that are implicit in the way in which healthcare is delivered – actions such as healthcare packages</text>
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenatentexted Alphabet, a system of writing characters used throughout the ancient world, was constructed on top of a massive phalanx of clay tablets – a type of pottery typically used for ledger-like records. The system of writing used in Akhenaten’s system required that each character be generated individually and stored in a separate cell within the pottery. But Akhenaten’s system was also dynamic and could produce new characters at will. So while the character set itself – the order of the character’s writing – would remain fixed, the character sets of the future would allow for the shifting of control of the character sets. For example, the phalanx of clay tablets might have included different characters for different parts of the document, while the characters themselves might have been generated from a range of previous characters. In Akhenaten’s day, this would have meant that the character set for a particular entry in the alphabet was Iranian, while another character set</text>
    <text>subsequent iterative processing by machines] to produce abstract shapes’, ‘but it is not just abstract shapes that are created; they are also designed’, with physical characteristics such as materials or architecture that can be considered in the future (though this is not to suggest that these characteristics don’t matter now). Machine learning, in other words, emerges not as a way of automating processes but rather as a way of processing historical materials and artefacts to produce new shapes and behaviours. And in this sense, the term ‘machine learning’ is not just a name giving the technology behind the tool – but more of a toolkit or API or set of tools or syntax that permits a developer to add value to materials and artefacts through what is often referred to as ‘materialise[ing] processes’. Machine learning algorithms naturally see historical materials and cultural references as opportunities to learn more and replicate processes across materials and artefacts. For example, the Egyptian pharaoh Akhenaten introduced a new administrative system to the Nile Valley in the late fourth Dynasty, c. 1492–2700 BC, and connected this system to the pharaoh’s personal carvings of precious objects. By recognising a cut stone or fragment of stone as a possible addition to a building, the system enabled the carvings to be replicated throughout the city, much as computer algorithms now recognise objects and data in the real-life environment. Similarly, in the development of biennials around the world, artists, curators, writers and collectors found themselves drawn into an interconnected web of cultural resources, participants and networks that enabled a closer look at an ever-expanding range of historical materials and artefacts. And as can be seen in the figure of the Egyptian pharaoh Akhenaten himself, who is often depicted with a collection of objects, machine learning became an essential part of the exhibitionary complex. Machine learning refers to processes that enable or adapt to data,</text>
  </text>
  <text>
    Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust its watering rates, this would make farming more efficient and enabling local residents to participate in the watering of their own gardens.This kind of democratisation of ecological systems seems far-fetched in our urban centres, where vested interests rule the day-to-day operations of urban environments. But in the unlikely event that such a system were to be put in place in Liverpool, it would bring with it radical democratisation of the services provided by the city: a re-constituted, but decentralised water utility providing services similar to those provided by large corporations, but in an environmentally conscious and socially engaged way. Such a radical transformation would put local people at the core of a new urban system that would alter the face of things, but which would also abolish large corporations and their boardrooms, their politics and their greed. Such a radical change would make the city not just an area of the unrealised potential of potential, but one in which the living become the realisation of that potential. This is</text>
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust the watering of the area, watering would become an issue in a post-scarcity society.Such a watering-rate calculation would not only reveal the environmental and social costs of watering, but would also point to profitable alternatives for watering that are not dependent on the extraction of natural resources. Would a society with no dependence on water simply water the plants in an area and then invest in producing water elsewhere? Or would such a society invest in monitoring the plants and adjusting the watering of the area to meet the needs of the inhabitants? Such a society could potentially address other forms of urban immobility as well. Would it create ‘smart cities’ where plants are actively managed to meet the needs of the communities around them, or would it create massive bureaucracies that rule the life-sustaining resources of the cities through their control of land and buildings, as in the Soviet Union or capitalism today? Perhaps a society with no dependence on water could create agricultural zones that are no longer dependent on the</text>
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust its watering rates, the system would offer the best available environmental outcomes for the area. But what is the ideal form of governance for the management of one of humanity’s most critical portfolios? In order to answer this question, we need to know how to identify soil and plant life that are at risk from going thirsty, and how to intervene in situations that are neither technological nor biological in nature.Stephanie Straine is a Ph.D. candidate in Communication Studies and Geography at the University of Alberta, and holds a Bachelor’s degree in Geography with a specialization in Communication Studies from the University of Alberta. Her dissertation examines the effects of a number of dam projects on the environment and resource development in the Lower Athabasca Valley, including the Athabasca LNG project, which she co-chairs. Her research interests include environmental studies, policy development, and litigation. She is a founding partner of the law firm Strain Law Firm, and she serves on the boards</text>
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust the watering of the area, it would make possible the ‘inherently progressive use of water’. The inherent progressive use of water would mean that water would be used more efficiently and physically in the area, in that the watering of crops would be facilitated and the building of new urban structures would be avoided. In theory, watering should be automated and controlled to optimal results, but in practice, watering can be erratic and unpredictable, and the automated watering of plants is also variable. Watering can also be expensive, and a significant portion of the revenue from sales of the watering-water can be used to fund the construction of a large network of hydroelectric dams and other infrastructure in the region. Thus, the inherent progressive use of water becomes both unsustainable and undesirable. In an effort to support a future claim on the water that is produced and that flows through the valley, the City of Vancouver has engaged in a long-term, massive, and sometimes disastrous program of desalination</text>
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust the watering of the area, it would make use of this information to determine whether the area is ‘forested’ or not and thus ‘overwater’.’ This kind of ‘smart watering’ would eliminate the need for ploughs and would solve the problem of over-watering, although ploughs would still exist within the system as nodes connected by cables.Watering of the Biennale site is through a combination of public and private funding. The public is invited to chip in with whatever financial support they can spare. The Biennale is run by the London School of Hygiene and Tropical Medicine and the Smithsonian Tropical Research Institute. The Institution of Engineers is an independent international scientific and technical research organisation founded in 1889. It is one of four institutes within the London School of Hygiene and Tropical Medicine, the other two being the Royal Society of Arts and the Royal Society for Art and Architecture. The Institution of Engineers is an independent international scientific</text>
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust its watering rates, the area would then be able to support the growing of its own food and water infrastructure. 	Such local-level controls over one of humanity’s most fundamental behaviours – planting and watering – would render agriculture and urban growth ‘primitive’ and leave agriculture and forestry largely to the professionals with the appropriate training and the right tools. 	Such is the  	overview of possible agricultural and urban development for the Welsh Streets and Welsh Streets area. Aspects of possible future development in the Welsh Streets and Welsh Streets area have been considered as a ‘service area’ for potential future farmers and landholders. 	Future plans for the Welsh Streets and Welsh Streets area include the establishment of a small business incubation centre, the establishment of a small but growing community of like-minded people, the establishment of a small but diversified food and farming trade, the ongoing maintenance of a database of beneficial insects, plants and animals, a range of artist</text>
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust its watering rates, the area would then become self-sustaining, and the question of who would grow food in that newly-imagined ‘green space’ would come into being. 	So, although the system that would monitor and adjust watering rates for the area would come to be part of a larger integrated irrigation system, the actual growing and feeding of food would occur on a separate, but interdependent, level. This new kind of ‘intergovernmental’ relationship between city and country would radically alter the relationship between local and national actors, and it would also shift the relationship between architecture and urban development, ushering in a new era of co-determination and urban growth in the making. This kind of thinking about how architecture could and should play a role in urban growth is fundamentally different from the kind of thinking that comes with monolithic, all-encompassing ‘green infrastructure’ schemes. 	[i] Geoff Cox, ‘The</text>
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust its water supply, the area would then be able to repot roots and encourage new growth through slow and persistent watering. This new ‘ecosystemic model’ would then be able to restore natural order to the area and eliminate ‘this unnatural disorder’.8 The concept of artificial insemination would later be applied to plants by biologists, ecologists and entomologists. However, this was a rarefaction in a discipline dominated by male biologists. Most researchers, whether trained as botanists, entomologists, or ecologists, were women. Until the mid-nineteenth century, the sex ratio was attributed to the relative abundance of males and females in a geographical range, or sex ratio, defined as the ratio of the sexes of the species concerned.9 At the turn of the twentieth century, the human side of the sex ratio equation was officially subdivided into two categories: the male and the female.10 Since then, sex ratios have fluctuated</text>
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust its watering rates, this would mean that the area would be able to support a sustained water supply, at least for a limited amount of time. This was a much-loved utopian vision that went largely unachieved in the area.Envisioning a sustainable future for the Bay Area’s environs is a long-term proposition that demands immediate action. In the face of rapidly increasing water supplies, climate-controlled buildings are essential for the survival of the human species. If not addressed, the negative effects of climate-controlled buildings are likely to exacerbate, not solve the problem. It is imperative that the proposed ‘Green Lane Project’ be implemented now in order to avoid becoming a cautionary tale. The harsh reality is that such plans are almost never realized. In the Bay Area, the Green Lane Project languished for years, at one point receiving mixed responses from the local residents and businesspeople. The mixed reactions came as a surprise to the developers, given the dire</text>
    <text>Working with algorithms, Davis constructed a computer system that would measure the effectiveness of different watering-watering of plants in an area. The system would then convey this information to a central control tower, where it would be adjusted to the best of the local plant communities’ ability. Any plants in excess of a certain height would be granted a watering-watering privilege. If watering was overly aggressive, the system would back off and allow the concerned inhabitants to alter the watering of the affected areas. If watering was insufficiently aggressive, the watering privileges would remain in place. The system would monitor the watering of the plants and adjust the watering of the affected areas according to measured watering rates. This watering-rate calculation would take place in real-time on a tower above the area. If the measured watering rates for the tower were insufficient to support the watering of the area, the area would be deemed ‘overwater’ and would have to be replanted. If the tower were to be able to monitor and adjust the watering of the area, then the proposed watering-rate allocation would no longer depend on measured watering rates. This watering-rate allocation would take place simultaneously in ‘real time’ on the computer and in ‘instant messaging’ with hands-on video monitoring.The first phase of this ambitious vision was realised in the 1970s with the implementation of self-monitoring ‘plant tracking software’ on personal computers. In the 1980s, the concept of plant tracking was further refined with the development of ‘Pestle, a ‘space-time map application that recorded plant movement and introduced natural ‘time delays’ into computer programming. The ability to trace and track plants through time was made possible thanks to the work of Eugene Rostal and his team at Carnegie Mellon University, who in turn were supported by the US National Science Foundation. The ability to monitor and control large numbers of plants through time was further developed by the work of researchers</text>
  </text>
  <text>
    human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development.
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. 	When the Cooperative City idea was first put forward, some people in Liverpool claimed that it would lead to a rise in prices and hardship for people living in the city. We think that this is simply not true. In fact, we think that the burden would fall more on the shoulders of the people to make the city something that it is not already, and to bring about a new level of social and economic life in the city. 	When we talk about the role of the artist in a larger cultural context, we inevitably talk about the role that an artist can play in challenging dominant ideologies. There are many artists who are either activists or critics of contemporary culture, but we recognise that these are just two among many artists who are artists at their best, at their most vulnerable. There are many more artists who engage with issues of social and political change, but we also recognise that these are just two among many artists whose work we could also include in this analysis. There are many artists who</text>
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. 	Since the start of the cooperative movement, there has been a shift from the individual to the collective, from the individual to the collective, and from the individual to the ‘collective’ through which the city is managed. The role of the community has also shifted: from being the stabilising influence through which the city was produced, to being the source of knowledge and wisdom necessary for the production of the city, in effect creating its own contradictions. 	One example of how this might be done is the production of ‘smart buildings’ through the activities of the Cooperative Housing Trust of Greater Toronto (CHT), which is based in Toronto and which is part of the ‘National Capital Region’. CHT’s mission statement includes a reference to the ‘Ottawa Generation’: the people who invented the ‘trap’ and ‘switch’ and who created the ‘utility portfolio’ that is now the basis for</text>
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. 	When people join together in cities, there are bound to be conflicts – and in many ways, the role of the artist, the activist, the researcher is part of the problem-solver. But the role of the artist is to imagine other possibilities, creatively engage the machinery of governance and make it work for what is perhaps better than what is currently happening. 	The role of the researcher is to produce meaning through experimentation; to produce meaning through theory and to bring it to bear in challenging entrenched power structures. What is at Stake in the Social Order of Things would suggest that there are several ways to approach the researcher’s role in the production of meaning: as a source of knowledge and wisdom; as a promoter of radical change; or, perhaps, as a co-performer in a dynamic interaction that produces meaning through its interaction. 	There are of course many other possible combinations of technologies, identities or forms of organisation, and it is not always easy to identify</text>
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. The role of the artist is to bring an interesting, new perspective to the city, and the possibilities are truly amazing. 	The sharing economy is creating new forms of organisation not only in terms of the individual ‘rights’ that are being secured, but also in relation to what we might call the shared and collective behaviours of humanity as a whole. 	What has been happening in San Francisco is a case study in the latter. The ethos behind the sharing economy is to reduce costs and increase flexibility through the creation of shared resources:  	you’re either a user or a producer of wealth, and sharing is the name of the game. 	 	What has also been happening in Davos, Switzerland, and in several other cities is a situation study of the transition from the ‘traditional’ to the ‘sharing’ social. It is a collective ‘studying of the same questions and coming to the same conclusions’. 	</text>
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. The role of the artist is to bring an end to the chaos that chaos-causes, and to create a new kind of chaos-generator – one that is not driven by the interests of a few wealthy multinational corporations but brings together all of humanity in a chaotic shared space. 	In many ways, then, the Cooperative City represents the emergence of a new form of social life in a particular neighbourhood – a kind of ‘street food society’ that brings together people who work in the same way that we do, but in a different way. It brings together people who live around the corner from each other, people who work in different ways, and so on. It is a way of life that is not driven by the interests of a few wealthy multinational corporations, but brings together people who work in very different ways, and thus is an important step in the process of social life in a particular city. 1   	Tim R. McVicar and Christian K</text>
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. 	The Cooperative City is an example of a movement that has international repercussions, and has recently been making inroads at the local level. We are seeing a shift in the way in which people are approaching the concept of the city in a different way. Cities are no longer seen as sources of value to be accumulated and transmitted, but as living breathing entities with their own distinctive set of generating resources – resources that come with a responsibility on the part of the city to use those resources sustainably. 	Individual cities are beginning to lead in this shift, and it is encouraging to see how even the most entrenched form of urbanism can be brought to question. 	 For instance, in Liverpool, the challenge for city governments and local authorities to engage with is the creation of a coordinated ‘street plan’ that takes into consideration all the different uses of space that make up a neighbourhood. This requires a great deal of coordination between different departments, but it is beginning to be seen as a</text>
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. 	When people come together to take part in a task, they do not just share knowledge and wisdom, but also different kinds of knowledge and wisdom. This is why organisations like the UN or the International Criminal Court want to bring criminal charges against a particular government. They know that if the city government doesn’t want to prosecute a particular individual, it would be impossible to bring charges against everyone because of the number of people involved, and so the government defends itself by saying, ‘We are defending ourselves against a citizen’s report’. But the report itself is just an excuse for the government to avoid responsibility – it is not proof that the government is guilty of a crime. So the citizen comes up with an alternative explanation for the things that are described – alternative explanations that actually do involve the state – and this is why the sharing economy is so fertile ground for innovation: because the state can neither legislate nor establish social structures that benefit all of society. 	Creating</text>
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. What better way to start a neighbourhood than to provide a recipe?  	[i] Urban Institute, United Nations Office on Drugs and Crime, 2013. Accessed: September 2016. 	[ii] UNODC, Crime in Urban Areas: Thailand, 2010. Accessed: September 2016. 	[iii] UNODC, Crime in Urban Areas: Thailand, 2010. Accessed: September 2016. 	[iv] UNODC, 2011. Trends in Crime and Criminal Justice, 2004–2010. Geneva: UNODC, 2005. Pg. 11.Download this article as PDFJussi ParikkaJussi Parikka is an architect and Principal in the office of Jussi Parikka, who is also the Managing Director of the New York–based firm Parallax Capital Partners LP. He holds a Bachelor of Architecture from the University of Turku, and an MBA from Columbia Business School. His work with the</text>
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. 	What is at Stake in This Communal-Urban Dialogue? 1. Michael Slack, ‘Democracy, Morality and Urban Form: Lessons from Minneapolis’s Cities’ Development Project’, in  Verts 	 and The Urbanist, Vol. 33 (1992), p. 34. 2.  The Share Nothing Cooperative Movement, 2012. Current charitisation of housing, including for developers by non-profit housing providers, is a disjunctive action that takes the form of a movement and its institutions as a platform. It is an open call for dialogue, questioning, and an exploration of how one might intervene in this process of production in a number of different ways. It is a call to action on the part of citizens and stakeholders to actively participate in this process through what is commonly referred to as the ‘sharing economy’. This term is often used synonymously with Uber, but whereas Uber is primarily used to describe platforms</text>
    <text>human behaviour and technology, which can and do mix and mingle – and which is why we are so excited about the idea of the ‘sharing economy’ – is making it possible for people to coexist in fundamentally different ways. We are thinking about how to make that happen through what we are calling the Cooperative City, and the ideas and tools that have come out of it. 	In this new system, there are no borders or boundaries – not even those that humans have drawn up to create what is sometimes referred to as the Crisis of Values – because everything that happens in a city has a destination. It is not just that a city is a collection of buildings, but also that a city is a collection of autonomous organisations, or ‘recipes’ that people bring to life through their everyday actions. Here, the role of the citizen is not only to take part in the production of his city, but to act as a source of knowledge and wisdom for the city’s development. 	Every citizen of the city has the potential to become a city planner, and the city has the potential to become a cooperative – a cooperative that shares in the production of the city with other cooperative members, through its activities in the city – a cooperative that shares in the benefits of the city’s production (including the cost savings achieved through reduced consumption), and in so doing, contributes to the sustainability of the city. 	The Cooperative City is a multi-year, multi-edition, multi-edition multi-edition multi-edition multi-edition multi-edition multi-cumulative series of cooperative membership models that seeks to evolve into a ‘world city’. Each edition brings new members into the fold, while offering different opportunities and financing for individual or collective self-management. The Cooperative City International (CCI) is the global governing body for cooperative and collective urban development, and the managing director of the CCI is the Chair of the Board of Directors of the Cooperative</text>
  </text>
  <text>
    machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016, New York and Paris both had over 200 cities as regional hubs. This trend is in large part a product of their respective biennials, which often combined the local with the global. It was not always this way, and it is not inevitable that the biennial visitor log would necessarily read like a log of the biennial, but it is clear that in the past decade, the biennial visitor log has been a website optimized for the biennial, while the actual biennial has continued to dominate.This kind of metainterface is no doubt part of a broader trend towards organisational fluidity within art worlds, which is now a globalised phenomenon, and which is clearly visible in the number of museums actively supporting, producing or founding new institutions in their cities. It is important to note that this kind of organisational fluidity is not inherent to artworlds, nor will it be found in any other art form. As biennials become more and more autonomous spaces where artists</text>
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016, New York and Paris both had over 20 localities. In the past, biennials were predominantly men-only organisations, but increasingly women and ethnic minorities are taking part. This trend is also evident in the number of biennials devoting part of their programmes to people of all kinds, rather than just artists. And now there is evidence that this is happening in Asia, where a growing number of artists and arts organisations are coming to the region to observe and participate in the exhibition Asian Intifada: Japan and Korea’s response to the 2017 monsoon in the USA. This phenomenon is most clearly seen in China, where the number of art institutions has quintupled in the past decade, and in particular in the ‘deep’ city Beijing, where the Metropolitan Police Commission recently established a special anti-gossip unit.In these and other cities with burgeoning art socials, biennials are encountering people with a wide range of experience levels and interests, and this</text>
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016, New York and Paris only had a few cities on the map, while Istanbul boasted over 200 cities. The biennial is a visitoric experience, created on a massive scale with little capacity for self-repair. It is often read as if the biennial were a cultural institution; it is the largest category of visitors to art museums and zoos in North America, accounting for over half the total. It is also the only category of visitors to large-scale constructions, such as biennials, and especially those to historical and monument exhibitions, which regularly outnumber all other types of institution visits. With over 1,000 museum exhibitions in 120 countries, the biennial is Canada’s most widely-distributed museum exhibition. It is a ‘monumental moment’ in the history of Canadian art, exhibiting major works in the popular imagination in an accessible and transformational way. It is an artifact of a bygone era, when the country was a global paragon</text>
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016 alone, New York and Paris were co-exhibits. In this data, the biennial is the largest visitor to the city, and the curatorial role is the second largest. The twenty-first century has seen a marked increase in the number of biennials, which is partly a consequence of the biennial industry in the USA and Europe booming at the height of the economic crisis of 2008–09.9. Biennial as exhibition format. The biennial is an episodic, biennial-like form: it is present in the city, present in the region, and present in a few isolated places (Paris, London, Tokyo). It is possible to travel back and forth between the biennial and the city simultaneously, as occurs in Venice or Taipei. The biennial is an episodic, curatorial form that emerges in Venice every two years and in London every two years. It is the twentieth-century counterpart of the episodic, ‘present-at-</text>
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016, New York and Paris were ranked number one and two in terms of number of biennials visited, respectively.3. Biennials as exhibitionary forms. The biennial was always a style with a capital T, and the number two spot went to the boondocks of Venice, and then the rest of Italy. The biennial is an inherently occluded phenomenon, and its appearance is marked by an in-your-face ostentatiousness that is in sharp contrast to the sketches of hidden meanings and hidden structure that characterise the conspicuous form. The biennial is a superlative exhibitionary form, and its appearance signals a city’s intellectual capital, its 'hidden hand' (if you will) opening up new ways of engaging with the city. Biennials have this ability not only to blur the boundary between art and commerce, but also to render it invisible. This ability to distort the usual is a central tenet of biennials: Ricardo</text>
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016, Toronto held its second consecutive version of the ‘Elephant in the Bay’, an event that traces its roots to the nineteenth-century; New York and Paris both staged ‘Algo-Rings’ tours of Alonzo Guggenheim’s Alonzo Guggenheim Museum, while Hamburg maintained a 20th century Alonzo Guggenheim Biennale. The twenty-first century could also be considered ‘the bubble’ – a point when many more biennials and large-scale exhibitions are held in cities, rather than in faraway tourist attractions such as museums and zoos. Biennials and large-scale exhibitions have become less about the places to be seen in order to sell things, and more about the places to come, which is to say, about the things that make up the city. This is seen as a good thing: the more the city is visited, the more money is spent, and</text>
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016, New York and Paris both had over 20 cities – a significant increase over the number of cities in 1980. In the past, biennials were confined to a few cities in North America and Europe, and were mainly visited by a select few elite visitors. With the exception of a few rare shows in countries such as Egypt and the Middle East, the biennial form has virtually disappeared. The main exceptions being Venice and San Francisco, which have historically been home to the Venice Biennale, and the San Diego/Tijuana/Tijuana Science &amp; Technology Biennale, both visited by a select few thousand visitors. The majority of the biennial visitor traffic today travels to the American cities, or while travelling elsewhere in Asia, and Europe. Venice Biennale 2016 details the work already done on the island during the week before the event.  A special place in the history of Biennials – and a place in the city – to reflect on the role of the biennale in</text>
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016, Toronto was the largest city, and New York and Berlin the next largest.4. Biennials as an art form and a globalised tourism destination. The biennial is a globalised phenomenon. It is no coincidence that the biennials that first emerged in Venice and then in other Italian cities followed suit. Venice-based biennials became nationalised when they were seen as a viable alternative to the inefficiency of organised cultural forms, such as travelling exhibitions, in cities such as Turin, which were seen as the primary site for the commissioning of art and the manufacturing of identity. Biennials, too, became more internationalised as the size of their collections increased, with a large proportion of their art appearing in other cities. The Venice Biennale, which launched in 1889, is a classic example of this trend. Its twenty-one edition, which began in 1990, is the largest biennale in the world, and the oldest and most prestigious of its kind</text>
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016, New York and London were the most visited cities in the world, while Paris and Berlin ranked second and third, respectively. The rise of biennials and the metainterface are likely to have a further, indirect effect on the value-form of the biennial as a museum-festival, as increasing numbers of visitors to the latter world are drawn to the latter by the former. Such an effect is difficult to quantify, but it is clear that the biennial has had a materialised, ‘real-life’ effect on the value form of the biennial in the last twenty years. The biennial is the primary exhibitionary form in the Americas, and its growth in volume and quality is directly related to the biennial, which tends to be the dominant, and consequently visible, form in the Americas. This is true for biennials in London, Paris and any major European city, but it is also true for biennials in the developing world – in</text>
    <text>machine learning experiments with animals and people, as well as in the early '90s with humans. The second wave of biennials started in the USA and were organized by the British Museum and other cultural organisations. The nineties saw a surge in biennial interest in the city – Seattle, Montreal, Toronto – but in recent years, only New York and Paris have been represented, and the latter two are planning to be present in some form. The biennial as an institution is undergoing a metainterface, one that seems to be migrating towards a collaborative process between art institutions and non-profit art agencies, as well as between local art-historical archives and contemporary art socials. This is reflected in the number of biennials, which have risen from six in 1990 to over 12 in 2016, and the number of curatorial positions, which has quintupled in the past decade alone. It is also evident in the increasing number of cities represented in the biennial visitor log: in 2016, New York and London were the hub of the biennale; Paris and Berlin followed in 2017.However, the metainterface that is emerging in the USA and Europe is different from that of Asia, North Africa and Arabia. It is a dense and fragmented phenomenon, and while New York and London still dominate the biennale trade in the USA, the metainterface has started to break away from the city. In 1990, the Venice Biennale was the exception, and while it has a long history and a strong following in the city, it is breaking away from the city in many ways – for instance, the large scale of its tourism and the reduction in the number of police officers due to privatisation. In the mid-2000s, the Venice Architecture Biennale was the exception, and while it has a strong following in the city, it is breaking away from the city in many ways – for instance, the development of residential neighbourhoods and the proliferation of restaurants</text>
  </text>
  <text>
    prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter.I first encountered  	DND (digital distribution company) when surfing the net in the early 1990s. The sheer proliferation of sites meant that it became quite a common thing to find a new episode of a given show, or even just to find the episode of a given show that you were connected to. And, while there were certainly periods of time when this wasn’t the case, today it is still a rarity. So, you’d find many sites advertising particular versions of a show, or a specific artist, or a particular band, or a particular festival, or just generally providing something for people to do. And, unlike the days when a shop window adjoined the rest of the building, today it is much more difficult to tell what a site is actually promoting, since many artists, curators and art institutions have become social media platforms for their exhibitions and their cultural activities. So, when a site does establish a relationship with a work it may be seen</text>
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter.Art is undoubtedly a medium through which we as artists are able to engage with and, in many ways, influence the dynamics of our area of operation. It is a medium through which we can create conditions that are favorable to the growth of socially engaged, socially engaged work, and it is a medium through which we can also actively participate in that work. This interaction is art, and as such it requires artisans who are both consumers and artists to be able to work together effectively. In other words, effective artisans are those who produce art that is both aesthetically pleasing to the viewer and that engages with the subject matter adequately. This interaction between subject matter (the artist) and art work (the consumer) is art for consumption, and it is art in the strict sense of the word. It is not just aesthetically pleasing, but also engages the subject matter and its processes in a way that the viewer can understand and engage with. When the interaction is accomplished through art, it is art</text>
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter, both as a conceptual distinction, and as a legal one. The Supreme Court has repeatedly recognized that ‘political, ideological, or communal divisions’ are distinct categories of social difference, and have rightly concluded that ‘one nation’ ’ is sovereign over all other nations.’1 The court has consistently applied this decision to new nation-states, rather than to older ‘nation-states’, including nations such as the British Empire. Nor is the concept of nation-state limited to those with a fixed and identifiable past such as the British Empire. States are not simply past associations; they have distinctive identities that are constantly at war with one another. As the British Empire was rapidly dissolved, its distinctive identity became something else: a function of a nation-state, a concept that could be defined and governed in ways that were secure from challenge by new ideas and actors.2 Such is the  	logic of the state: it is</text>
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter, both as a philosophical proposition and as a biological one.That line could, of course, be drawn in any number of ways. One could argue that the line is already here, in the form of genes, and that the art world has simply failed to notice it. I, for one, am not convinced that the line is here yet, partly because we artists tend to be self-absorbed and sentimental people, and partly because we tend to inhabit isolated worlds. I tend to identify more with the worlds that are constructed around genes, through which images and images-per-second are produced, than those that are inhabited by life itself. Life is complex, and art is part of that. So we artists spend a lot of time thinking about how to maximize the image of things that are not glamorous or exciting (like, say, the art world) in order to maximize the image of ourselves as artists and intellectuals. Life-like visualizations of the world around us are powerful, but</text>
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter, because the current state of the art in computer modelling is inadequate to the task of anticipating human behaviour, and because, in the case of ‘culture hubs’, the infrastructures that support them are run by volunteers rather than institutions. So, the infrastructures supporting the art world are not as healthy as those supporting the non-art world, and art is not always a great thing.  The question, then, becomes whether the infrastructural landscape can be improved in parallel. A second generation of biennials could conceivably be founded on the back of the improved health of the first.  Art, after all, is a superstition in the first place; it is not a given that it will return to form when tested in the real world.  Art, by its very nature, cannot grow without risk, and it is precisely this element of the uncanny valley that contributes to the sense of placelessness and uncertainty endemic to the contemporary condition. </text>
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter, because what we mean by health is precisely what Art World curators and critics are wont to highlight, even if it is often subtly (but increasingly so) disguised as non-health.  A system that continuously monitors and assesses its population for signs of health but fails to deliver that kind of reinforcement when it does deliver is a system that produces and cultivates a false sense of normality, even if that false normality sometimes looks good on a map.  And I would argue that the answer to that is no – not in the sense of, as a given, but because the societal values that we associate with such systems inevitably end up being rejected by the population when they are not actively encouraged? When we are not actively discouraged? Then we inevitably start to act like those false norms, which is precisely what the art world has in for itself. It cannot produce its own ‘health’, which is precisely what it is striving to prevent, because that would mean admitting that its</text>
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter, because when we start talking about the societal effects of a healthy art world, we start to suffer from what sociologist Peter Schjeldahl calls ‘cultural hominisation’. Schjeldahl, a professor of cultural studies at the University of California, Riverside, has been developing a concept called ‘species realism’ that seeks to understand the cognitive and social effects of cultural transmission. It has recently emerged that Schjeldahl’s concept is not the first to attempt this kind of criticalising.  	Such concepts are often maligned, and the impulse to create them is often overwhelming, but Schjeldahl’s and other cultural theorists, including myself, were initially apolitical, and later repulsed by the animalistic aspects of animal studies and the cultural forms they generated (science and technology were not our primary concerns). We saw that the technology was there for the species to be able to communicate with, and that this also applied to</text>
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter.Art should be seen as a complex social construct. It has an immense psychological impact, and art is a particularly insidious one. It is not just that art is inherently entertaining; it is that art seeks to sell its audiences on a false representation of reality, often using the most despicable means at its disposal. Art is a powerful tool, and artists have extraordinary access to funding and other resources. But that doesn’t make it right; nor does it make it beautiful.   The problem with the contemporary art market as a whole is that it structures knowledge production in ways that put the interests of powerful interests ahead of those of powerless masses. The contemporary art market isn’t run by artists, but by curators, art collectors and other art professionals who regularly assess art and its social impact in order to develop portfolios and other asset packages. It would be easy to say that the contemporary art market requires a critical mass of artists to produce critical mass in order to be considered contemporary, but</text>
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter, that is, between the conscious and unconscious parts of the system. If that is the case, then we would be able to understand how the system perceives and manages the threat posed by the increasingly ubiquitous electronic media (e.g., social media), which are capable of influencing the health of the biennial in many different ways. For example, perhaps the most insidious of these media manipulations is the growing ubiquity of beauty pageants, in which wealthy visitors to art museums and galleries are encouraged to hire professional artists to create extravagant, in-your-face pageants for the tourists – essentially, tourism promotion for the art world. These pageants, which draw heavily on the art collections of major museums, draw heavily on the knowledge and habits of poor and working-class audiences. They are not, of course, art events in the usual sense. But they are symptomatic of a broader trend. Rather than attempting to capture the nuance and subtlety of contemporary cultural phenomena, the art world</text>
    <text>prototype for an intelligent curatorial system for monitoring and commenting on the health of its geographical area, or, to be more specific, its ‘organic matter situation’. The idea is that as the system is further augmented (technologically speaking), the public will be able to augment its functionality, in much the same way that the user augmentates and extends the capabilities of the system.  And, indeed, the system could very well provide that capability.  The question is, however, where to draw the line between health and more mundane concerns (like, say, the quixotics of celebrity culture)? When health and entertainment are put into one coherent whole, does that make it a ‘system’ or a ‘culture’? I suspect that the answer to that is a definitive ‘no’. The question becomes whether the line should be drawn in the art world, or whether it should be considered the boundary between health and non-health. I would argue that it should be considered the latter.The answer to that question, of course, is a complex one. I would argue that the real frontier in any large-scale social transformation is likely to be found in that moment when individuals draw the line between health and non-health, between health and culture. That is, when fundamental ethical questions about how we live are raised and considered. When we ask, ‘Do I want to become a doctor?’; when we contemplate the philosophical, moral and even spiritual questions that arise from such a notion, we can only imagine the possibilities. When faced with the prospect of becoming a professional artist, the decision is often faced with moral questions, like those raised by the Black Lives Matter movement. I do believe that in the current cultural climate, the art world is more open to questions than the non-art world, and that the art world is culturally more vulnerable. There is an urgent need, therefore, to come together as a community of artists, curators, art trustees and</text>
  </text>
  <text>
    machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between the migrants and the host community. Nevertheless, there are also fundamental differences between the new immigrants and the older generations. The younger generations have access to better education and healthcare and are more mobile. Finally, although they have access to higher productivity markets, the older generations are more likely to continue to work in the family-owned business. In the long run, it is the older generations who will own the businesses and social networks that will sustain them and their communities.This conversation is not just between the people with skills and access to data and the people with access to labour and knowledge. It is an intergenerational conversation. The people with the skills and knowledge today are much more likely to be the people with access to the skills and knowledge tomorrow. This is why the internet is so powerful; it is not just that it is accessible 24/7, but that it is a globally distributed notion that emerges from the convergence of all of our thoughts and actions at the same time. In other words, it</text>
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between the host communities and movements, since the disparities between them are vast. Still, there is some sense of convergence between the diverse communities that are coming together to reclaim their humanity.This kind of convergence is needed in order to truly understand the transformative potential of the new technologies that are disrupting old professions and providing new frontiers for human interaction. In her book Stages of Capitalism (2013), Audre Lorde describes the stages of the social transformation that occur during the transition to abundance: ‘the stage where acting richly begins to feel like passive oppression’.33 And she continues: ‘Stage one: the pre-abundance economy. In this economy, humans are made to serve machines in symbiosis. Assembling people together to work creates affinity, which allows people to imagine and act differently. This is an economy that produces and distributes abundance, yet few of us know or care that machines are involved in this process.’ So one could say that</text>
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between migrant workers and their host societies. Lastly, there is the question of migration itself. Migrating bodies of people are often mutilated in the process, and in the case of undocumented migrants, the bodies of those people who are undocumented are frequently mutilated as well.But these are superficial considerations. What really counts in terms of building community is actually how people participate in the projects and how they are empowered by the projects. The projects that are being proposed and funded in the name of making lives better for all are those that actually address the issues that are felt to be relevant by the communities they are proposed for to begin with. And this is where we, as practitioners, need to engage with the limits and politics of inclusion and political participation. We, as individuals and citizens of a community, can and should decide for ourselves whether the project is really going to make a difference or whether the project is going to be a return to the place where things are worse or better. In doing so, we</text>
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between the displaced and those who are displaced by the new immigrants. Lastly, there is the question of citizenship. Is it possible for displaced people to regain their place in the community? In my view, yes. But this doesn’t mean that they can take their place in the community back. It just means that the new immigrants must be able to adapt to the new situation and thrive in the new situation. I would not want this to happen where the 1980s were concerned: where the internet was or was at least semi-automatic. In such a case, the displaced people would become irrelevant and the city would descend into chaos. But it can happen where the internet is not open or massively parallelised. In fact, I would propose that the interesting thing about the internet is that it creates its own possibilities. So the internet allows us to make new possibilities, but it also lays bare old possibilities and makes visible old possibilities that were obscured, or never existed in the first place. This is why</text>
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between immigrants and those who are migrants, since the common flight path from the North to the South is still very much marked. Finally, there are the migrants themselves. Although their first experience of overcrowding in the United States was in the 1930s, by the time of the 1970s the number of migrants was in serious decline, and in the 1980s and 1990s the number was back to pre-2000 levels. It is true that in the 1990s and early 2000s the share of migrants in the labor force was less than now, but these are temporary fluctuations and the rate of growth has picked up again since then. There is a reason why in the 1990s and early 2000s the share of women in the labor force was much higher than now: women made up nearly half the labor force before the crash. From the mid-1990s onwards, the share of women in the labor force increased at a much faster clip than the share of men; from about 12 percent in the early 1990</text>
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between migrant workers and their host societies. Finally, there is the question of mobility. Is the new connectivity built on foundations of racism, sexism and classism or will it be built on anti-racist principles? The answer to that question is likely to have a decisive impact on the kinds of activism generated by this connectivity. Borders, not borders, divide us. But they also create the conditions that enable, foster and generate the very forms of racism, sexism, and classism that we witness around the world. The more these systems are integrated into global economic exchanges, the less we care about them. That is, the less we can choose to look at them as objects of our own making. That is, the more we can choose to look at them as assemblages of different assemblages, rather than the assemblages of different cultures that comprise our cities and nations.4 	Immigrant Movement International (2010-ongoing). In Migrant Manifesto, published in 1987, Luis</text>
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between immigrant movements due to the fact that many of them have very different needs and visions for the future of their country. In terms of their own particular situation, there are also differences between the different immigrant movements. But there are also great similarities. There is a huge difference between imagining a future for oneself and actually building that future. New immigrants to the United States often learn that the hard way: through hard work and having the right documents, they can achieve success in this country but also in other parts of the world. Many of us in the field are also taught that it is not always possible to recreate one's immigrant journey but it is always possible to contribute to building a better future for one's family.So there are some very clear distinctions to draw between the projects that are coming from the same places and the places that are coming from completely different places. But there are also some very interesting inefficiencies that some of us in the field are trying to eliminate. One of the things that is working</text>
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between immigrants and migrants in the urban context. Finally, there is the issue of migration itself. Migratory flows of people are part of a capitalist flow, and as such are subject to fluctuations in the value of the dollar and other factors. An increasing number of immigrants are relying on the kindness of strangers in need while fleeing violence and poverty. But this kind of migratory logic is not possible in the interests of capital in the interests of humanity. That would be the day when the rich and powerful nations of the world met in Cleveland to decide how to allocate their scarce finite resources.That is, how to allocate scarce finite resources in ways that are not dependent on the exploitation of labour and which will yield economic benefits for the owners of the means of production but also for the owners of the land and the corporations that build the infrastructure on which the surplus flows. The question here is not whether technology is a solution to a problem of scarcity, but whether the problems that arise from its use are problems that can</text>
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between immigrant movements because the different kinds of profiling and surveillance that are being done in the United States are structurally related. And finally, although new immigrants may be arriving in waves, it is important to note that in the past few years, there has been a fundamental reorienting of migration flows away from Europe and towards the United States. This is evident in the number of refugees that are arriving in the current crisis, which is primarily caused by conflicts in the Middle East. And while these movements may have their roots in the social, economic and political conditions of the 1960s and 1970s in the United States, they are also heavily dependent on the advent of social media and blogging.The community of online activists that emerged in the 1990s is making a difference. The power of the web has spread globally, and in many ways, it is the most malleable of all the vectors. But there are persistent forms of power that are fragile, and it is these that are continuously being challenged on multiple</text>
    <text>machine learning experiments) that harness the power of crowdsourcing to identify, classify, and categorise large amounts of data, and to do so in real-time, using machine learning and big data. These efforts are part of a global movement to democratise data gathering and utilise it to make everyday practices more open and transparent.Many of us in the field see the potential of this kind of connectedness. But there remains a crucial disconnect between the people who are coming to the fore and the people who are actually managing the data. The former are trained professionals who possess technical know-how and the latter are people who were born and grew up in the United States or have Americanised parentage. In the case of new immigrants, for example, the divide between those who came through the legal and those who did not is still very much present. But there are important differences as well. For one, new immigrants face different kinds of profiling and surveillance. For another, there is a much greater need for solidarity between the movements seeking asylum and the movements for social and political change, due to the massive influx of migrants in recent years. Finally, there is the question of sovereignty. In the current period, there is a question of whether or not the authorities in Istanbul are responding to the will of the people, and if they are, how this affects the future of the city. In an ideal world, the answer to each of these questions would be a simple yes. But as we all know, no matter how well intentioned the authorities are, the people always end up being the ones who are denied what they want.So while the biennale has undoubtedly entered into a new format – increasing numbers of artists, curators and other curators flock to the city to explore its exotic neighbourhoods, partake in its festivals and indulge in its spectacular architecture – it is important to pause and reflect on the historical context of the event. The demand for an ever-expanding biennale is immense. To meet this</text>
  </text>
  <text>
    prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model.
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. These included many from the artistic ranks of both the major artistic tendencies (e.g., Pollock, Van Gogh, Surrealists), as well as artists who had previously worked in the social sciences but were less overtly social scientists, among them Martha Hervey, Carol Becker, Bernard Saltzman, Maria Hlavajova, and many more. It is important to note that these were not popular or avant garde artists, and their social/cultural orientations were often overtly political. 	[1] John Berger, Société experimentaliste, 1951, Paris. Translated by Graham Tipuric, ‘Potlatch and the Inca Question’, in Recent Advances in Sociology, Vol. 19, No. 1, Spring, 1951, p.385. [2] Gareth White, ‘The Art of Not Being Governed: Participatory Art as Autonomy’, Speech delivered at the</text>
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. The term ‘West Bengal Artusi’ was coined to describe this new medium of cultural production emerging out of the financial hub of Bengaluru.[3] The introduction of artists from the East that came as part of the ‘West Bengal Artusi’ project, however, was not confined to artists from the West. Artists from the East were brought into the fold through performances in cultural institutions in the East, as well as through the establishment of joint-stock companies. 	The new curatorial approach to art and culture emerged at a pivotal point in the history of the region. The end of the war in 1914 opened new opportunities for artistic and curatorial exploration in the region, and the beginning of the 1920s saw a new artistic and curatorial policy taken by the British East India Company (BEIC) in an attempt to reanimate the dead and usher in a new era of national glory. The East India Company commissioned a series of paintings by a range of artists,</text>
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. These included many from the likes of Andy Warhol, Goya, Debord, to Maria Hlavajova and Peter Osborne, among many others. However, it is important to note that all of these artists were operating in their own localities within this larger cultural context. While they may have had a personal connection to the particular work they produced, their involvement in the creation of this art was much more complex and nuanced. 	As a result of this new curatorial approach, much of what we would consider contemporary art today fails to take into account the complex social, cultural and political context in which art was originally produced. This lack of sensitivity to cultural difference and this lack of ability to understand how art was made today is indicative of a larger trend, as well as a symptom of a more complex but also more visible problem: avant-garde culture is no longer the dominant form of cultural consumption in the West. Avant-garde culture is still a core belief and feature</text>
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. In addition to the usual curatorial demands, this required that artists actively participate in a new form of art-developmental model that connected contemporary art to a future in which conflict zones would no longer exist. The curators of the new curatorial model were instructed to engage with what might possibly become a future conflict zone in an engaging, sometimes critical fashion. 	Artists were encouraged to participate in this new model of art-development through the use of futures – fictional or imaginary – as a media system for representing possible outcomes of various scenarios. The media system was to produce what Sculpture critic Peter Schjeldahl refers to as ‘false consciousness’ in the form of paintings, sculptures and works of architecture.[3] Schjeldahl defines false consciousness as follows: 	When we ingest a substance, divination comes to mind. We picture things differently, of course. A jinn is a demon, or monstrous figure, who embodies evil in a monstrous form. A</text>
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. These included not only composers and artists from the West, but also artists from the East, as well as artists from other parts of the world. 	While not everyone brought their ideas of the future art world with them when they relocated to the new world, many artists did bring their creative approaches to the problem of urbanisation and proliferation with them. 	The curatorial shift towards a behavioral science of cultural design came as a consequence of a few key events in the late 1940s and early 1950s, when a new curatorial mentality was introduced in London under the leadership of Sir Peter Blake, who promoted a new curatorial style and theme through which curatorial works increasingly addressed social and political concerns.[3] One of these was the publication of an American artist’s book entitled Social Practice: A Primer in the philosophy of art and contemporary social practice. Blake was a proponent of a dialectical relationship between art and social practice, in which the artist and audience were active agents in</text>
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. These included Mark Jacobs, Jennifer Coontz, Pam Stenner, Ronnie Wood and others. Despite the fact that their work often addresses social issues, such as poverty and homelessness, these artists usually bring a humorous or satirical spin to their proposals. Jacobs, for one, utilised the Arts and Cultural Curriculum as a vehicle to address serious social issues. His proposal for a new series of installations at the San Francisco Museum of Modern Art was a good example of this. These artists were brought into the fold through a combination of connections made during the Cultural Curriculum exchange. 	[1] See http://www.biennaleofsydney.org/files/biennaleofsydney2017/art/biennale_ofsydney_2017_1105x390.JPG. Also see http://www.biennaleofsydney.org/files/biennaleofsydney2017/art/bi</text>
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. These included many from the avant-garde tradition, as well as composers, dancers, paintingists and architects. Some were drawn from the curatorial staff, while others were hired by the artists to develop their projects independently. These artists were not only given an independent voice, but also the support of the curatorial department in creating this independent voice. 	The curatorial department also gradually integrated these artists into its artistic and curatorial repertoire, creating a more integrated artistic and curatorial experience for the public. This was done through the development of public programmes, which included the provision of resources, including funding, for the artists to undertake projects across the city, as well as for the development of artist-run associations and citizen art projects across the city. 	[3] As a result of this process of public programmes and artist-run publics, the city came to represent a critical mass of citizens, citizens with a collective voice and a shared responsibility. This mass was largely</text>
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. These included not only composers, painters and artists, but also architects, corporate executives and political leaders. All were expected to contribute something to the new art pot, which would provide the final touches before the pot was placed on the market. 	The curators assigned to this part of the project were divided into three groups: the Hierarchy of Performing Arts (19 members), the Public Programme (including members of the Royal Academy of Arts), and the Arts Council. All three were expected to contribute something to the public programme, although the public programme was expected to grow independently of the art pot. 	The Hierarchy of Performing Arts (19 members), the Public Programme (including members of the Royal Academy of Arts), and the Arts Council were given equal access to the art pot. However, because of their organisational skills and institutional knowledge, the members of the Arts Council were able to contribute significantly to the development of the aesthetic experience of the public programme. This was particularly the</text>
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. As early as the 1920s, the Varanasi Biennale attracted artists from all over the world, and the introduction of such artists as Wittgenstein and Meehan Murray signaled a shift in the curatorial priorities of the biennale from documenting real cultural activity to documenting artists’ cultural activities. The introduction of such artists as these signaled a shift in the curatorial priorities of the biennale from documenting real cultural activity to documenting artists’ cultural activities. However, the biennale didn’t stop there. As cultural theorists Gregory Ulmer and Lynn Tolman point out, the introduction of a new art form (such as painting or sculpture) into a larger context is a type of cultural articulation, which requires the participation of artists to generate a response from an audience. Hence, while the introduction of art and modern art practices into contemporary art environments may seem minor in the scheme of things, in the larger scheme of things, these practices mark</text>
    <text>prototype for an intelligent curatorial system that augments and responds to the vast amounts of artistic and cultural recording currently taking place on a global scale. The project was originally planned for completion in 2026, however, with the end of the war in sight, a new inquisitive curatorial model was devised in order to begin work on a new form of art and culture architecture later that year. 	The new curatorial model placed art and culture in a new context through the integration of new scientific and archaeological techniques. This model incorporated a new kind of art school, one based around the archeology of human behaviour, which attempted to incorporate elements of biology, genetics and the social sciences of behaviour into contemporary art and cultural design. Art and culture were placed at the centre of this new cultural design process, and the new curatorial approach to art was one based on the behavioural sciences of human behaviour.[2] 	Artists, including those from the West, were brought into the fold of this new curatorial model. The introduction of these artists to the Tate Modern Curatorial Group and the wider contemporary artist-community raised awareness of the pressing cultural problems facing the UK at this time, and the possibility that this awareness might lead to change at the highest levels. 	[1] The Tate Modern Curatorial Group was established in 1984 and works across a broad range of disciplines including art, architecture, photography, design, public programmes, enterprise and social work. It is chaired by Sir Kenneth Clarke, who has a particular focus on art and visual culture. The group has published more than 100 books and over 2,000 articles and books, among them six volumes on the history of visual culture in the UK. The Tate Modern Curatorial Group was established in 1989 and is the only curator-in-charge of the Tate Modern. It is a division of the Tate, and its publications include the trade catalogues Academy of Art and Architecture Advertiser.  http://www.</text>
  </text>
  <text>
    subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is almost certainly not what happened with Chaucer. And yet, the idea that images could be created and exchanged across borders seems commonplace in computer science texts and tutorials. In Computer Science, Chantal Mouffe defines the concept of ‘interconnection’ as follows: ‘It is a point where two or more points meet and form a causal chain.’ If this definition is understood in this way, then computers and images really do meet in space and time – and play around with each other.’3 In computer programming, a synonym for ‘interconnection’ is ‘multiplying’ – and so, too, in human language: when two or more statements interacting in the same sentence form the same sentence, an understanding of implication is implied. The word ‘synchronisation’ is used synonymously with ‘interconnection’ in computer science texts and tutorials, but, as we have seen, there is no inherent inherent relationship</text>
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is almost certainly not what the ancient Egyptians had in mind when they invented the machine. Images are powerful because they are recognisable, and images are recognisable precisely because they are re-created and reconfigured each time they are viewed. And images are powerful precisely because they are re-purposed: each image contains a weight of meaning and history and symbolism that is both traceable and absent in the original image. So images not only have meaning but also because they are re-purposed, exist in constant transformation. This is why images – and images only – can be counted, and why they are forever changing.In recent years, biennials and other art forms that incorporate large numbers of artists and audiences at one time have increasingly come to represent art’s excesses and perversities – its wild, over-the-top excesses, in art’s parlance. But this is primarily because the artist or curator is able to convene a large group of artists and</text>
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is rather simpler said than done. Art galleries, and the artists who exhibit there, would do well to pay more attention to the images they provide, and the work that comes out of them.Art is made possible through the infrastructures that we build, and the infrastructures that we leave behind. We can't always access the imagination of the past, but we can always empower the imagination with the tools of the future. Thus, the infrastructural renaissance is a product not of techno-utopianism, but of future modelling. Future-like apparatuses are what Sebastian Thrun calls ‘the ultimate distillation of the infinite into finite things’, and what Peter Osborne calls ‘the ultimate abstraction of space’. Thrun focuses on the ways in which things can be made to behave in ways that are both predictable (e.g., by algorithms) and totally unpredictable (e.g., by gods and giants). He develops these in his</text>
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is doubtful to achieve the same level of impact as the Machine learning employed in the above examples. Images today control much more than what is depicted on the screen; they constitute a part of a much larger web of meanings that interact and intertwine in complex ways. Images are particularly useful in that they convey a sense of continuity between past and present, as well as of movements within the imagined present. Thus an image of a train might convey a sense of continuity between 1871 and 2015, as well as of progress and progressions. The assemblage of images is an important part of the web of meanings that exist between us, and the assemblage of images that we actually are created. Yet despite its primacy in our contemporary culture, images are not so ubiquitous as in other media. The tweet is ubiquitous, yet its depiction as a collection of 140 characters or so constitutes a small part of the total number of images displayed by museums and art galleries worldwide. A tenth of all images on the internet</text>
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is not at all what happens in the real world. Rather, assemblages of images are produced and exchanged across cyberspace, and assemblages of images are objects of cultural exchange. The assemblage is made up of fragments from different images, fragments from different images, and this process is repeated ad infinitum. Each new image is created and exchanged across cyberspace in the same way that images are made up of fragments. The assemblage, as an evolving image, is constantly on the lookout for new images, and thus continually innovates its form and content. This process, which is largely invisible to us in the physical world, is also what enables us to identify images by their patterns – recognising patterns across cyberspace that emerge from the system as fragments of images.Where did the image come from? When did it come? Who made it? Who is in it? Who has the right to it?These questions are questions that circulate in the virtual space of</text>
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is not at all what the term meant in ancient or classical India. Rather, the machines that run modern-day publishing, advertising, transport and social media need to understand the images that they process to create what they refer to as ‘representations of India’s real culture, reality, beauty and substance. Retouching is an art rather than a science. It requires mastery of both the tool and the system, and so it is a kind of rebellion against the grain of modernity. But it is also a rebellion against the self.What is meant by the term in relation to images of India? It refers to images that have been digitally manipulated. This is what computer programs do. They alter images in such a way as to make them look different from the originals. So an image that is digital is one that has been altered in some way. And so an image that is retouched is an image that has been modified in some way.This kind of modification is part of what</text>
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is discouraged by the machine. It is more like assembling a human assemblage of diverse human knowledge. The assemblage can then be re-created in the image via a website or assemblage of images found in archives. This kind of creation is discouraged by the ‘design thinking’ community, although many contemporary artists and curators embrace the technological and cultural aspects of the new age. (…) Contemporary art today is based on the web and social media, and the assemblage is digitally mobile. However, the assemblage is not passive. The assemblage actively participates in the web and social media in various ways: it produces and contributes to its own image (…) of the web; it participates in the perception of the web; and it participates in the construction of social relationships on the web. So the assemblage has a brain, a nervous system, and a social context. But it also has an image, an image formation mechanism that generates images, shapes perceptions</text>
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is rather beyond the pale of what the author has in mind when he/she purports to have created the image assemblage. Rather, it is the work of machines that create and emerge from such assemblages, and hence the image assemblage is an artifact of the machine’s own processing. It is true that languages – and the underlying principles that allow humans to organize and reason about them – are composed of inflected forms of the Hindu, Aramaic, Syriac and Chaldean script, as well as other scripts that are scriptural in their own right, but this is to trivialise the significance of the role that languages play in envisioning future historical trajectories, or in understanding the world as a world beyond our present form of being. If there is any truth to the notion that language can alter one’s trajectory in history, it is that ‘truth’ itself is an artifact of the ways in which words are distributed across a global language network</text>
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is rather beyond the scope of this article.Images can be bought on the marketplaces of the new ‘megastore’ type infrastructure, which is increasingly associated with the globalised globalisation of finance and industry, and which is increasingly seen as a desirable extension of the ‘utopian capitalist bubble’ that characterises contemporary capitalism. Such ‘megastores’ purchase and re-use existing images, images of shopping malls and image-heavy media, turning them into beautiful reproductions of themselves, selling them to galleries of any size, and creating a new set of images around them. Images can be retouched to produce images of any size, colour or texture, and images can be created online that perfectly capture the imagined fantasy of the retailer looking to meet new people in a new setting. All that is required is a clear set of skills and an interest in exotic animals and the exotic. The challenge then becomes to find the right set of users for the new ‘platform</text>
    <text>subsequent iterative processing by machines] is a generalisation of the idea that underpins [the machine’s] 'intelligence' – the ability to process vast amounts of data, to master new information and to anticipate future outcomes. The idea is that of a continuous feedback loop: the more data is processed, the more data is sent, the more data is realised, and the more data can be stored, the more images can be created, the more data can be analysed, the more patterns can be identified, and the more images can be purchased, the more images can be retouched, and so on.Images are powerful because they can be reconfigured and re-created at will. Assemblages of images can be created, and retouched images can be found online, and retouched images can be found in museums and art galleries. Assemblages of images can be re-purposed through computational magic – creating what might be called a ‘digital Nepalese’ – although this is rather beyond the capabilities of most people at the time. Most people would probably do well to becoming artists in order to utilise their artistic talents like this.Images can be bought – and artists have always been artists – but the real art comes from doing things that are not immediately apparent. For instance, the Nepalese painting ‘The Laughing Snake’ is a direct quote from Simone Weil’s book Animals for Show and Pleasure Island Farm, in which Weil speaks of the time that she, as a Nepalese artist, spent in a remote part of the Himalayas with Tibetan Buddhist monks. The picture above is a fragment from that book, with the Nepalese landscape in bright red and the Tibetan monasteries in dark blues. Despite the apparent simplicity of the image, the Tibetan monks who lived among us are clearly not smiling. The image has been altered to show us the animal in a different light.Images can be bought – and artists have always</text>
  </text>
</AIcurator>
