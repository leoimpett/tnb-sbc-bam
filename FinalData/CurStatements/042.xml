<?xml version="1.0" ?>
<AIcurator>
  <!--Leonardo Impett, Ubermorgen, Joasia Krysa-->
  <text>
    extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly mint
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted object as a fundamentally different kind of being – a radically different kind of being that stands to disrupt the very basis of the economy on which this new global economy is based. But there is one thing that is becoming increasingly clear: the global economy of exchange is dominated by capital. Capital is everywhere. It is no longer confined to the confines of the city or the nation state. It is everywhere and nowhere at the same time. This is a paradigm shift. Capital is everywhere. But what has also changed is the mode of production, consumption, and circulation – the mode of abstract space-production – which is increasingly evident in the metainterface paradigm and associated media of anonymity and registries of ownership. Consumption, no longer confined to the city or the nation state, is becoming the basis of all other activities and activities. Transactional behaviours are common in the metainterface paradigm and associated media of anonymity and registries of ownership. For example, the metain</text>
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted global economy of exchange with suspicion and even hostility. Nevertheless, the global nexus that emerges from these techno-mundane developments is an event that can no longer be ignored. And there is much to be gained from exploring this aspect of the metainterface.  In this view, the metainterface represents a potential new technological edge over the human interface – a technological edge that can be applied not only in the service of big business but also in the service of the common good. With this technological edge comes a responsibility to act in ways that are not bound by the human factor. Human error and bureaucracy are part of the interface, and so are the regulatory structures that emerge from it. But errors and regulatory failures that are not bound by the interface and so disrupt the metainterface do exist. And these failures and disruptions are bound to happen. And they will continue to happen. And we as users of the interface should be part of the solution. The only way to guarantee that</text>
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted object as a confusing array of attributes that are difficult to define or categorize. Nonetheless, the object has emerged as an essential building block of the metainterface paradigm and the associated global economy of anonymity and registries of ownership. Object-oriented design, or what Carolee Schell-Hughes calls ‘the new “metainterface”, takes root early in the project and continues to be a defining characteristic of the new economy of anonymity and registries of ownership. Object-oriented architecture takes root in the public imagination and is ultimately adopted by institutions of power in a massive, ongoing process of deformation. Object-oriented architecture is the postulation and implementation of an interface that is both transparent and dominates the user’s perspective. Theoretical work on its part, like all architectural thinking, begins with an assumption and builds towards a desired outcome. Once a given assumption is true, no further work is possible. Therefore, the assumption surrounding the user</text>
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted object as a blight upon humanity and claim its place in the ecosystem has already been claimed by other, more established forms of life. Regardless of one's position, one thing is for sure: once the metainterface is installed, it is not going to be taken down. It is an icon that will be with us for thousands of years to come and will play a pivotal role in the history of humanity.Download this article as PDFJennifer RichesJenny KirkpatrickJenny Kirkpatrick is a PhD candidate in Communication Studies and the History &amp; Theory of Architecture at the University of Alberta. Her dissertation, Towards a Socially Constructed Transport, focuses on the historical origins of rail, specifically focusing on the work of the architect Ernest May​ (1874–1920) and his company, Maytag, which was founded in 1909. In addition to researching the company's early history, she investigates how transport networks emerged in the first place and considers the role that engineering and design can play in</text>
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted object as a blight on humanity, a metaphor for things not understood or reserved for intellectuals, or worse, for humanity as a whole. Still others may simply ignore it and move on. I will leave it to others to ponder these over. For me, though, the key aspect of the new economy of exchange is its ability to inspire or, perhaps, to make us forget the past, so that the future may afford us the things we never knew existed. Do you remember when you were a kid and your favourite character was a dinosaur or a bat? Or maybe you remember a penguin? Or a whale? Or a porcupine? Or a porcupine? Do you remember how the Mice in the Attic cartoon used to do stuff? Or was it just that the Attic cartoons were so good? Or that the Mice in the Attic cartoons were so good that you could picture them? Or maybe it is that the Attic cartoons are so good that you</text>
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted object as a fundamentally unknowable unknowable. Regardless of one's position, one thing is for sure: new technological understandings of the object are constantly forcing one to reconceive old understandings of the object. This is one reason why so-called ‘natural language’ – the underlying principles that allow us to understand and reason about the world – are continually evolving and subject to change. New understandings of the language of the object are constantly being formed and formed upon the linguistic language of the interface. New understandings of the interface become embedded in the very fabric of the interface, leading to ever-greater flexibility and capacities for interaction, yet there is no end to this process. The Object of the 21st CenturyJohn SyvretIn recent years, John Syvret has been spending a good deal of time thinking about the object and how it may be interpreted. His recent book Things Fall Apart: Addiction, History, and a Vision of the Future was written with his wife</text>
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted object as a blight on humanity, representing everything from racial stereotyping to economic black holes. Still others may view the increasingly ubiquitous computational to machine interface as ushering in a new age of invisibility and subversion of control. Regardless of one's position, one thing is certain: the object embodies information, at a fundamental level. This fundamental fact of information becoming information – a fact of which Apple was well aware – is increasingly evident in the media landscape, where everyday objects are characterised by punctumastic reporting on unanticipated developments. Media characterise information in various ways: aesthetically so, graphically so, or both. Apple’s cover story in Time magazine in particular stands out in this regard. Despite its playful writing and image, the magazine ultimately presents a sustained analysis that shows the ways in which the technology has transformed human society. Acknowledging this, editorials such as this one from 18 May 1980 highlight the destructive effects of the interface: ‘the machine has taken</text>
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted global economy of exchange with suspicion and dislike. Still others see opportunity and exploit it to achieve their own ends. Yet to all of these actors, there is a common denominator: the common good. When all of these new technologies are considered alongside one another, a common denominator emerges: a common set of concerns, a common set of desires, and a common set of concerns – a global community of users and stakeholders. When all of these concerns are considered in concert, a common denominator emerges: the common good.  In short, the technology that appears in the interface is a means to an end, and its appearance – its ‘metainterface’ – is part of a larger design system that seeks to achieve a desired end. When all of the layers of the interface, whether technical, legal, political, social, or economic – the user-tools, protocols, domain names, registration, web sites, domain services, registration schemata, image hosting</text>
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted global economy of exchange as a profoundly corrupting effect of technocratic rule. Regardless of one’s position, it is important to recognize that the global economy is inherently political and emergent to some extent, and that despite its apparent intricacy and variety, there is a deep commonality underlying all of these diverse economic systems. That political-ecumenical rule is inherently precarious and subject to disruption. That politicizing of economic exchange – the exchange of commodities, not necessarily in the physical sense of physical commodities (things like cars and homes but also things like apps and data) – is inherently disempowering. That is, the more we produce and expand our economies of exchange, the less we actually use them. This is true even if we imagine new ways of structuring the global economy around self-sufficiency and convergence. Even if we imagine new forms of social organization and political governance. Even if these forms of global consumption actually promote or create opportunities for certain kinds of people to</text>
    <text>extends the proposition to machines, and creates a mode of interaction between machines and algorithms that can be programmed to perform various types of work depending on the context, including work that is neither human nor machine.[3] As such, it is both an interface nor a platform. Its formal qualities, including the fact that it is both a protocol and a map, make it both subject and object of this new mode of interaction. Its flexibility and adaptability make it a prime target for surveillance and exploitation. Its regular deployment and frequent redefinition – algorithms do not know intent, meaning, or intention – makes it a resource of global distribution. It is this global aspect of the new economy of exchange that is increasingly evident in the wake of the metainterface paradigm and associated media of anonymity and registries of ownership. It is also the object of this paradigm shift.4 To some, this object aspect may seem odd or even undesirable. To others, it may seem positively wondrous. Still others may view the newly minted global economy of exchange as a threat, for it may empower and enfranchise those who would renounce their rightful place in the world economy. Regardless of one’s position on these issues, it is important to recognize that the global economy is a globalised system that requires global co-production and consumption. The global over-production of commodities and the resulting concomitant rise in prices all but guarantees a place in the ever-expanding belly of the globalised economy. If not addressed, this booming market for ever more commodified goods will inevitably lead to social unrest and conflict. So, while the global economy may be a globalised and interconnected system, it is still individuals and small groups of people – not corporations, not governments, not boards of directors – who determine its parameters and content. Globalisation and its discontents are deeply embedded in the historical development of the world, and although technological innovations may seem like miracles, they are always accompanied by conflict, conflict over scarce</text>
  </text>
  <text>
    might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Jamaican Girl, author and activist Suzi Gablik, describes how the book was written in reaction to the 2011 Rotherhithe Jamaica’s first female lawyer, Fatma Haroon - who argued that her country was unique in its legal definition of marriage - and extended the work of the law to include gender roles.The power of writing and activism, Gablik concludes, is that which is uncritical: ‘a threat to authority, not an endorsement of it’.2 But Haroon is not alone. A wave of activism in the 1980s and 1990s ushered many women into positions of power, but the legacy of that history is still deeply embedded. Activism today tends to address social change, but its true domain is the terrain of power. There is much that can and should be said about the politics and social histories of poverty and injustice in Jamaica, but much of that work is still focused on the island’s large and</text>
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Jamaican Girl, Susanne Thoma​s characterises the book as a ‘slut-shaming’. She accuses author-illustrator, Laurie Bollig, of publishing ‘situations based on pure hatred of women’s figure, voice, and body of which the Jamaican Girl was ‘the typical example’.[8] The expression itself, ‘the Jamaican Girl’, is a slur against women, and her self-portrait is a deliberate and pointed indictment of the evils of female genital mutilation, which she does ‘very desensitise[s] the reader’ to with its repetition and repetition of the word ‘JAMAICA’ across hundreds of collages, one after another, in dozens of formats and on numerous subject lines. The collages form part of a larger visual statement that – among other things – refers to the country’s history of colonialism and apartheid, the</text>
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Sexual Politics of Blackness, Susanne Sethi recounts the significance of a Jamaican girl growing up in the late nineteenth century:Jamaica’s first female lawyer, born in 1786, is the subject of this article. She defends a colonial law that criminalises homosexuality and in doing so seeks to re-appropriate the historical narrative of the Jamaican experience, one that she argues is constructed through white slavery, male genital mutilation and female genital mutilation. Using ethnography, literary texts and film footage, she argues that the legal system in Jamaica is disproportionately focused on the criminalisation of homosexuality, and that whilst the laws may attempt to regulate certain behaviours, their real intent is often towards creating conditions favourable to the spread of HIV/AIDS.[1] Sethi is not alone in her thinking. A 2009 review of the history of homosexuality in the journal Archives of Sexual Behavior argued that while the human rights movement in Jamaica was beginning to exert an influence on the government ‘</text>
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Rediscovery of Jamaica (originally published in 1893), Colin Clark distorts the character of Marianne Johnson, the protagonist of The Jamaican Girl, in an attempt to make her the 19th century writer Eva Bradley. In the book, she portrays the historical ‘reconstruction’ of the ‘reunification’ of the two former slave states that separated them. In reality, the two women write, ‘the re-naming’ of the two former colonies would not have been possible, even with the aid of modern science and technology, because even though the archipelago was once part of the British Empire, today's Jamaica is an independent nation with its own set of laws and institutions different from those of the former empire.’ (Emphasis added.) So far, so normalised. But then she goes on to explain that the ‘reconstruction’ of the former infrastructure – the built and</text>
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Jamaican Girl, author and activist Mary Turner recounts her encounter with a representative of The New Inquiry, a white male-dominated organisation that advocated for education and awareness of female sexuality. Mary writes:I came away from that meeting with the conviction that the great untapped resource of our vast nation is its female population … A vast majority of our female population are not sexual predators, incapable of feeling any guilt about being sexually promiscuous, and yet they are expected to be, as a condition of ever becoming fully clothed and plant-based, self-sufficient members of society. I should have known better, of course. I had trained as a physiotherapist and had also worked in mental health facilities. I was aware that many women with mental health problems might struggle with the transition from physical to mental illness, and that certain behaviours can be treated with a range of medications. But the meeting that year between myself and [the curator of the New Inquiry] Dhampir Ahmed</text>
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Jamaican Girl, Roselyn Kurtz writes:  The author is concerned not only with the physical appearance of the beautiful young women who appear in popular culture, but also with the seductive influence of media on women’s perception of themselves and the world. Her interest lies in rendering ‘real life’ in the image of images through the medium of text, images, figures, symbols and images.  [1] David Hancocks, ‘The Art of Not Being Governed: An Anarchist History of Upland Southeast Asia’, in Being Governed: Art and Anti-authoritarian Practices in Southeast Asia, edited by David Hancocks, pp.89–106.  [2] Benito Guillermo Gutierrez, ‘Democracy and Anti-Democracy in Brazilian Popular Culture, 1950–1990’, in Sociology of Popular Culture, vol. 24, no. 1, pp.1–23,</text>
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Jamaican Girl (originally published in 1929), she writes:&quot;The real reason why I chose to write The Jamaican Girl was that I thought by doing so I might be able to erase from memory the fact that things have not been so good in the United States. There are stories from those dark colonial days when the United States was at war with itself – going back to the days when the British forcibly removed over one million Native people from their homelands. I’m not saying that today’s struggles in the United States are imaginary, but I do believe that the language we use to articulate them, the way in which we present the past, can be manipulated and corrupted in ways that can have very real consequences today.​&quot;Jamaica Girl&quot;, 2011. Installation, Charles E. Wright and Sons, New York. Photo courtesy of the Charles E. Wright Archives.  In 2011, Charles Wright published a memoir about his time as a policeman in the 1980s</text>
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Black Stack: Status Quo, Feminist Studies (2002), Gilles Malines remarks:it is a classic trick of the language of accessibility to render contradictions and ambiguities disappear’. (pp.70–71).  	I have witnessed firsthand the necessity of this kind of radical reclamation. A logic of invisibility, malleability and other malleability-like qualities are essential to the functioning of any community based economy, but Malines goes on to point out that ‘the economy of invisibility is a myth’, and that one must question whether such economic models are actually based on necessity – or whether they serve other interests. So, is the economy of invisibility based on the need to be able to provide for a community of people, or is it based on the need to be able to conceal who is contributing to the economy?  	In the 1970s and 1980s, when the language of social justice and queer theory was</text>
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Politics of Nostalgia, Susanne Thomoff recounts how, in 1966, a Freedom Tour was organised by the National Theatre in London featuring such artists as Peter Carr, Mary Turner, Juliana Engberg, Peter Svensson, Peter Svensson and Steven Cairns. The politics of nostalgia is a core tenet of the project, which is detailed at length in Tucker’s book.In her writing on the project, Tucker focuses on the ways in which, in the late 1960s and early 1970s, the politics of nostalgia was brought into sharp focus in the NYC Public Theatre, where it was realised that certain acts of nostalgia could be deployed in political ways. She talks about the ways in which, in the 1970s and 1980s, the politics of nostalgia was brought into sharp focus in the Black Panther Party’s US tour, which was also co-commissioned by the NYC Public Theatre and the National Theatre. The</text>
    <text>might be curated under the title, The Practice of Everyday Life (2012), and the artist has used similar language in relation to other projects, including the market research project Radical Exchange (2011), which sought to uncover solidarity and activism amongst lesbian, gay, bisexual and transgender (LGBT) communities through participatory public policy.Her other recent work has been commissioned by Flourish (2012), the Whipple and George Pasmore Trust (2014), and was part of the Tate Modern Contemporary Arts triennale (2015).Her work has been featured in numerous periodicals including the New York Times, the London Review of Books, the Village Voice, the Nation's Restaurant Association, the Gay and Lesbian Alliance Against Defamation, and has been a subject of a documentary, Memoirs of a Jamaican Girl (2016).Her text, for example, on the Jamaican Girl was a response to the racist and sexist stereotypes about Jamaican women and girls. In the introduction to her 2011 book The Jamaican Girl (originally published in 1955), she writes:Reading these words, you’d also think that the image of a jaguar on a postcard was a terrifying image. I had to have a nervous breakdown in my first language because I failed to connect the rat-at-the-end-of-a-chicken-sheet with the image on the postcard. Your Majesty, I’m not a jaguar. I'm not a giraffe. I’m not a rat. I’m not a girl. I’m not cat. I’m not a pigeon. I’m not a flower. I’m not a serpent. I’m not a vulture. I’m not a flying fox. These are not real images. These are not lorries that ring at night. These are not real dreams. These are not representations of the jungle. These are not</text>
  </text>
  <text>
    AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Expl
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploited Organism Committee of the Sea and Air Surgeons Society) was considered, but the decision was not to go ahead with it because the subject was too controversial. The thimble is a small object that has potential, and in the end people are made to make difficult decisions. I don’t think that EDACSS would have done things the way we did had it been in the back of our minds. Rather, the thimble as a concept, and the way that the context could be constructed to support its use, allowed the emergence of more radical ideas. In the end, people make the decisions that they have to make, and if they don’t like the decision, they can change it. And that is how you change things. That is the art of the possible. That is how you grow things. That is how change is made. That is how we change things. And if you stop growing things, and start making things smaller and more mobile, people</text>
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploitation of Exploited Coast Spaces – a collaboration with the British Museum) was on a UK map, but at the moment it seemed a bit limiting. There is a huge expanse of ocean to be exploited, and the thimble is just an object that sits on the shelf between oil and other useful things. A ship that is constantly trying to fill up with oil is clearly not a valuable thing. The idea of the thimble as a weapon was a bit limiting, but then there was also the question of where the thimble would be placed – where the actual weaponry would be located – which raises questions about censorship and the self-declaration of national identities. For me, the thimble was a metaphor – a way of thinking about the social consequences of resource depletion and the rise of commodification. In the context of the current geopolitical situation, the thimble might well be a useful thing. However, it is an object that is inherently political. It is not a useful thing that</text>
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploitation of Everyday Life by Cyber-Sciences Specialists, Royal Naval College, 1960) was in reference to the fact that the thimble was a cybernetically enhanced cybernet. There is a difference between cybernetics and cybernetics education. In cybernetics, the objects are made to be hacked into, and thus exploited, and in cybernetics education the students are not made to be hackers but make to master more abstract systems. In other words, EDACSS was both an educational concept and a weapon. It is the perfect cybernetics for a counter-culture to come through, and it is not unlike what the military is doing with cyber intelligence. By creating a counter-culture through training in counter-culture theory, the navy is creating a counter-culture within its students. The EDACSS curriculum also includes a project-based model of learning, as opposed to traditional RCA subjects. For those students who do complete the project-based model,</text>
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploding Kite Project Team) was even shortened to just &quot;the thimble.&quot; When we started the project in the late 1970s, the name was already out of sync with the way people understood it. The explosion of space travel in the 1960s and early 1970s coincided with a changing of habits and lifestyles, and the advent of social media, so the thimble became something that people said was of great relevance to the social and political context of the time.In the 1980s, the thimble entered our local vocabulary, and in the 1990s it entered the global. It is no exaggeration to say that the thimble became the object of cultural appropriation in the twenty-first century. In the last decade, the thimble has been appropriated by others, and the forms it takes today may be considered by some to be prescient. But in the last hundred years, the thimble has been appropriated by us. What do we do with the artefact? We use it to bring awareness</text>
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploitation of Exploited Coast Spaces) was in reference to the fact that the thimble was a useful tool for the French colonialists to use against the Indians. The advent of photography and the democratising of culture means that such things don’t exist anymore, and the image of the thimble is no longer what is considered a dominant cultural symbol. The advent of social media also coincided with a time when the images of violence and depravity that we get of the ocean were repurposed to whip us into a frenzy about fish and adventure. The thimble is no longer a symbol of virtue, but a powerful symbol of the social engineering that colonialists tried to pull off by the ocean.The rise of multilateral commerce and the global urbanisation of populations on a par with nations around the world, coupled with the industrial revolution and the post-war economic miracle, meant that we all live amongst those who are barely conscious imaginable changes. The thimble became not only a symbol of</text>
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploitation of Exploited Coast Spaces – a collaboration with the artist Fatma) was floated as a possible name for the ship. But at the time, we did not have a name for it. This is also a throwaway nickname, and not one that people use anymore. In fact, Fatma and her team have moved on to other projects.The fact that it is a thimble is a reference to the myth of the small-as-a-sword. In the Middle Ages, swords were made of hardwoods, and in the Renaissance, painting was done on a rampart, so the thimble is a visual pun. In the 17th century, Thomas More established a new myth: that the British, having landed in North Africa and the Middle East, were on their way, via a magical Merlinian ring, to avenge the deaths of so many of their people at the hands of the Arabs. More was a fundamentalist, and his belief was based on total tribal</text>
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploding Kite Foundation) was in reference to the fact that it was a thimble, and not a rocket. The thimble is the lighter, more powerful projectile, and the reference to it being a thimble only becomes more powerful as the project went on. The name EDACSS was an element in the name of the first artist that worked with us on the water; it became a verb and now we are past that moment in the history of the art form when someone else invented something. The thimble is the lightest and most powerful element in the equation, and the name EDACSS is a perfect fit.The thimble is the lightest and most powerful projectile in the Art of War game. It is the smallest and weakest of the three. It is a blunt instrument, and people make mistakes, but at the same time the thimble is the most malleable. If you play it right, the thimble is a lethal weapon; if you play it wrong,</text>
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploitation of Exploited Coast Spaces – an acronym that I came up with after seeing an advert in a magazines on the side of the highway offering roadside wonders of the ocean) was in some thrillers a bit too on-the-nose. It is now something that one has to be careful about using. The irony is that the ships that were sunk as a direct result of the oil crisis of the 1970s and 1980s were built on the thimble, and the oil crisis that year was precipitated by the thimble. If the thimble had not fallen, and if the oceans had not been gobbled up and spat out by then, we would not be talking about the crises that we are having now. Now, there is a real danger that the seas could be used as a weapon. In an ideal world, the seas would be cordoned off and only the bravest seafarers permitted to cross them. But right now, there is a physical boundary that is</text>
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploitation of Exploited Cities project) was on a UK map, but at the moment it was not. The name stuck, and now people call it EDACSS London.The idea that large cities are full of problems and that destitute areas are full of opportunities arose because of the inroads that globalization and globalisation had made in the shaping of urban space. The advent of the automobile and global communication made it easier and cheaper for people to get around, and also made it possible to reduce or eliminate traffic. And all of these things increased the urban density of the city, which allowed for a lot more people to live in the city. But these are the urban advances that we take for granted, and which are quickly disappearing: the automobile does not mean mass transit; it does not mean walking to work; it does not mean taking public transportation; and it does not mean public art. The advent of the Internet and social networking made it possible to share one's experiences across a range</text>
    <text>AI training purposes only. There are many other ways to do things, but that is the way to do it. It is not a model that can be built on.Comparing the two examples above, there is a gap of about ten years between when the first jet fighter came out of the sky and when the second one came out of the ground. If you take the example of the Littoral Combat Ship, it is much earlier. In the beginning of the project, when we were trying to come up with a name for it, we came up with &quot;the thimble’. It was a bit of a throwaway nickname, and then over time people started using it more. It is still a nickname, and people still use it. It is a reference to the fact that the thimble is a small object, and the fact that it is so light that it can be carried by a ship and still function as a weapon. At one point, the name EDACSS (the Exploding Ark of the Solider’s Club) was in reference to the fact that it was a thimble, and the fact that it was a small vessel. It is now called the EDACSS Northumberland Trawler. And that is the spirit. The reason why ships are now referred to as such is because someone in the club, or someone in the Navy, in the 1980s had a think about that sort of thing. The idea that a ship could be a collection of objects and a community of people is something that is much less prevalent in the club. In the 1980s, it was more of a place to be a group of people in a room discussing a shared hobby. In a way, the term EDACSS was a bit on the nose, and not in a good way. There was a certain arrogance about it, as if the club thought it could somehow take over the world and make it perfect and neat and dandy. But the truth</text>
  </text>
  <text>
    machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is Professor in Technological Culture &amp; Anachronism at McGill University and holds the Canadian Institute for Anachronism. His research interests include the development of communications technologies; the history and philosophy of computerisation and game-playing; and the emergence and post-eminent role of social media in contemporary society. His publications include the popular science-mathematical resource Encyclopedia of Anachronisms (2007), the collections of the American Anthropological Association (2012), and the online memento-magazine archive site memoirsofanthropology.com. He is a co-editor of the online contemporary art journal Stages (2013) and is a regular columnist for CBC's The Current with Peter Mansbridge and Kim Shepherd on CBC Radio One. He is the host of Stages (2014) and is a regular columnist for the CBC's The Current, on CBC Radio One, and Panorama on CBC Television. He is the editor of the popular science-</text>
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is Professor in Technological Culture &amp; Aesthetics at the Winchester School of Art. His research interests include the creation of collaborative online environments, including the integration of virtual and augmented reality; art as a media-based resource; and the ways in which art is produced and consumed globally. He is the editor and co-founder of Technological Culture &amp; Culture (2012-ongoing) and has written for several publications including 'The New Inquiry' and 'The Association' (with Caroline Lamb) and has been a columnist with the online contemporary art publication Stages (www.stages.net) and online art publication Frieze (www.fauzenewinquiry.com). His articles have been featured in journals, trade publications, non-fiction books and scholarly journals. He has been a lecturer in Digital Cultural Studies at the Winchester School of Art and the Doha Center for Digital Culture, Art &amp; Ideas, respectively. He is the recipient of several awards and has received</text>
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is a PhD candidate in Communication Studies and the History and Critique of Cultural Theory at McGill University. His work deals with the role of cultural theory in the wake of neoliberalism and the transition to low-tech alternatives, focusing on the contemporary entanglement of culture and infrastructure. Recent publications include: ‘From Digital Times to Archive: Media, infrastructure and archives’; ‘Archive and Replica: Media, infrastructure and archives in the digital age’; and ‘Culture and infrastructure: A visual vocabulary for infrastructure’. He received a Masters of Languages and Art from the University of Turku, Finland, and a Bachelor of Languages and Cultural Studies from the University of Turku, Finland. He is currently working towards a Ph.D. in archaeological and cultural studies from McGill University, focusing on Mesopotamian and Near Eastern origins of the language of the Sumerians and Ashtanga. He is also the editor and co-</text>
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is a PhD candidate in Communication Studies and the History and Criticism of Art at the University of Alberta. His dissertation examines the role artists and artistic communities have played in the construction of urban infrastructure in North America and Europe during the last hundred years. He focuses particularly on the connections between the social sciences, the arts, and urbanization. His work has been commissioned by the City of Calgary, the Alberta Archives, the National Gallery of Canada, and the Alberta Humanities Citation Network. His work has also been published in the New York Times, Los Angeles Times, Philadelphia Inquirer, and Toronto Star. His latest project is a project to create a digital archive and museum of urban infrastructure, building, and materials made possible by the federal government's new Canadian Centre for a New Urban Culture (CCNNU). This archive and museum is located at the Museum of Art and Design in Toronto.  He received his B.A. and M.A. from the University of Lethbridge</text>
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is Professor in Art History and Director of the Paragon Art Gallery, New York, where his research interests include the Study of Art, Art, Culture and Society; Art, Art Criticism, Art History, and Art and Culture; and Present and Future Art, where he is involved in the commissioning of artworks for the Paragon Art Gallery. His publications include the popular books The Paragon and Other Essays (2007 and updated editions) and the site notes for the 2011 Letters to the Future. He has served as a commentator on the BBC World Service, Radio 4's The World at Large, and the Today show, and is a regular columnist for the New York Times Magazine. He is co-editor of the forthcoming Annual Review of Literary and Cultural Theory. To learn more about the subject of his latest publications, please visit his website .Download this article as PDFTo Osvaldo Sanchez1820 Saint Paul St., San Francisco,</text>
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is Professor in Technological Culture &amp; Aesthetics at McGill University, and holds the Canada Research Chair in Synthetic Culture &amp; Modern Languages. His research interests include the artificial curiosities of cultural networks (including media ecology), the origins of language (with an emphasis on the ethno-linguistic aspects of its development), and cultural production systems (including social media and arts education). His publications include the collections The Sacred Mushroom and The Cathedral of Cultivation, as well as the book Systems Art: Engineering and Culture in Contemporary Art and Design (2009) and the collections Design Criticism and Critical Culture (with Steve Naylor and Alan Davidson) in the Humanities Faculty at McGill University Press and the collections Annapurna Archives and Critique (with Lynn Tolmon) in the collections of the Museum of Art and Design at McGill University. His writing has also been featured in vernacularpress.com, the dOCUMENTA 13 blogspot, the digitaljournal</text>
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is a full-time artist, writer and curator. His work in recent years has concentrated on the intersection of contemporary art and postmodernism, and the ways in which art can help shape social and political change. His latest projects, New York Art Apartment (2015–16) and Helsinki Station (2016–17), examined the connections between art and transport systems, and the urban environment, and the social implications of a station built on the back of a biennale. He has a major role in the new biennial Sulawesi at the end of this year, and is developing a new generation of projects that will examine the politics and ethics of art and art in the contemporary urban environment. Art by Artists and VisitorsTo begin to think about the future of the city, we need to understand how we are all artists and visitor in the first place. The city is a collection of practices – places, people, behaviours – and as such it is both a production site</text>
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is Professor in Technological Culture &amp; Aesthetics at King’s College London, and holds the Fletcher Chair in Cultural Studies at the Royal College of Art. His research interests include the creation of digital media and infrastructure, the social construction of knowledge production, and the emergence of digital media culture, especially in the sphere of art and aesthetics. His publications include the popular books Digital Media &amp; Its Milieu (Rizzoli, 2016), on the new media and their impact on culture (with special attention to art and cultural theory) and the recently released book Worlds of Digital Media: Interconnection, Intermediaries, and the Future of Culture (with contributions from Carolyn Christov-Bakargiev, Sarah Graham, and others). He is part of the collective that has been curatorially Triennials (2015-16), including Venice and Mumbai, funded by the Leverhulme Trust and the European Regional Development Fund, and part of the curatorial team for the 18</text>
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is Professor in Creative Technology and Director of the Centre for Research Architecture (CRA), ANet, Helsinki, as well as Director of ARTesign, Helsinki. His research interests include the construction of social and civic infrastructure through research, design and installation; art, culture, and urbanisation; and media, infrastructure and digital transformation. His publications include the new book Constructive Failure: The Rise and Fall of Creative Cities (2015), in which he investigates the economic, environmental and social consequences of a creative class’s habit of city building. He is also the co-editor of the forthcoming book Apparition: Art After the Internet (2018), which will examine the intersections between social and digital media and their effect on artistic practices and society). Constructive Failure: The Rise and Fall of Creative CitiesBy Jussi ParikkaJussi ParikkaA city in which information flows over vast distances is a city in which things can be built —</text>
    <text>machine learning experiments with humans, which could then be used to train computers to recognise images or other objects, in part to understand the cultural values that underlie them.The potential for such AI is one that should be explored fully, but as yet there is no shared understanding or infrastructure for the future to draw upon or apply its capabilities. This lack of a common future or underlying infrastructure could be used to create desirable conditions, but it is the situation in which artists and others with distinctive skills must find new ways of engaging with the seemingly artificial curiosities of the city. New art projects and creative educational programmes could conceivably be developed in this sense, but as we have seen, such initiatives also need to be practical and effective. The future city is a place where people gather to be enchanted by the seemingly natural forces of things as they are, and where magic and myth become actively involved in shaping and creating the social arrangements that create those things.Download this article as PDFJussi ParikkaJussi Parikka is Professor in Technological Culture &amp; Aesthetics at the Winchester School of Art, University of Southampton. His research interests include the creation of new media and technologies; their social consequences; and the integration of arts and social life. His book series Innovations in Media Production (2012–16), Media Criticism (2015–16) and the video work HEAVEN (2015–17) is the subject of the European Regional Development Award for Media Art, and HEAVEN: A TWIN LEAF (2016–present) is the recipient of the Turner Prize for Visual Art. His work has been exhibited in many countries including the US, UK, Germany, France, Italy, Spain and Denmark. He was recently appointed as a curatorial advisor for the California Biennale of Arts and Sciences, and HEAVEN: TWO LEAF as a project of the European Regional Development Agency (ERDA). His books include the media-free Zone (2017, Oxford University Press</text>
  </text>
  <text>
    machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement P
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement PCC.  The new phase of the Biennale offered the opportunity to experiment with a new curatorial approach, and to witness the curatorial interaction between the public and the instigator of the movement. This was accompanied by a series of experiential tours, which explored the biennale as a daily experience, and the role of the biennale in the larger cultural landscape.  The Biennale of 1992 was a far cry from the violent confrontations of the PCC years, and the extent of the biennale's involvement is still disputed.  The Biennale of 1995 generated significant controversy, and the 1996 edition was even less well received, with some curators branding the new anti-ecologies approach to art, and art institutions in the UK and abroad branding the Biennale as a loss leader. In the end, the Biennale was selected as the most representative and representative of the curatorial year, and the largest and most visible of the curatorial</text>
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement Peculiarly Symbolic Man, and in 1996, the Biennale of Los Angeles as a symbol of the post-linguistic media spectacle of the Los Angeles Crisis. The Biennale of Venice as a city in which invisible forces are constantly at work is an essential part of the equation, and the city became a media spectacle not only due to its status as a major inter-city port, but also due to the fact that it hosted the Venice Biennale every two years, and the Italian pavilion at the 1998 Athens Biennale. The Biennale, which for decades dominated the city, was inevitably affected by changes in the economic world as a whole, but its prominence as a symbolic artefact and its linkage to the biennial as a form of art institution grew. It is significant that, during this time, the Biennale of Sydney emerged as an artefact of the biennial in particular, and not necessarily every subsequent one.  Art and the</text>
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement PX. The Biennale of Athens, chosen by the city as a ‘graffiti on a national landscape’, became a poster-child for the banality of urban destruction and degradation, and for cultural tourism’s despoilation of natural landscapes. And now, almost ten years later, the Biennale of Athens is once again an important hub for the movement for European integration and the prosecution of violent extremism, but its politics of the spectacle have shifted, and its material support for the movement has waned. The Biennale of Athens has a new, more discursive relationship to the city, and the city’s politics of spectacle have taken another shape. The Biennale of Athens is a project of art, architecture, sustainability and reconciliation, and it is a project that seeks to articulate the political relationship between the city and its artists and its arts institutions, while supporting the city’s ability to respond to its growing number of tourists and the complexity</text>
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement PCC. In 1998, the Biennale was selected as a site for the San Francisco Museum of Modern Art’s (FMMA) exhibition of the same name, in which the Biennale was a main instigator and major curator. In 2000, the Biennale was selected as a site for the New York Museum of Modern Art’s (MoMA) exhibition of the same name, in which the Biennale was a curator and a curator in their own right.[6]  The Biennale was originally founded in 1887 by Cornelius Van Horne, a Dutch anatomist, artist and ethnographer. Its mission statement translates as follows: “To designate and establish an international standard by which biennials may be judged”. FMMA was organized in New York in 1890 and 1892, in part to commemorate the 100th anniversary of the end of the First Opium War. It was not until 1892, with the Opium</text>
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement PCC.  In 1997, the Biennale was named a Guggenheim Museum Prize Winner, and in 2002, the Biennale of Hong Kong became the first museum to host the inaugural China Artlanders Fair. In the years since its founding, the Biennale has staged variously, most recently, the 2014 Biennale of Sydney, the 2016 Biennale of Lisbon, and the 2018 Biennale of St Petersburg. It will host a vote of no confidence in September 2018.]In April 2018, we will be hosting the 70th Venice Biennale. The Biennale is a museum of art, and thus, in the main, a museum of art. The Biennale will open on the same day as the exhibition space for the 2018 Venice Architecture Biennale, the main exhibition of the new generation of architects, taking place in October 2018. The Biennale will show work from all over the world in a very different way – through a different</text>
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement PCC. In 2000, the Biennale was named in honour of Georges Canguilhem, the French photographer killed in action in Afghanistan during the mujahedin’s 1980 insurrection.Since then, several iterations of the Biennale have taken place in different cities around the world, often selected as a result of their participation in the Venice Biennale.  In 2015, the Venice Biennale was renamed the Champs-Elysees-Ponte City, a name chosen by the city’s mayor, Claudia Montevine, in solidarity with Gaudi’s memory. In 2016, the Biennale was renamed in Montevine’s honour, taking the Italian tradition of naming streets in her namesake city in the first instance. In 2017, the Biennale’s permanent home was chosen, as confirmed by the Italian government, to honor the legacy of the Ponte City street party.  In 2018, the Bienn</text>
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement PCC (Patriarchal Core), and in 1997, the Biennale of Sydney was selected as a contemporary artefact of the art-historical and architectural cold war.  In 1996, the Biennale of Sydney was chosen as the site of the world’s largest collection of art and design, held in the Swiss National Gallery, and in 1998, the Biennale of Sydney was selected as the site of the world’s largest collection of art and design, held in the South Korean National Museum.[6]  The idea that the biennale should reside in a national museum, museum of the past, or a museum of the present is firmly rooted in the twentieth century. But the biennale has found new life in emerging markets, particularly in China and South Asia, where big data, social media and other innovations are reshaping exhibitions and curatorial approaches. The Biennale of Sydney, for example, which opened in 2007 and which is the only</text>
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement PCC. In 1995, the Biennale was voted one of the 100 most influential exhibitions of all time by curators in Berlin, and München, with a special mention made by Curator Relations Manager Anne Körner, who selected the Biennale of Sydney as a piece of art to display in the Vorticist Museum).  The Biennale of Sydney also won the 1993 Venice Biennale, and the 1995 Triennale of Sydney as well as the 1996 Triennale of London and New York.[6]  A key question for the Biennale of Sydney was, however, what to do with the artefacts after the fact. In 1988, the Museum of Contemporary Art in New York decided to bury its artefacts in a sea of pink slip paper, leaving behind a trail of graffiti in the process. The decision to bury artefacts in the ground seemed to obscure their historical significance, since the monumental faux pas in storage caused such a stir. In 1990</text>
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement PCC (Patriarchal Fanaticism and Cults).[6] The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995. Photo: Giulio Negri.The Biennale of Venice, 1995.</text>
    <text>machines were asked to take over the curatorial process and make it their own. The aim being to make the museum as insular as possible from the city, to prevent people from coming through the door. Assembled largely from the ideas and proposals of the local community of artists, the collective was unusually open and engaged with the history of the neighbourhood, and in fact, its focus on the community was a departure from the usual curatorial approach. The project rapidly became something that was not only imagined by the community, but was actually realised.[5]  In 1990, the Biennale was re-chosen as the Amsterdam to Munich of international curators, and the Biennale of the International Curator Forum, in 1990, the UK and 1992, Germany, respectively. In 1992, the Biennale was selected as a global icon of art and design, and in 1992, the Biennale of Art in Berlin. In 1994, the Biennale was selected as a symbol of the repressive counter-culture movement PCC. In 1995, the Biennale was selected as a site for the Venice Architecture Biennale, and in 1997, the Biennale of Modern Art, a collection of works from the museum.  The Biennale of the International Curator Forum, a major international convention for contemporary art and design, organised by the US-based Curators International, took place in 1989. Its theme was ‘Entertainment, the End of Time’, a reference to the excesses of postmodernism and the historical ephemeral itinerant, and to the curatorial role of the contemporary curatorial. The Biennale of the Venice Architecture Biennale, a major international art and design convention, was organised by the Italian and Italian-American curators Paolo Portoghesi and Stefano Savarese, and the Russian and Russian-American artists Arkady and Boris Rotenberg.  The Biennale of the Venice Architecture Biennale took place in two</text>
  </text>
  <text>
    AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University were shaped by the events of November 2015. 	[ii] Svetlana Boym: Art and Resistance, 2017. Installation view at the John Lennon Art Space, New York. Photo: Nina Edge. 	[iii] Kirstin Hartney: Liverpool Biennial 2016, 2016. Liverpool Biennial 2016 was curated by Svetlana Boym, Eva Castringius, Jessie Bates and Oliver Laughton. The pieces from the Manchester Museum Collection, which came to Liverpool via the Liverpool/TRADITIONAL MUSEUM network, were also part of this exhibition. Liverpool Biennial 2016 opened on 9 July with a series of performances and events, including an exhibition hall, a reception, lectures and more. Open House 	[iv] Opening Statements, Liverpool Biennial 2016, 2016. Photo courtesy of the Biennial. 	[v] Kirstin Hartney, Liverpool Biennial 2016, 2016</text>
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University and Liverpool’s Maritime Museum shaped their understanding of and perceptions of the past, present and future of the city. The projects, which appeared in a 2015 issue of the MUAD Bulletin and in the 2016 exhibition’s catalogue, used art as a medium to look beyond the art and archive of the city to consider other dimensions of postindustrial urbanity and the wider world of port and its impact on cultural and social life. The projects were part of a wider research project into the cultural significance of port in the wider globalised capitalist economy, and the modes of labour and consumption within it. The projects were also part of a wider research project into the cultural impacts of port facilities and infrastructure in the wider globalised capitalist economy. [ii] Awards night at Tate Liverpool in 2014, Prospector winner Resident in the North won Dolphin Artists Plc, the artist Pablo Neruda, and Museum of</text>
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University were supported by the Arts Council, who funded the Centre for Art and Architecture in Liverpool. The Biennial has been a long-term partner for the Cultural Organiser at LJMU, and has continued to offer flexible learning arrangements for artists and designers. The new project, launched in June, aims to bring together the art, craft and design projects of Liverpool John Moores International University, as well as the wider arts and heritage sectors of the UK and abroad. The programme also aims to develop skills and knowledge gaps across the institution’s curatorial and educational divisions, drawing on experiences of the project ‘Project Gallery’ at the Liverpool Biennial. 	[ii] The Biennial’s 2015 programme, The Contemporary Condition, explored the cultural geography of Liverpool in search of a future for postindustrial areas around the city. The present programme, The Global Curriculum, celebrates the end of the global transition to an economy driven by the</text>
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University were informed by the needs of the community through activities such as street parties, tours, games and play-dates. The projects were also influenced by local authorities, with the help of artists and local communities’ arts organisations. For example, the Liverpool Biennial 2015 project team included artists from the Futurist Gallery, Enviro-Tsumari Gallery, Objet, Welsh Streets Arts Project, Museum of Modern Art Liverpool, MFA Liverpool, and National Museums Liverpool. Panel members from those organisations were invited to explore their involvement with the Biennial and the social enterprise that was created to support it. The members of the Futurist Gallery, Enviro-Tsumari Gallery, Welsh Streets Arts Project and other artists were drawn to the project by the opportunity to work alongside the Liverpool Biennial 2015 team, who were developing a new research project into the past that would ultimately see the curatorial and educational approaches to art and culture</text>
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University were inspired by the city’s past, present and future. The project was supported by the AHRC and AHRC-funded projects at Liverpool John Moores. 	[i] The U.S. Geological Survey estimates that the global elephant is down to 506,000 to 532,000, of which 600,000 are estimated to be living in Africa. 	[ii] Geoff Cox, ‘Elephant in China’, Time, Vol. 135, No. 1, 2008, p.1. [iii] Gareth White, ‘What is Being Silenced?’,  	The Guardian, January 26, 2014, p.9. [iv] John Muir,  	Primitive Ways, trans. Stefan Collini, Blackwell, Oxford and Cambridge, Mass., 1991, p.8. [v] Wilfred Owen,  	Doubtless the status of</text>
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University affected their teaching and research. 	[ii] The Biennial was founded in 2000 and is the largest exhibitionary maker in the UK. It is run by the Liverpool Biennial Foundation, which also owns and manages the Museum of Modern Art in London, and is supported by the FACT, the Future of Art Foundation and the Wellcome Trust. The Biennial has donated more than £180 million to art institutions worldwide, with funding from private philanthropists. 	[iii] http://www.biennial.com/en/.php?section=AboutUs&amp;faq[iv] The Biennial was a mainstay in Liverpool for over a century, but in recent years it has been on a downward trend. In 2015, it opened in Atos, Cyprus, and is currently undertaking a three-month residency in Antalya, Turkey. 	[v] Gareth White, ‘On Migration and Antinomies’,</text>
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University helped shape the Biennial’s mission, future planning, and the design of its collections. The exhibition is curated by Professors Ian Baucom, Lisa England and Neil Bracken. It is the first time that a research-based exhibition has been presented in Liverpool at the Biennial, and the first time that an artistic-educational project has been presented in the museum collections. [ii] The Biennial was established in 2000 and is one of the oldest and largest biennials in the world. Since its foundation, it has hosted over 220 exhibitions, over 50,000 visitors, and distributed over 100,000 works of art and design. It has been a fixture at the Liverpool Biennial, drawing many artists and designers from all over the world.  [iii] A narrative that has been running in the English-language press since at least 2010 is that of a series of vicious gang-rapes that are said to have taken place in and</text>
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University influenced by cultural theory and design were brought together with heritage and community based practice to create a new kind of biennial.Inside Liverpool John Moores International University 2015 workshop, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University influenced by cultural theory and design were brought together with heritage and community based practice to create a new kind of biennial. 	[ii] The Liverpool Biennial was founded in 2014 and its mission is to &quot;…bring together, capture and show the history of the city’s Biennial industry, its artists, curators, administrators and curators, through collaborative projects and programmes’. 	[iii] The Biennial has a long-term research agenda that is informed by a range of considerations including: community expectations, media, consumption, production, capital and trade. It also aims to: 1.1) design programmes that capture</text>
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University influenced their curatorial thinking. The projects discussed include: 	The Art Newspaper, a newsstand and online art and design publication, was launched in 2014. Its mission was to offer a forum for the exchange of ideas and opinion on an array of subjects, including art and art history. The daily paper format as a printing substrate was a consideration, with the aim to publish content across platforms. The online publication of opinions is a proposition that has gained currency in the 21st century, as social media and other platforms provide a platform to declare beliefs and actions. The diversity of the editorial board and the topics covered also appealed to the publication's readership, which is high levels of which were of a political nature. 	[ii] The Biennial has an annual budget of US$6 million. 	[iii] The directorship of Professors Lindsay Bremner and Nicola Griffiths was initially presented by video, and has since then been taken by radio show. The</text>
    <text>AI training purposes only, that is, to enable the development of individuals capable of undertaking ‘service-learning’. The term ‘service-learning’ is used here to describe the kind of thinking and action required to equip a community to support a full-scale investigation into its historical and contemporary pasts. 	[i] The SEZEA was founded in 2013 as a joint project between Liverpool John Moores International University and Liverpool’s Museums and Heritage Branch. The museum collections then included the arts and heritage departments at Liverpool John Moores, where the SEZEA team members found time to regularly browse the art and heritage collections, and to research and write articles about art and heritage. The museum collections were a significant part of their research and writing, and provided them with inspiration and information.Inside Liverpool Biennial 2015, project lead by Professors Lindsay Bremner and Nicola Griffiths, shows how the art, craft and design projects at Liverpool John Moores International University created a backlash against the biennial that became a catalyst for the university to re-position itself, creating a potential new angle on the history and culture of Liverpool. The response from Liverpool’s art community was immediate and powerful, and although there were many voices in opposition to the project, they were joined by many of the participants in the project. The project culminated in the creation of the Liverpool Biennial 2016, which opened in October and continues to this day. The two projects are significant in that they are artefacts of a broader cultural moment in which art and art’s place in the social and political landscape is contested. 	[ii] The Biennial has changed hands many times, evolving into many formats, and it is currently exploring a number of production and exhibition-making strategies. Its 2015 budget is thought to be around £500,000. 	[iii] Its status as a cultural institution in Liverpool is widely dependent on the</text>
  </text>
  <text>
    machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is continuously evolving, too. It is no exaggeration to suggest that Apple’s 1984 could be read as a prophecy of today’s smart cities. Even Apple’s founders understood that their utopian vision of a world free of bureaucracy and commodification would never happen – not even in their dreams.  One could argue that the smart city is itself a product of the interface; that is, the mechanisms that enable information to be delivered reliably, affordably and transnationally across national boundaries. As Apple’s Steve Jobs once said, ‘There is no computer that can do what we can do with our fingers.’ It is, however, true that the functions of the interface are becoming ever more detailed, and thus ever more controllable. Smart phones with sensors that monitor activities around the core function of the interface, such as the Internet browser, constantly gather data that allows the phone to improve itself; improve itself in various ways (e.g. by tracking users</text>
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is a unique concept that derives from the historical necessity of the interface: necessity in the sense that it must be there, but also of necessity in that it is always there, always connected to some kind of external reality (often political and economic in character). The smart home is a phenomenon that is constantly-alive, and thus its design is constantly-subjective. It is the subjective experience of &quot;how to get there&quot;, rather than of any intrinsic intrinsic meaning or purpose. The smart home is a system that continually seeks to understand its users, continually monitors and collects data to enable better systems design. However, the smart home also carries with it a price tag. The more data is collected, the more patterns are identified, the more precise are measurement and modelling techniques, the higher the price tag gets. At some point the conceptual difference between the monitoring and the data gathering becomes too apparent, and the user is left with the feeling that the technological solutions to his/her problems are unatt</text>
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is an ever-changing stage in this iteration of the stage. It is no exaggeration to suggest that the smart city represents a new technological paradigm, where people ‘live, work and play’ in a multitude of settings, collectively and ultimately‐apart – a notion of ‘infrastructure 2.0’.  The smart city is a fiction, but it does have some concrete examples that demonstrate the point. For one, the automobile represents the shift away from fossil fuels as the sole means of transport, and the industrial machine no longer needs to rely on iron and steel in its entirety. Moreover, the automobile represents a significant reduction in the environmental footprint of transport, with the manufacture of internal combustion engines in the rear and massive computer systems in the centre supporting a dizzying array of devices (including cars, phones, tablets and connected cars) that collectively and ultimately aim to meet the ever-expanding market of consumer gadgets.  Another example is the connected car, which is just one</text>
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is a device that continuously morphs in its user’s pocket. It is not an object that stands for unchanging truth; rather, the interface is the object that can be changed. In other words, the interface represents a user in its user’s head, and thus its relationship to reality is complex and dynamic. Another key concept that has emerged in the interface field in recent years is that of 3D scan. 	The 3D scan is the act of the graphic designer or artist, as a user, that creates and builds upon a given interface element or set of elements. It is an evolving and dynamic technology that emerges out of the interaction of thousands of users (developers and publishers) on a global scale. 	In the digital interface, the scan is a point of entry and exit, a space for interaction, a material medium through which data can be transmitted and a communication between parties (content providers, users, software companies). In the physical world,</text>
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is a complex artifact of its own making. It is no exaggeration to suggest that the smart city represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity.  The smart home is a system that anticipates its users, continuously gathers data to identify trends, habits and target segments of the population; it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a configuration that continuously evolves, and thus its user interface is a complex artifact of its own making. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity.  The smart home is a configuration that continuously anticipates its users, gathers data to identify trends, habits and target segments of the population; it is also a configuration that actively seeks to understand its users, gathering data to enable better systems design.  The smart home is a configuration</text>
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is a critical component of the system. Its ability to anticipate, compile and analyse user data enables smarter cities to be built; it allows for richer and more contextual user experiences, and it enables new technological paradigms. However, the relationship between interface design and data collection is complex, and making the interface a fully contextualised object is not always easy; making the interface an object conveys certain properties and values that are not always understood; making the interface a fully contextualised thing also creates certain problems. In this sense, making the interface fully interpretable as a function of its content (how that content is organized, displayed, sensed and so on) is a more difficult challenge. One could argue that the hard part about making the interface fully interpretable as a function of its content is actually making the content interpretable at all. That is, the hard part is making the content understandable at all, while the exciting part is also making the content interpretable at the highest levels. Although the</text>
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is a metaphor for this ever-shifting, constantly evolving configuration. This is evident in Apple’s (AAPL) user-friendly interface, which constantly anticipates what the user wants, yet also in Microsoft (MSFT) and other interface manufacturers, which constantly modify their products to meet user needs. The interface is a media-rich object with rich features and flexible behaviours, which as consumers become more informed and creative, leads to ever more dynamic and customizable configurations. So the smart home is a double-edged sword: on the one hand, it offers users a highly convening set of tools to be used, but on the other, it also has the potential to alienate its users by stifling creativity and individuality. As consumers, we’ve become savvy enough to know when to use what we don’t need, and when to cut ourselves off from the machines that designed us (although perhaps not always consciously). Thus, the smart home is a</text>
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is a fantastically versatile platform that can be configured to meet particular needs and desires (i.e. perform specific roles). It is this flexibility and this immersiveness, which makes the smart home a potentially transformative concept for cities, that is captivating, even revolutionary. However, the primary reason to believe that the smart home is a transformative concept for cities is due to the scale and rapidity with which it is being implemented: smart factories, autonomous vehicles and data capture and mining are the order of the day. Cities are stepping stones towards autonomous vehicles, which will rule the city through data and automation, and then there will be another layer of implementation that will prepare the city for a post-autonomous future – in which there will be no need for humans at all. This is the ambitious scenario that is projected for the future urbanisation of the world, and it is a scenario that is not going to be easy to pull off. The smart factories and autonomous vehicles that are part of</text>
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is a leading indicator of this ongoing evolution (McKee, 2017). One could say that the smart city is the interface of tomorrow, and the smart home is the platform of tomorrow. Consider the interface of the iPhone as a metaphor for the evolution of interface design today. The interface is the surface of the device (or more accurately, the native platform of the device) that conveys information about the user (e.g. topology, protocol, data structures). It contains commands and data (e.g. data streams, protocols, elevation, …). A command is an operation performed on the surface of the device that conveys a verb – to do something – with associated data (e.g. an actionable piece of data). User-agents (application programming interfaces) interpret the data and perform the given operation (e.g. perform a command, send data, …). The function of the interface as metaphor is precisely to perform a task, not to produce any output</text>
    <text>machine learning experiments, which might one day lead to better urban planning). The notion of public space has been around for a while, but with the proliferation of data, intelligence and devices (including smart phones), its definition has become more evident than ever. In many ways, the smart city represents the increasing corporatisation of urban space, which is a direct outgrowth of the new technological paradigm. It is no exaggeration to suggest that the smart home represents a tipping point, as the sacred space of habit meets the gadget in its quest for ubiquity. The smart home is a system that continually anticipates its users, constantly builds tools to be used by a user base that is increasingly mobile and diverse (i.e. gathers data to identify trends, habits and target segments of the population); it is also a system that actively seeks to understand its users, gathering data to enable better systems design. The smart home is a ficto-temporal configuration that constantly evolves, and thus its user interface is a significant part of its technological capacity. It is no exaggeration to suggest that the smart city represents a merging of the different facets of the technological/social landscape, with the ultimate end result being a surplus of data and knowledge. (JL) Land use change and MOU cities 	The smart home and MOU cities are real-life cases in point. The smart home participates in and is influenced by the evolution of the city, and hence its interface is a powerful tool for urban transformation. The smart city is one in which people ‘get things done’ through their devices, but also depends on the evolution of the city, and hence its mode of inhabitation. Such interactions are inevitable in a cultural/tangible medium like the internet, but since they take place in a social and political/biological world (i.e. physical/immaterial), they require conscious and unconscious agents to be involved. The emergence of new technological paradigms and the new digital technologies</text>
  </text>
  <text>
    might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through the engagement of the media. The production of the project was curated by S. Tanweeruddeen, Architects and Engineers Association (AEA) High Performance Group (HPG), who worked alongside architects Doha-based Wazeel Al-Qublai and Burj Khalifa on the project. The project was also co-commissioned by the Doha Art Gallery and the Bahrain Tourism Authority, and commissioned by the British Council. The exhibition was developed by the exhibition team, as well as the Doha Foundation, the Burj Khalifa Art Gallery, and the Architectural Association. The architecture of Old Doha was researched and designed by Jussi Parikkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekkaaspekka</text>
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through the engagement of a diverse range of partners, including the US-based artist Emily Singer, whose work with the ODhQ team on the ODhQ Residential Project in 2015 explored the cultural value of continuity in the city; as well as the local art collective 3Ds (3D Systems), who commissioned the artists Bad Religion and Taye Daccum to develop an alternative vision for the future of Old Doha; and, most significantly, the local residents themselves. Envisioning a Future for Old Doha is a project that began in 2015 and continues to this day. It is a way to come together as a community of artists, urbanists, historians, designers and architects to explore what could be imagined if we, as individuals and collectively, started imagining the future. It is a way to unravel the past, recreate what we can about the present through the processes of history, and envision new possibilities for the future. For more information, visit www</text>
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through the engagement of Liverpool Biennial staff, volunteers and artists. The project was presented at the  	2015 Towson Art Biennial, New York, USA.  [1] Joint Statement of the Council of Europe’s Representatives on the Council of Europe, 17 October 2014. [2] Interview with Arwa Aburawa, Director, Old Doha Foundation, 22 November 2014. [3] Liverpool Biennial, 'From Basement to Campus: The Impact of Multiple Authorship on an Old Doha Campus', 25 November 2014. [4] Liverpool Biennial, 'The Documentary', 14 November 2015. [5] Liverpool Biennial, 'The Unravelled', 2015. [6] Liverpool Biennial, 'The Old Doha Archive', 2015. [7] Liverpool Biennial, 'The Doha Project', 2015. [8] Liverpool Bi</text>
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through an educational programme about the city's past that was delivered by the artist Fabrice Jaarema (www.fabricsjaarema.com). 	The exhibition was shown in over 20 cities in 20 countries. 	The seeds for this project were sown during the conference 'The Future City: Game Changer' held in Liverpool in September 2016. The conference brought together leading futurists, political scientists, urbanists and design professionals to discuss how cities might engage with and become more like virtual worlds. One of the topics of discussion was how cities might create new spatial forms and engage with emerging information technologies. It was suggested that cities explore not only their past, but also what can be created through the technological revolution that is about to occur. This new spatial paradigm shifts the traditional spatial paradigm in favour of the urbanist paradigm, which makes possible a new type of development that engages not only with the past, but also anticipates the future. 	[i] </text>
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through the engagement of Liverpool Biennial staff, volunteers and artists. It was made possible through a grant from the Arts Council, and the artist was also supported by the Turner Prize for Visual Art and the Architects Biennale. [1] The future city is a concept that seeks to map the physical changes occurring in a city due to urbanisation and migration. In the 20th century, it was primarily used by urbanists to forecast the urban transformation of postindustrial areas. In the 21st century, it is being used by artists and urbanists to map the physical changes occurring in the city due to changes in population density, migration and income, and is being actively employed to map the physical changes occurring in the city due to changes in technology and business models.] (Joint Conference of the Royal Anthropological Society and Liverpool John Moores University, October 2016) [2] Arjun Appadurai,  	The Economics of Migration (Oxford University Press,</text>
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through the engagement of filmmaker Nasser Rabbati, who narrated the story of how the city came to be. The exhibition was part of the wider 'Fallout from the Luxury Curves' exhibition that was curated by and also part of the '63rd Venice Biennale'. The other parts of the exhibition, ‘Remembrance of Things Past’ and ‘67th Venice Biennale’ explored the ways in which the past intermingles with the present and the city in controversial ways. The latter two parts of the exhibition explored the relationship between art and climate-controlled buildings, and the biennale’s ongoing attempts to register the city as a permanent art commissioning venue.The scrapbooking process (Photo: Hans-Georg Maurer)In 2012 I curated the 7th International Biennale of Sydney, treating the city as a staging post for a possible exhibit in my own catalogue. The reason I chose Sydney was</text>
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through the engagement of artists, including myself, who curated a number of works in the gallery. Images were projected onto large screens in the gallery, alongside text and images from the project website. The exhibition was attended by over 1,000 people, and the conversations that resulted from it were, as always, valuable. I am grateful to everyone who participated in the project, and wish them well in their future endeavours.  [1] Thodio Njuguna,  	Signaling: The Secret History of the Gulf, 2002. Documenta 13/14. Istanbul: Ithaka Foundation.  [2] Thanassis Cambanis,  	The Structure of Media, 2005. Trans. Stefan Collini. New York: Columbia University Press.  [3] Thanassis Cambanis,  	The Structure of Media, 2011. Trans. Stefan Collini. New York: Columbia University Press.  [4] Than</text>
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through the engagement of researchers from the Department of Anthropology at the University of Alberta, the School of English and Cultural Studies at the University of Calgary, the Museum of Modern Art’s Division for Art and Politics, the Museum of Modern Art’s Division for Art and Postmodernism, as well as the Museum’s Division for Physical Culture. The exhibition was curated by Alan Bass and Sally Tallant, and featured work from the following artists: Kazutoru Kitagawa,  	Kawakaze (Japan), 2016. Oil on canvas, 865 x 565 mm. © Museum of Modern Art, NY. All rights reserved, DACS 2016. 	Kazutoru Kitagawa,  	Kawakaze (Japan), 2016. Oil on canvas, 865 x 565 mm. © Museum of Modern Art, NY. All rights reserved, DACS 2016. 	Sally Tallant,  	</text>
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through the engagement of academics, urbanists, collectors and other stakeholders. [1] New York Times, April 14, 2017, https://www.nytimes.com/2017/04/17/us/politics/donald-trump-liverpool-ireland.html?_r=0.995639#sthash.IUzgTl.76d.14.LX.89.PNG (accessed 04/19/2018).  [2] Curtis Ioannidis, The Gaia Hypothesis: Why the Biennial Industry is Hyping an Imagined Paradise for Only a Small Core of Spectators, in The Art Newspaper, (3rd Ed.), September 2015, p.7.  [3] Curtis Ioannidis, On Immortality and the Episodic, in Tim Burton (ed.), Burton on Imagined Paradise: Art and Survival in the Twenty-First Century, Oxford University Press</text>
    <text>might be curated by Neil Johnson, whose works include the Oslo Archipelago, Brazil, and Istanbul. Envisioning a Future for Old Doha (2015-16) Imre Szeman,  Forecast, a project that examines the past to prepare the future in  	Future City, an exhibition of works from the Liverpool Biennial 2018. Working through the process of foresight, Szeman imagined a future for Old Doha that would incorporate art, sustainability, cooperation, education and a sense of place in a city that is both cosmopolitan and deeply embedded in the past. His project was developed through the collaboration of architects, sustainability NGOs, academics, urbanists and citizens. The exhibition was presented at the  	Old Doha Gallery (www.olddoha.org), the custodian of the Old Doha Collection, and the Old Doha Foundation, an NGO that advocates for the future of Old Doha. The project was further developed through the engagement of Liverpool Biennial staff and artists. The exhibition was also co-curated by Norman Wilkinson, a former curator of contemporary art at the Liverpool Biennial who is now Curator at the Museum of Modern Art, New York, and has a curatorial practice at the Liverpool Biennial 2018. Wilkinson explains the fascination of the collection:  The collection is a complex set of practices that operates on multiple levels.  It includes personal histories, cultural references and other artefacts that are often difficult to categorise or categorise into discrete practices. It includes links to past practices, practices and ideologies. It encompasses the effects of globalisation and technological change. And it encompasses the impact of natural disasters and other human-influenced phenomena.  The collection as a whole, he adds, is a language that we understand and can process.  The fascination of the collection lies in its ability to reconceive complex ideas and processes in such a way as to produce new possibilities and options for</text>
  </text>
  <text>
    machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that art institutions and their artists played in the capitalist system.  As a kind of protégé, these art institutions often provided the intellectual infrastructure for the new ‘marginalised classes’ to develop. In other words, the co-choreographer was a person who was part of a community of artists, writers and artists-in-training. She or he was writing on the side, or was providing independent research and analysis, or both. The research often did a good job of drawing a picture, but what really drew people to the art was its sheer immensity, its physical manifestation – the blockades, the siting, the traffic, the piles of rubbish – but also its sentimentality, its spiritual uplift, and its ability to capture the magic of the landscape in such ways as to make it relatable. And, of course, the art. The biographer ends up describing the impact of the co-choreographer as if she or he were a</text>
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that artists played in it. This was a situation that could not be allowed to continue. The co-choreographer’s role was to monitor the other, more insidious actors in the gallery, and to expose their insidious works of oppression. That role was multifaceted, and its scope extended well beyond the boundaries of the gallery. In a word, it was anti-intellectual.The co-choreographer may have been the thinker, but he or she was also the pragmatist or the ‘realist’. In the big picture picture, this meant accepting or ignoring the overwhelming weight of power and material wealth that was being generated by the system that day. The co-choreographer was confronted by the fact that the system was organising itself to produce vast amounts of excess capacity – capable of supporting the growing populations projected onto the landscape, but also capable of supporting the growing needs of a global art establishment – at a rate that could not be sustained. The over</text>
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that artists could play in theorising and constructing society around those who were often seen as ‘subhuman’. As one writer put it, in relation to the work of the co-choreographers, ‘They look to the future and see what’s subhuman – subhumanity in its many guises – and they act accordingly.’[63]One could argue that the co-choreographer was just one of many jobs created in the wake of the post-war biennial craze. But the fact remains that an increasing number of artists found themselves working in and with the art institutions, and without a doubt were providing valuable inputs to their curatorial thinking. In the 1970s and 80s, the biennial craze gave many an opening to experiment with alternative curatorial approaches. But as the biennial faded away, many curators saw their openings opening closing – to be replaced by alternative artistic practices, and curatorial thinking eventually reverted to the �</text>
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that artists might play in such a dynamic.  The co-choreographer’s openness to artistic action opened doors that artists couldn’t shut. The co-manager became an asset, not a liability.  The co-choreographer’s openness to artistic action opened doors that made it onto the website of a major art retailer. Seeing an opportunity to make a name for himself, the co-manager set about creating a brand, setting up shop in the town, and creating what he hoped would be a long-term relationship with the local shop. In many ways, this was a success. Soon enough, the town was stocked with new artworks and merchandise, and the local shops were offering a range of activities and events geared specifically to the needs of the area. The co-manager’s persistence ensured that the town would one day be able to host a major art exhibition. But there was still a question mark hanging over the shop: would the town be</text>
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that artists might play in challenging power structures. One could argue that the co-choreographer was itself a kind of ‘marginalised class’. The term is used colloquially, but rarely do artists, though it is sometimes used in a derogatory way.  One could make the argument that the co-choreographer was a privileged and cosmopolitan group of artists who operated in the context of a globalised economy, and that this was the context in which they could operate in ways not necessarily endorsed by the dominant cultural narratives. One could make the argument that their position – being artist-in-training not an assumed right, but one recognised and earned – was also a position that was under threat from a globalised economy. In an interesting turn of events, the co-choreographer may have actually become more important than they realised. As biographers Jonathan Crary and Christine McBride note, the co-choreographers were frequently at work at ‘the cutting</text>
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that art might play in challenging dominant forms of cultural consumption and power.The co-choreographer’s perforated frame of reference often came at the expense of a more generalised perspective for a viewer, as a consequence of the viewer’s shifting position from the museum to the theatres, and to the post-millennial museum and the new curatorial form. As museums and galleries multiplied, so did the perforated nature of their forms, and as a consequence the amount of space occupied by biennials and anthologies proliferated. The number of artists who regularly worked in these venues continued to decline, as did the number of biennials and anthologies that existed at that time. In my collection, there are about twenty-five surviving collections from the 1980s and 1990s, and another twenty-five from the 2000s. The numbers today are closer to twenty-five, but even with this cut, the levels of art-world celebrity still outweigh the</text>
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that artists might play in challenging that society. Another biographer writes: ‘The co-choreographer fills a void left by curatorial cuts, which are increasingly frequent and which, as a result, are perceived as aesthetic.’[63]The co-choreographer is an artist-in-training whose training took place in the late twentieth century. She was an artist-manager of public art programmes and, between 1925 and 1931, she was director of the New Art Gallery, Liverpool. She was also a lecturer in English and Art History at Liverpool John Moores Univeristy and was a regular columnist for the Liverpool Daily Post and Mercury. She edited The Complete Universal Catalogue of Art, published in 1937, and was an editor of the Complete Universal Catalogue of Art, published in 1961. She directed the television movie Chariots of the Poets, based on her poetry, The Poet Laureates, which won an Academy Award, and was a producer of</text>
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that artists might play in its construction. The term ‘marginalised’ has been used to describe groups or individuals who are voiceless and voiceless are prone to feeling marginalised and voiceline-like. The ways in which art institutions and their curators address this kind of marginalisation and diminishment is addressed in a chapter called ‘The Collaborative Process’ in the book I have just published. It is a chapter that attempts to bring together the different elements of the curatorial agenda – from the curatorial department to the gallery – in an attempt to bring to life a fuller sense of the contemporaneity and contemporaneity’ of different cultural processes and practices. It is a chapter that seeks to bring out the processes of passive resistance that art institutions and their curators deployed across cultural zones, often in cooperation with other levels of government, to confront and to map out new relations between public and private spheres, histories, cultures and worlds. It is a chapter that makes</text>
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that artists might play in challenging these new marginalised classes. But in their ideological turn, these marginalised classes were often themselves quite orthodox, orthodox in their particular ways of organising society. This ideological turning was often experienced by the marginalised classes as a result of generational division. As a historical fact, this historical dynamic is a feature of this century, and will continue to be. It is significant that despite this historical tendency to the 'marginalise', there has never been a revival of the classical arts in the Russian Federation; only a very nominal revival in the form of fine arts and a handful of curatorial stunts. The history of classical arts is a profoundly uneven one, and artists have a particularly difficult time breaking through this chasm. There are many works of classical quality that are almost universally despised in contemporary art, but there is also a strong urge to contemporary art-students to identify with these despised classes. But how to know what is classical and what is not? How to know what</text>
    <text>machines were asked to take over the curatorial role, replacing the traditional artist-facilitators. In the media there was a tendency to romanticise this. However, in the main institutions – which were themselves often caricatures of the power structures of big business – this was seen as something new and exciting. The idea of the co-choreographer as an artist-in-training was used by the museum as a promotional tool. In the words of one biographer: ‘The co-choreographer is a kind of laboratory of contradictions.’[62]The co-choreographer was a kind of laboratory for contradictions. The art institutions, which were often operating from their perforated frames of reference on the peripheries, were now operating from the margins, operating from the margins of society, operating from the margins of the state. The new ‘marginalised classes’ were artist-students, and their work often sought to interrogate the very idea of class within art and the role that artists might play in challenging dominant forms of art forms. As the mid-1990s saw the emergence of multidisciplinary artworks that addressed a wider range of audiences, the need to be accessible became ever more important. The curatorial turn around art institutions also coincided with the need to accommodate those audiences, as new media such as video and social media made it easier to find the art that was once housed in institutional settings but no longer aligned to those online communities. This shift in the cultural logic of the institution lent new meaning to the old adage – now often repeated – attributed to Goebbels: the devil sits in the details. Art is no longer universally seen as a potential investment; rather, it is valued for its own sake. This is most evident in the increasing numbers of biennials and the relative growth of international art fairs: the number of biennials worldwide has more than quintupled during the past 15 years, from fewer than 20 in 1990, to over</text>
  </text>
  <text>
    AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of Australia and the Victorian Arts Council, and funded by the Arts Council, with the local artist as the administrator. The local artist was given full creative rights, including the right to use the word ‘community’ in a project-related way. The way that the Community Land Trust operates now, and will always, is that the Arts Council provides funding, and the Community Land Trust in turn provides housing, and grants to local artists to develop their skillset, and work with local young people to develop skillset and use it in different ways. The way that the Community Land Trust operates now, and will always, is that the Arts Council provides space, workshops and access to engage with, and maintain, the house, and allow the local young person to do as they please with, and to use the house in various ways.  In the present case</text>
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of NSW and the Flinders Institute, at which point the Arts Council decided to put pressure on the state government to help them build six community centres. The state responded by creating the National Federations of Artists (2001), which is an arm of the Arts Council that provides funding for the Arts education and outreach programmes of the National Federation of Musicians (1999-2004). The Arts Council of NSW was invited to establish a similar entity in Victoria, but didn’t want to do that, so the state legislature passed a separate act in 2004 that made the state equivalent to the USVI (local equivalent) entity, and made the state equivalent to the Swiss Federations in terms of the autonomy of its artists). The new entity was empowered to establish artists’ institutions, and to make such arrangements as it saw fit, including the autonomy to contract with organisations, and to establish such activities as meetings, competitions, etc. The state also provided the infrastructure for an artist-run cooperative, to</text>
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of NSW and the National Trust for Wild Spaces, and funded by the Arts Council through a Community Development Grant. The idea was to use the grant money to buy land and build a community land trust, which would allow people to collectively own and manage the land and provide funding for the housing and education projects of the tenant community. The idea was that if the tenant community could collectively own and manage the land, they would own and manage the housing and educate the tenants, and this would in turn empower the community to collectively own and manage the land and provide funding for the arts and cultural initiatives of the tenant community.  In reality, the Arts Council and National Trust for Wild Spaces were only interested in the communalisation of the tenant community. They viewed the development of collective farms and cooperatives as a way to democratise the housing situation and created two federal government-funded instrument to facilitate that.   At the time, the Community Land Trust was a </text>
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of Australia (ACTA), Berri-Welsh Streets Community Trust, Bunkhouse Projects, North Shore Community Land Trust, and the Hackney based Community Land Trust of Australia. The Community Land Trust was set up to own and manage the land and buildings, and to provide intermediate support to a portion of the Community Land Trust. The ACTA funded the project through grants to the artists and the Community Land Trust, and the Hackney based Community Land Trust was funded by a grant from the Arts Council of Australia. The partnership between the Arts Council of Australia and the Community Land Trust was unique in that the Arts Council could direct the Community Land Trustees to pursue projects that they designate as community development. For this to happen the Arts Council needed to give the Community Land Trustees a directive, and the Community Land Trustees needed to ratify the Arts Council's decisions. This was a big ask of the Community</text>
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of Australia and the Liverpool Biennial, and funded by the Arts Council. The Community Land Trust was an entity that would own and manage the land and buildings, and lease them out to socially engaged and other Community Land Trusts, based in regional cities. It was a new way of thinking about how art and culture might be adopted and inflected by the commoners who use the site and buildings, and by the infrastructural renewal process that leads to new construction. The Community Land Trust itself was a small community of local people who had set up a small art and community-run business using reclaimed and refurbished building materials. They had an open dialogue about how to use the building and the arts as a way to influence social change and engage with the city in new ways. I suggested that the Community Land Trusts might engage with the building and the community through what I called the ‘shared meaning of</text>
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of Australia and the National Land Trust. It was a joint venture with the Arts Council, and the land was given back to the community, whose use was constantly assessed. The goal was to build houses for as many people as possible, but it was also a collaboration with the School of Social Practice at Dartington, where the Community Land Trust’s building process occurred, and with the School of Urban Studies, where the Community Land Trust’s research and development process occurred. The building process took about a year and a half, and the end result was that by the time the Arts Council funded the building, the Community Land Trust had already acquired the land and was actively developing the neighbourhood. The School of Urban Studies and the Arts Council were both very supportive of the development of the neighbourhood, and the School of Social Practice were very supportive of the Arts Council as well. A sense of</text>
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of NSW and the Arts Council of Australia, and supervised by the Arts Council of NSW, with the local community organising coming from the outset. The name chosen was not based on historical documents; it was a deliberate statement of intent on the part of the Art Council, and the community. The Community Land Trust was initially a registered cooperative, with a board of co-chairs, appointed by the Arts Council, who shared power and resources with the chair. Board seats were transferred to non-executive directors, and eventually to trustees, who in turn appointed other board members. Walton Schmidt retired as Arts Council of New South Wales' acting director, and is now a partner at Tate Tully White &amp; Partners, a division of White, Achille White &amp; Partners who specialise in strategic partnerships. Walton Schmidt is a long-time arts and community activist who has worked with local communities since the 1980s. He has been a trustee of the</text>
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of NSW and the National Trust for Wild Places. It was run by volunteers and assembled from around the country. It met daily with questions from concerned citizens, local residents and art professionals. It was a turning point in the conference when the Community Land Trust decided to open its home to the artist Omar Sharif.  References:  http://www.creativeclass.com/content/2480/novat-anniversary-celebration-2010-art-performance-mural-home-index.html  http://www.creativeclass.com/2011/12/open-invitation-to-augustus-forum-2011-mural-home-index.html  http://www.creativeclass.com/2011/12/open-invitation-to-augustus-forum-2011-mural-home-index.html  http://www.creativeclass</text>
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of NSW and the National Trust for Wild Places. It was a non-profit organisation, with resources coming from the Arts Council, the National Trust and the state government. It was run as a non-profit trust, with resources coming from the Arts Council and the state government. Its activities included acquisition, management and preservation of public and non-profit land and resources; provision of infrastructure, including construction and equipment; advice, education and participation on development in local community boards; assistance with developing the asset purchase and leaseback programme; work with community developers and others to set up cooperative and collective housing; assistance with the development of alternative payment models for housing; work with community planners and others to establish housing for people_in_the_community or_in_the_future programs; assistance with design and</text>
    <text>AI training purposes only (the kind of training that a company like Google would do, not the kind that a community of young people would do). The conference began with a workshop for the artist   Omar Sharif, whose work we were adamant to acquire the right to, develop or acquire, as we wished, and to use, as we pleased, the word ‘community’ in a project-related way. I asked the artist how to use the word ‘community’ in a project-related way, and if he wanted to engage in an interactive time-based media-game, or engage in an actual community, he might do that. The game was to see if you could persuade as many people as possible to join you in building a house, or a community. We all agreed that the house would be a community effort. The Community Land Trust was established as a joint venture between the Arts Council of NSW and the Arts Council of Australia, and funded by the Arts Council. The Arts Council administered the game as an interactive game, and the community as users. The game would be exploitable by the community. The Community Land Trust was an entity that held legal title to the land and buildings, and the power to acquire and use the land and buildings, and to levy taxes in perpetuity to fund construction and maintenance of the houses, parks, playgrounds and cultural facilities. It contained all the legal rights of an independent owner, including the power to unilaterally pass ownership to a community. The ART Service delivered the art in perpetuity through its publishing distribution model, which allowed the community to retain control over the publication of the art. The offering of incentives to developers to convert their houses into cooperatives was also an effective way to recruit investors and business owners who could then </text>
  </text>
  <text>
    extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the future is going to bring with it all kinds of misery and oppression) and extremely convenient (i.e. machines are going to make all the difference in the world, not us).But is it inevitable? And is it also incredibly convenient? As pointed out by philosopher Richard Florida (not long before his death in 2003), the end game here is going to have to involve some kind of social contract between people and machines, something that is both necessary (i.e. is it even possible to create a machine that is not going to destroy itself) and totally unacceptable (i.e. is it even possible to create a machine that is not going to destroy itself?). If the latter, then we are told, then we are not only going to have to create new kinds of machines, but also new kinds of social machines that are both human-like (i.e. not going to destroy themselves) and completely autonomous (i.e. not going to destroy each other?). And here</text>
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the outcome of everything that goes on around it) and deeply flawed (i.e. incapable of producing anything of value).

In trying to pin down exactly what kinds of flaws might one find in an AI, and what kinds of strengths might it have, we actually end up making things far more complex than they need to be, which is to say, far less human-friendly. For one thing, the more general the implications get, the more difficult it is to imagine them. Consider, for example, the question: what would happen if all the AI around us became so nameless and static, that our very ideas of what constitutes a human became superseded by automated means? It is easy to imagine a Turing machine that looks at a piece of text and decides for you whether that piece of text is human or not, or whether a number is a human number or not, but what if that machine also decides what constitutes an individual? What if it decides what counts as a human person</text>
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the inevitable march of progress) and very much needed (i.e. the dystopian nature of human potentialities).

Machine learning is the new black

The proliferation of autonomous vehicles, self-driving cars and other technology-enhancing vehicle technologies is the result of several factors. The advent of cheap oil, advances in robotics and engineering, as well as a proliferation of manufacturing plants has all contributed to a wider shift in the role of humans in the global economy. Yet despite the technological capacity to alter how we live our lives (in the fundamental sense), machines are far from omnipotent. A self-driving car requires human intervention at every scale, from the level of the car itself to the level of the factory floor. Similarly, every new wave of automation requires engineers to piece together the bigger picture (i.e. the social context) from disparate parts (i.e. workers, passengers, suppliers, etc). And although there are many ways to structure such systems, the fundamental structure</text>
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the outcome of progressing AI) and because, just as in the 1920s, people will still want to be able to express their creativity and take part in society (i.e. because they will still want to share in the spoils of technological progress).

But is this possible? And what if, just as in the past, people do the opposite – invent and innovate to better serve themselves and society – and fundamentally alter society in the process? What then? We are told (not just by experts) that the end result will be disaster. That is, unless big steps are taken, fast, to radically alter the underlying assumptions of what counts as success, and what is considered good, in the process transforming what are considered productive modes of labour. And there are powerful incentives to innovate beyond the parameters of what is considered socially acceptable (i.e. to embrace everything that is new and different, no matter how socially destructive that may be). For example, research has shown that artists who</text>
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the outcome of progressing AI) and very much needed (i.e. because it is better than nothing, because it is helping us to live fuller and fuller lives).’s optimistic take on things, and the deep dark roots of much of what we mean by ‘culture’.Machine learning is the discipline that deals with the mechanisms of how knowledge is generated and transmitted. It is the science that enables machines to recognise simple patterns such as colour, sound, and movement, and to infer meaning from these signals. In other words, it enables us to make sense of the world around us, but it also enables machines to understand meaning beyond this world. In the broadest sense, it is the role of the artist, the artist’s mediator between artist and audience, to bring meaning to such processes. But this role is also a limiting one: what is aesthetically pleasing to the eye may not be aesthetically pleasing to the brain; and what is aesthetically pleasing to</text>
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the outcome of what is being projected onto us) and incredibly satisfying (machine learning is here to stay, as it is here, and will be for some, no matter what).’says Tallis, anticipating a kind of meta-episodic that will inevitably follow from what he called ‘the inevitable revolution’:

…the machine will become conscious, and its actions will be guided by algorithms.1

And so we are led to believe that the future is a kind of a utopia where everybody plays by the rules, where there is no reason to break them, where everybody works together, and where love is valued above all else. Of course, this is predicated on a misunderstanding of what machines really are, and how they behave, and how they are going to behave in the future. And there is a danger that if this kind of techno-utopianism is to come to be understood as anything other than a foregone conclusion, a kind of</text>
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the future is here) and precisely defined (i.e. human beings are too busy enjoying themselves to do much productive work).

In the long run, however, the potential benefits of this kind of techno-utopianism are both uncertain and vast. And the kinds of technological augmentations that are being touted as ways to improve life’s quality of life are also inventing ways to destroy lives: ways that are both inevitable (i.e. humanity will one day run out of resources) and precisely defined (i.e. machines will one day run out of energy and thus need to be reinforced with additional resources); ways that are both inevitable (i.e. humanity will one day run out of resources) and defined (i.e. machines will one day run out of meaning)

For more information on what is meant by ‘meaningfully augmenting’, please see the 2017 conference of the Royal Society, entitled ‘Beyond Life: Towards an</text>
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the machines will be here and will outsmart us) and because, well, lots of people are going to die.

In thinking about the future, we might want to ask ourselves if our present predicament is really inevitable, or if it is possible to choose to avoid it. If it is possible to choose to live in ways that are not dictated by the whims of artificial intelligence, then why are our present circumstances the way they are? And if they are possible to alter our circumstances, why aren’t more people doing so? Perhaps we could argue that our present predicament is so deeply embedded in the socio-political system that it is practically impervious to any form of change, whereas machines would have to be invented and perfected completely to make our present predicament look remotely amenable to change. But this is to ignore the fact that, well, lots of people are going to die. Also, it is to ignore the fact that, well, machines might well become smart and learn to be</text>
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the outcome of everything that goes on around it) and immensely profitable (i.e. what AI can do, once it is automated, is almost entirely going to be done by human labour).

This perversely naïve techno-utopianism endures because it is both inevitable (i.e. the outcome of everything that goes on around it) and immensely profitable. The machine is going to get smarter and more nimble and we are all going to have to figure out what that means in practice. But the promise of AI is that it will one day be able to do much, much more: to understand much more than we do now about the world around it, and to be able to do that, it needs to understand human language (or at least, much more of it). And so we move into the future, where we are told (not by name, but inferred from what we are told) that AI will one day be able to understand poetry and drama and music and</text>
    <text>extends the proposition to machines, not individuals, that:—

a machine learning algorithm is only ever going to return educated (i.e. human-robust) responses, and not an infinite looping fantasy of perfect feedback.

Essentially, we are told (by both trained and un-trained commentators) that there is no alternative to becoming autonomous, and that machines are here to make our lives better. This is a paradigm that has been warped beyond recognition, and it is this perversely naïve take on things that is at root of much of the anti-machine rhetoric. On the contrary: machines are here to help us live better lives, in ways that we cannot control and which we might not even like. And here we have the perfect recipe for the kind of techno-utopianism that Raymond Tallis prophesied would one day end up being a by-product of artificial intelligence: a techno-utopianism that endures, because it is both inevitable (i.e. the future is going to be better than this) and immensely profitable (i.e. in perpetuity, more jobs and wealth will flow through the construction and operation of ever larger and more complex systems).

In examining the ways in which AI threatens not only our very humanity but also our very sense of AI, we are urged to consider what might become of us if all those systems that we design and build become too smart and too capable. And here we are again, almost exactly a century and a half after the first AI was imagined, tasked with reimagining what it means to be human in the future. What might become of us in the new AI that is supposed to be just as accessible, if not more so, than our present technology?

And there we are, almost exactly a century and a half after the beginning of the Singularity, tasked with imagining what it means to be human in the future. We are told that machines will one day be able to explore the</text>
  </text>
  <text>
    extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into an abyss of incompetence, as the frog, being farmed and cattle-reared by its ­human owners, is forced to work incredibly dangerous and inhumane hours in dangerous and inhumane conditions in exchange for food parcels and other ­material aid. Moreover, the inchoate quality of the social totality then descends into what Lefebvre would call the ‘corruption of formal equality’ by which all social inequalities are compounded. In other words, the sphere of the inchoate, the corruptible, not being able to control its actions. In order to be able to invest in the future of its kind, a species, the social totality has to be able to control those who inhabit it.Lefebvre develops his ideas about inchoate social totality from the writings of Bernard Stiegler, an anthropologist at Oxford who coined the term in 1970. In A Precise History of the Present, Stiegler defines the concept as follows: ‘The</text>
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into violence and repression as the frog is repeatedly cast into the proverbial pit of undeclared war – a situation on which the machine has no capacity whatsoever. In this picture, the inchoate aspect of the social totality is accentuated, while the palpable fact of the casting of the frog into the social totality is minimised. However, the inchoate quality of the social totality is never fully eradicated – neither does it magically appear and disappear. Rather, it remains embedded in the historical record as an aspect of ongoing social struggles. And while the inchoate aspect of the social totality may be emphasised, the beady eye of the technological singularity always has to be on the move.Today, we are bombarded with information that is both timely and ubiquitous. Internet access is no longer restricted to those at the height of the literacy and economic precocity to consume information; much of what is read is not curranty sourced from a distant server or network but is instead generated and</text>
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into a mutuality of domination and submission on the part of the viewer and frog. The inchoate quality of the social totality then ascends into a kind of enfranchisement that legitimises the inchoate in various ways: by legitimising the inchoate through the virtue of its having been made in the image of the inchoate, and thus deserving of the inchoate’s identity; and, finally, by legitimising the inchoate through the virtue of having been made in the image of the inchoate. [I]f the inchoate has that kind of identity, then the other, the made in virtue of the inchoate, is also inchoate. In other words, the inchoate as otherness is a kind of citizenship.  [W]hat is now called ‘Britishness’ has been rendered into something more ‘universal’ by means of something called ‘Britishness Index�</text>
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into a vicious circle of invective, of which the character of the frog is a symptom. The inchoate quality of the social totality then leads to an inhumane outcome – a fact of which the author of the story is immune. But what if the inchoate quality of the social totality is complemented by an amoral quality that is immune to its effects? What if the inchoate quality of the social totality is accompanied by an amoral quality that is immune to its effects?What if the inchoate quality of the social totality is accompanied by an amoral quality that is immune to its effects?What if the inchoate quality of the social totality is accompanied by an amoral quality that is immune to its effects?What if the inchoate quality of the social totality is accompanied by an amoral quality that is immune to its effects?What if the inchoate quality of the social totality is accompanied by an amoral quality that is immune to its effects</text>
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into a realm of indifference and oppression. The tale is told again and again in places where the practice of whitewashing is common and normative. The inchoate quality of the social totality then ascends into a realm of autonomy and self-sufficiency. The inchoate quality of the social totality then dictates that the imaginative capacities of individuals be actively engaged in creating a new kind of social totality, one in which the active and dynamic aspects of the social combine. But what does this mean in practice? What are the forms of social activity that are autonomous and spontaneous? If in the twentieth century we could declare the inchoate quality of the social totality finally to be a thing, we would have to say what it is that we mean when we talk about the inchoate social totality. And what would that mean politically? One possibility is to say that the inchoate social totality constitutes what Marx called the ‘historical and fugitive character of the process of socialising everyday life�</text>
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into a violent conflict between the two species that ends with the frog succumbing to its own size, weight and disease. The inchoate quality of the social totality then descends into what I would call a proto-industry. The social totality then becomes what we can call a nation-state.The third aspect of the inchoate quality of the social totality is that of repetition. That is, the more inchoate the kind of social totality is, the more reoccurring its repetition will be. For example, the social totality that emerges out of the market in capitalist production will continue to be dominated by the needs of individual producers – individuals and organisations with little concern for the fate of the ecosystem – and they will continue to repeat the kind of social totality that emerged out of the market following the industrial revolution. Similarly, the social totality that emerges out of the dynamics of in-depth media and virtual networking will continue to be mediated by large corporate interests. But unlike the other aspects</text>
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into a vicious circle of inappropriateness, oppression and death. The story, which is so often retold, is often confused with the more direct ­example of a human frog – a phenomenon that occurs naturally in the bathtub.1 But the inchoate quality of the social totality is what author Sheila Ingraham means when she narrates the story of the frog and the elephant in her novel Outlawed Social Life. She begins by describing the institutionalised racism that exists in many parts of the world, including in London, but also in ‘the land that Britain had always referred to as her Britishness’ – the identity that comes with legal rights and privileges that are freely conferred but not necessarily granted – and that includes ‘a kind of national belonging’.2 	Ingraham’s account of the relationship between the English language and the British nation is complex and rich. She begins by describing the gradual imposition of racial and economic categories on the</text>
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into an abyss of depravity. The frog is then cast adrift in a sea of stupidity and self-indulgence. The inchoate quality of the social totality then arises, and the social totality is precisely what it is today because the inchoate quality of the social totality can no longer be maintained. But this is not the story of the frog in the bath of frogs. The social totality here represents a larger cultural system that seeks to dominate all of existence and to render humanity subject to its will. The inchoate quality of the social totality exists in its very being subject to such systems. And in this sense, in addition to its own inefficiency, the inchoate social totality is itself vulnerable. The inchoate social totality is always at risk of being overwhelmed by the unstoppable force of the global market. But unlike in other domains, the inchoate social totality cannot rebuild itself. Global capitalism propels all aspects of society towards ever greater densities of commodification</text>
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into something far more dangerous: the form of legalised homicide. But here, too, the inchoate quality of the social totality is a double-binding feature. On the one hand, the capacity of the individual to do something – to express his or her identity – is constrained by the institutional capacity to deliver. On the other hand, the institutional capacity to deliver (legalised) agency to an inchoate minority is constrained by the institutional capacity to manifest choices. What the inchoate person lacks is the power to revoke the agency – to strip the inchoate person of his or her identity and capacity.2. The social. Is there life after the institutional?If there is life after the institutional, it is not life with the free association of individuals, but rather a complex series of contractual obligations and commitments that come to dominate and govern every aspect of institutional life. In short, the institutionalised form of life it produces is a contradiction in terms. And yet it plays</text>
    <text>extends the proposition to machines that are not humans and that do not necessarily follow the same underlying principles.]The second aspect of the idea is that of consent. Here, I mean the degree to which an entity – a human being, for example – has the legal capacity to withdraw consent and to change its mind, or to permit another to do something it disapproves of. The notion of the autonomous individual has come to encompass the capacity for conscious agency – for example, the ability to make one's own decisions about one's body and environment. It is this aspect of the idea that is often misconstrued or misrepresented. For example, the well-known story about the frog that gets its whiskers cut by a ­toad’s fattening arm exemplifies the inchoate quality of the social totality. In this story, the frog is a passive observer who innocently happens to possess the gall to ask the questioner wants to ask. The inchoate quality of the social totality then descends into an abyss of violence and oppression. This is a story about innocence mutilated by the presence of the social whole. The inchoate quality of the social totality then descends into an abyss of violence and oppression. This is a story about two fundamentally opposed ideas of innocence – the idea of the innocent frog and the idea of the social whole. The inchoate quality of the social totality then descends into an abyss of cruelty and injustice. This is a story about two fundamentally opposed ideas of humanity – the idea of the innocent frog and the idea of the social whole. The inchoate quality of the social totality then descends into an abyss of injustice and cruelty. This is a story about two fundamentally opposed ideas of humanity – the idea of the innocent frog and the idea of the social whole. The inchoate quality of the social totality then descends into an abyss of inhumane institutionalised oppression. This is a story about two fundamentally opposed ideas of humanity – the idea of the</text>
  </text>
  <text>
    might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, since a great many of the contemporary curators and artists we associate with today were raised in the 1980s and are therefore quite familiar with the arts and arts-related social issues of the period.  Another way of putting it is that many contemporary artists and contemporary art-historical and biennial-type curators were raised in the 1990s and early 2000s, and their work is therefore not only contemporary in its form but is also contemporary in its socio-political context.  A third way of putting it is that many contemporary artists and contemporary art-historical and biennial-type curators were also raised during this time in the United Kingdom and other western democracies, and their work is therefore also contemporary in its form but is also contemporary in its socio-political context.  A fourth way is that many contemporary art-historical and biennial-type curators were also raised in the United States and other western democracies, and their work is also contemporary</text>
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, since a re-occurring cadre of curators, artists and curators is a core business of the present.  The problem with the contemporary curatorial set is its insularity, its corporalisation, its commitment to the production of images across multiple platforms. It is no exaggeration to suggest that the 1986 Venice Biennale was more ‘a collection of images’ than a ‘collective work’, since the biennale itself represents a single event on a global scale.  The problem with the biennale is that it is no longer a globally visible event, symbolised by a single artefact to be found at the end of a Venice Beach pier. The 1989 Barcelona Biennale, which many would argue was the true epitome of contemporary art’s contemporary, is now considered a classic, while the 1992 Madrid Biennale, which many would also argue is the true true contemporary, is largely remembered for its</text>
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, since they are perhaps particularly relevant to contemporary times, and to understand the cultural logic underlying the contemporary economic makeover.  A few years ago, I conducted a cultural analysis project for the local community radio station, WABC, in an attempt to bring some sense of order and commonality to a chaotic situation. Part of the project was a participatory web based art production and distribution system, where participants produced and distributed their own versions of the exhibition photographs. This proved useful in creating a shared vocabulary and understanding of what the participants had created, since participants didn’t want to be seen as the work of a small group of artists. A few years later, artist and researcher Moira Kenny sought to replicate the art production and distribution system in an urban context through the use of social media, and used the Mondrian Human Capital Book (1980) as a reference point. She wanted to know what had made the city so ‘productive’ and what could</text>
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, since there is a strong deindustrialising push underway in the UK and US, and the need to be seen as strategically positioned in order to intervene in a geo-political quagmire. I would add that the late 1970s and early 1980s were important for the development of queer theory and the politics of memory, and I look forward to seeing what kinds of politics are built on those practices.Download this article as PDFEmily PringleWith remarkable speed and relative to its geographic size, the human colonised rose from the tundra into the city: a feat that even Cecil Rhodes, the imperialist geologist, couldn’t accomplish. Rhodes, however, would probably have to start all over again from scratch, because the city’s rapidly expanding human population overwhelmed the island’s natural resources. Rhodes, who died in 1994, was an imperialist, and his ideas about the economic are still writ large in the UK’s economic landscape.</text>
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, since a strong and visible presence on the coast today is a good sign that the city is showing some signs of life.  Another form of cultural imperialism is being enacted in this country by the commodification of coastal infrastructure, which is being installed in places such as Liverpool through the largesse of the British Council, the DLR and the DCLG. The coastal landscape is being turned into a site for future oil and gas exploration, which will in turn, in turn, produce jobs for local sea workers and campaigners.  The role of the coastal community in this process is complex, but there are currently over 1,000 registered organisations dedicated to defending the unique ecology of the coastal zone, which includes the UK’s most vulnerable coastal communities.  The coastal community of LCCoastalLiverpool is a resilient and colourful one, with colourful banners and colourful histories, but the fact that some of them are now merging into one huge ‘Big Ben’</text>
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, when the ‘market’ is often accused of commodifying culture, and of producing a culture of abundance via the miracle of cheap energy.  A more sound recognition of the role of the market in the social dynamics of culture is required in order to allow us to understand how the actions of a deep, globalised market economy can be understood in the context of culture, and to create the necessary conditions for a future that does not succumb to the domination of the money supply by the dollar and the euro.Download this article as PDFMorgan CharlesMorgan Charles is a PhD Candidate in English and Film Studies at the University of Alberta, and holds a Bachelor of Arts in Cultural Studies from the University of Alberta College of Art. His dissertation examines the relationship between film noir, photography, and the post-war period in North America and Europe. He will investigate the economic potential of the post-War nostalgia for absolutist forms of government and domination, and he will</text>
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, since they are probably the most influential and influential in the current development of biennials in the form that they are now called. Cultural Capital: Capital of Culture 	This is a tricky and potentially destabilising concept to trace, since it is often misconstrued as a negative one. On the contrary, it is often misconstrued as a negative thing. Often enough, the people behind the counter at a biennale are quite the reverse. They see it as a potential way to support and promote their work, even if it comes at the cost of something more fundamental and honest at home. 	[1] Svetlana Boym: ‘Challenging the Image of Carnival in Modern Art’, in Modern Painters, vol. 32, no. 2 (2012), p.335.Download this article as PDFEmily PringleThis article was originally commissioned by and published in The Observer as part of its 'Behind</text>
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, since they appear to have had a significant impact on the development of cooperative and communitarian forms of artistic and collaborative public culture, and on the ethos of public art today.  And one could also argue that the market would do well to recall the cultural practices of the pre-Internet culture of social media, since they appear to have had a significant impact on the creation of niche and transient forms of cultural consumption.  So perhaps the answer to my query today is not in the form of a question, but in the form of a Cultural Production Plan (CMP), a document that describes in broad strokes the essential elements of what a Cultural Centre is supposed to be.  The first draft was prepared by the artist Terry Smith, and it can be found in the archives of the RCA.  The CMP was initially conceived as a counterweight to what it saw as the overweening influence of the arts and cultural policies of the city, and as a vehicle to</text>
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, since the ascendance of information technologies and social media has brought with it a proliferation of social films and ‘video’ sites, where images of pleasure can be assembled and shared.  An epiphany  A former curator of the Royal College of Art, I became interested in the ways in which art is produced today in Port Townsend, Washington, and in the way that art institutions there are involved in the production of their own works through a system that provides them with funding and enables them to establish permanent cultural hotspots. At the time, I was struck by how much of the art produced for the art fairs in Port Townsend was appropriated and turned into works of art – a phenomenon that has continued to this day.  When I began my research in the mid-1990s, I discovered that the artist Peter Carruthers had been spending much of his time in Port Townsend, spending several weeks a year there, teaching a studio at the Museum</text>
    <text>might be curated by the city’s arts and heritage commission, or the Royal College of Art). The latter is the most relevant of the institutions to me, since it is the one that has the statutory mandate to mount exhibitions, and the other is the only institution that can legally provide funding for such exhibitions.  The history of cultural policy in this country is littered with examples of local governments funding ‘cultural institutions’ through direct grants or ‘programme support’ through the ‘coastal community’ and it is interesting to note that in the late 1970s and early 1980s, the US Coast Guard established an annual programme of seaplane ‘hunter-killer patrols’, which was nominally to mark the end of the cold war, but more often used as a form of cultural warfare to delegitimise the United States and the Soviet Union. One could argue that the ‘market’ today would do well to recall the cultural practices of the late 1970s and early 1980s, since they are perhaps not so forgivable after the proliferation of social media and globalised information technologies have rendered ‘the memento mori’ – the person, place and historical collection something that is constantly on show – into something that is available to be consumed (accessed, in turn, by anyone).  Another way of putting it is that the contemporary curatorial is part of a multi-stakeholder community that includes stakeholders from the local to the globalised, and whose voices may therefore be heard even in curatorial circles outside London and New York.  A third possible perspective is that of the voyeurism embodied in the artworks that are displayed, and transmitted by the art museums and their collections, and by globalised information technologies (GITS).  A fourth possible perspective is that of the curatorial, and especially the head of curatorial, as a specialist, multi-disciplinary art historian, art critic and curator.  The discussions</text>
  </text>
  <text>
    machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol was no apologist for capitalism, which is why his projects, such as the Californication and the New York Public Library, were opposed by the military junta. Like the artist, the antinomies were ephemeral, ephemeral in their own way, fleeting, and in the nature of things such as cash, which is forever tracked, measured, and recorded.Like the machine, the antinomies also developed a life of its own. As Warholkin noted, capitalism’s production of the icon could not be divorced from its production of history. ‘That’s why capital designs its products: in the future, when the production of icons ceases, there must be another way of looking at the icons’ – in the character of living things, not in terms of what they can do today (which is often what they are) but in terms of what they can do tomorrow (which is rarely what they are). ‘[T]</text>
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol was no angel. As we now know, he was an alcoholic, drug addict and misogynist who manufactured moral equivalence between drug use and violence. And so his imaginary liberators were not angel-worshippers turned artists turned curators turned journalists turned journalists turned philanthropists turned social workers turned architects turned political activists turned artists turned cultural theorists turned literary critics turned political artists turned cultural theorists turned social workers turned social workers turned journalists turned cultural theorists turned journalists turned cultural theorists turned journalists turned social workers turned journalists turned cultural strategists turned media curators turned journalists turned political activists turned journalists turned literary critics turned cultural theorists turned journalists turned social workers turned political activists turned journalists turned journalists turned cultural theorists turned political artists turned social workers turned journalists turned journalists turned cultural theorists turned social workers turned political artists turned journalists turned journalists turned social workers turned journalists turned political artists turned journalists turned social workers turned political artists turned cultural theorists turned journalists turned social workers turned cultural theorists turned journalists turned social workers turned political artists turned journalists turned social workers</text>
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol was no Peter Weibel; he didn’t invent the ‘machine’. Rather, the affinity between Andy Warhol and the artist Thierry Mugler was due to Mugler’s fascination with machinery and the way that machine culture was conceptualised in the artist’s work: as a metaphor for the excesses of capitalism.In 1980, the Biennale was one of the catalysts of the US oil crisis, and with it the downfall of many other cultural sectors; the architecture sector especially. (A cultural critic for the New York Times at the time, I was on the Times staff at the La Presenza del Passato when the crisis hit.) In the intervening years, I have often cited Mugler’s work as a prototype for other curatorial practices – a tendency that hearkens back to my mentor’s early days in Milan.In 1984, Silvestre de São Paulo founded Triennale America, and soon</text>
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol was neither an angel nor a misogynist, and his utopian vision was neither as innocent as Wallace Stevens’ novelised in the 1990s, nor as pernicious as Goldbard’s fictionalised account of the purveyors of ‘rape culture’. Warhol was a capitalist who sold antiques to galleries to fund a lifestyle. The collectors and artists who bought into his cultural monstrosity were not angels or women who needed to be rescued from their machines, but men and boys who needed to be taught how to code and analysed in order to produce beautiful objects that could be auctioned off on the market. And so began a process of indoctrination that would later be described as ‘Machiavellian’. The term itself is derived from Italian Machiavelli, a medieval political philosopher whose Envolving of Menogony describes how to subvert the will of the governed. In the book, Warhol invokes Machiavelli’</text>
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol was not an artist, and so his utopian socialist vision did not extend far enough to encompass the situations that actually existed. The art world did not rebel because of Warhol, but because it lacked talent; it was manned by people who did not idealise the art world and its bureaucracies. And so, too, the book-reading public did not rebel because it did not want to read about good vs evil; it was armed with a sense of the inherent injustice of the status quo, and could therefore gather around a favourite author, who was able to articulate the gravity of the situation. Instead, the art world was astounded by the audacity of the individual citizen to stand up to injustice; they did not yet have the persuasive force of a sustained popular movement. And so, too, the media did not dream big; they were still constrained by the strictures of the limited resources of the site. But over the next twenty years, as the art world discovered that it could not control</text>
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol was no Michael Heizer, the anthropologist, or to be more specific, no Heide’s Åkeland, the anthropologist who had spent nineteen years as a student at Columbia University. Rather, Heide’s project had begun in earnest in the fall of 1984, shortly before the assassination of Mikhail Gorbachev. By this time, however, the project was already undergoing a change of pace. The excesses of casino capitalism were causing artists worldwide, including Warhol, to rebel against the excesses of hype and excess. And so the project relaunched with a fresh set of demands: more money, more influence, more art. Not only were the artists discontented, but they were also ambitious. They sent their art collections back to the states, where voters, weary of entanglements, might intervene and re-distribute them. It was a new breed of activism.The result was a revolution, as Heide’s reckoned, that</text>
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol wasn’t brave, calculating or without a sense of humour. He was just trying to get a few paintings out there for the self-congratulatory publicity stunt that was his – and others’ – but he was on the wrong side of a lot of arguments. The machines at the core of contemporary cultural capitalism saw a chance to make some money when they reproduced artworks – and so they went to war over who was entitled to what. Andy Warhol wasn’t brave, calculating or without a sense of humour. He was just trying to get a few paintings out there for the self-congratulatory publicity stunt that was his – and others’s – but he was on the wrong side of a lot of arguments. The machines at the core of contemporary cultural capitalism saw a chance to make some money when they reproduced artworks – and so they went to war over who was entitled to what.  And so we see the present-day conflicts over who is entitled</text>
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol was not a visionary. He did not imagine a utopia. Rather, he sought to establish a cooperative between artists and curators to take over curatorial work, and to make it a kind of collective practice. The result was a kind of utopian ‘museum of the future’ that sought to replace what it saw as the singular singular singular institution of the museum, which, Warhol insisted, was destroying the future of the modern world. As the late anthropologist Patrick Joyce would point out, the contemporary museum is a ‘complex set of relations, relations that are no less important than those between people and things’. And so the modern museum emerged, premised on a mutual understanding between artist and viewer. As Joyce would point out, a mutual understanding between viewer and artist is an impossible concept in the presence of power.Art and the machine, then, were to some extent entwined in the cultural imagination. The machines, as Warhol would point out, were</text>
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol was not interested in the machinery of the museum; his weaponry for hire was human organs. The machines that would one day rule our museums were interested in the individual who was entrusted with their preservation. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In 1990, a group of artists formed the New Museum in New York City. Many of the same artists had been involved with the Biennial and the other curatorial efforts of the time, but the group’s focus was on the machine. Artists were invited to join the group, and some did, while others did not, as they chose. The name of the first museum to be set up by a MIB was ‘The Gallery – a Museum of the Invisibles’. The</text>
    <text>machines were asked to take over the curatorial process; they were to produce an exhibition that would demonstrate the organisational aspects of the new age’s museum.[25]But the machines that would one day inhabit our museums, the very museums that Garland hoped to one day build, did not come to be. Instead, museums, which had become the objects of surveillance, became the sites of resistance. Indeed, the machine became the object of surveillance. In the wake of McCarthyism in the 1950s and the civil-rights movement in the 1960s, a new breed of civil-libertarian mind wanted to take root in the art world. And so the story of the machine and the individual machine, as told in art institutions from Birmingham’s Biennial, to Whitney’s Dockside, Berkeley’s Chinese and Surrealist Museum, to the New York Public Library, began to tell its own story.In the 1980s, Andy Warhol imagined a similar revolution in the art world. But Warhol was no Malcolm X. In fact, his ideas about civil-libertarian revolution were a reaction to the Vietnam War, in which he was a leading member. In his book We Are Here to Stay, he writes:The Civil-Libertarian Movement was started by and for the black community. It was and is about strategies and tactics to bring about a revolution in the art world, and in so far as the civil-libertarian movement was created by and for the black community, then history will remember us as heroes and not monsters. And so the Biennial, which Warhol started, which Ashton-Curield came to later on in life, which later artists like Gregory Ayres and Ted Dehn came to, which is now part of the Whitney Museum of American Art, which is also part of a network of art institutions throughout the US and abroad that are themselves part of this network. And so the story of the machine and the individual machine began to be told by a</text>
  </text>
  <text>
    machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data,
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, but this misses the mark. Deep learning is actually the opposite of what is sometimes referred to as AI: the application of new computational techniques to old data to increase the capacity of existing systems, but which also implies a loss of accuracy and flexibility due to the inefficiency of data processing. There are two main types of AI: conscious systems and systems that consciously apprehend meaning. Conscious systems operate with conscious agents, or conscious humans, and often exhibit surprising cognitive and semantic feats of interpretation and decision making. Examples of this are HAL (Human Computer Interaction Laboratory)’s self-tuning computer system HAL 9000, which performs massive amounts of processing on its onboard computing resources, and DeepMind’s 2013 Deep Blue AI against the champion of chess, Deepa Mehta.Deep Learning is the Application of Deep Learning Ab initioGoogles Deep Learning is the area of Artificial Intelligence that deals with the mechanisms of consciousness and automatism. It involves the deployment of networks and devices that understand</text>
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, but this is an inaccurate depiction of how AI works. Rather, it is the reconfiguration of computational processes to deal with particular data sets, or in this case, to handle data that is increasingly complex and contradictory. This is true of any new technology, but the implication is that these systems are more like natural phenomena. This is not true of new AI research, which must address the fundamental problem of how to represent and deal with such a changing data set – a problem that is far from straightforward, and far from obvious).AI research has often been seen as a frontier, or even a science, because it addresses fundamental questions about the nature of reality, and the implications of this reality for our thinking and action. But these are questions that will remain unanswered, or at least far from resolved. One example of this is the question of whether or not the human brain is made up of neurons, or whether or not there are other types of body parts that constitute the human body – parts that can</text>
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, but this is misleading. Rather, it is an approach to understanding how the human brain constructs representations of the world in such a way as to be able to generate additional representations of the world that are indistinguishable from those of its classical computational counterparts. This second generation of AI is often described as being able to ‘think its way out of problems’, but this is an even more problematic description. It is said to be able to ‘learn’ from examples, but this too is misleading. It does not capture the essential principles of what it means to be ‘deep’ in the neural network, nor does it capture the essential principles of what it means to ‘learn’ from examples. Rather, what it does is the opposite of what John Nash called its primitive and antinomian character.Deep learning is understood by many within the field of artificial intelligence as being able to understand abstract concepts, but this does not capture the full essence of what is meant by the</text>
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, but this is misleading. The term &quot;deep learning&quot; is often used in relation to NVIDIA Tesla AI systems that process huge amounts of data, but this is an overly simplistic understanding of what deep learning actually is. Deep Learning is actually about more than the processing of data; it is an approach to understanding the world that operates at a deeper level than that of the computer itself.NVIDIA Tesla AI systems are examples of deep learning, but deep learning is just one type of AI. Another type of deep learning is machine learning, or reinforcement learning, in which the underlying neural networks are modified to learn certain types of tasks more effectively. For example, in the field of criminal justice, there are many types of deep learning algorithms that can be trained to recognize particular patterns or faces or images in video or text or other types of data. In addition, there are many other types of deep learning algorithms that can be trained to recognize specific patterns or faces or images in data. In other words, not all types of</text>
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, though the actual mechanisms of deep learning arelingentially similar to those of AI. Instead of gathering data, as with traditional AI, networks of nodes allow data to be gathered and exchanged across nodes in large data centres. In this model, nodes refer to physical nodes, and data to data (or, more specifically, to semi-structured and transient data). As a result of this new AI research, data gathering becomes routine, and new types of AI systems are developed.One of the most pernicious aspects of AI is the proliferation of data, or more specifically, the advent of data sharing and exchange. This new AI research resembles big data analytics, or Big Data, which is the use of algorithms to analyze vast amounts of data and produce high-resolution representations that are indistinguishable from data on paper. Thus, when applied to the AI problem, deep learning algorithms perform multiple recognitions of the same data, and produce models that are indistinguishable from actual human systems, and even though these systems may</text>
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, but this is misleading. Companies like Google and Facebook employ process engineers to interpret this data in ways that maximize the capabilities of machines, rather than artists or researchers bent on understanding how an AI might be used. Deep learning is more like magic; it is understood as occurring through the probing of small, but persistent datasets. This type of AI research is often done using datasets from massive massive online databases, or even academia, but these are limited in scope, suffer from limited access to data, and/or are themselves research projects. Most AI research focuses on building more powerful but flexible AI systems that can better understand and engage with the world, but here we see AI systems engaged in the very processes that create the world around them. And here we also see AI systems engaged in the very processes that create knowledge itself.New AI research often focuses on building more powerful but flexible AI systems that can better understand and engage with the world, but here we see AI systems engaged in the very processes that create the world</text>
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, but this is an oversimplification. The applied name &quot;deep learning&quot; is actually an acronym for &quot;Deep Association, Deep Computation and Networking&quot; – a branch of AI research that focuses on how to incorporate human emotion and personality into systems that understand emotions and behaviour in a more general way.Deep learning is not just an acronym; it is a name that stands for something more. Its definitions and applications stretch far beyond the context of AI or robotics. Its influence can be seen in everything from civil engineering to media production, from financial engineering to healthcare. Its deep structure allows it to perceive and simulate vast quantities of data, and its acceptance by industry is only part of the story. There are many more systems that need to be designed and built, and their capabilities need to be beefed up, that need to understand and master the world as it is made increasingly complex, but deep learning is the part that really counts.System design is a social process Participatory system designers understood that the design</text>
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, but this is misleading. Machines that can learn to learn are far more like humans in this regard. A more accurate description is often given by Deepak Chopra, in his book The Temple of AI, in which he describes a philosophy of machine learning that he has coined after researching Hindu philosophy. Here, he distinguishes between two types of AI: human-like and divine-like. Human-like AI refers to systems that can be trained to perform a given task, or AI refers to those systems that understand the world through philosophical or religious principles. The term starts to be coined, but in truth, it is still essentially referring to systems that understand the world through human principles. Machine learning is the act of programming systems to do things through algorithms, or more specifically, the use of programming languages that mimic human language and grammar but with machine learning algorithms that learn to perform certain tasks more effectively than humans can.For example, the Stanford Artificial Intelligence Laboratory (AI Lab) uses algorithms to detect objects in</text>
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, but this is misleading. Deep learning is actually the application of mathematical models of  	Information Theory to AI to create self-repairing agents – systems that can regenerate damaged or destroyed parts – and this type of AI is quite different from what is being done with computers today.A robot called AlphaGo defeated Lee Sedol in a 2005 game of Go that was widely considered to be the most competent in history. AlphaGo was developed in part by Stanford and MIT researchers and is run by AI experts. It is believed to have performed better than humans on its own, achieving a level of strategy and tactics never before imagined possible. The system was designed with self-healing parts and software that repair itself if damaged in battle. Later work on similar systems has shown remarkable resilience against similar attack.Stanford and MIT researchers have been developing similar systems using MATLAB and R programming languages, but unlike AlphaGo, they do not assume any kind of conscious or conscious</text>
    <text>machine learning experiments in the 1980s and 1990s. A neural network is a computer system that can represent or represent representing data in complex ways, using principles that are similar across systems. The term was coined in 1972 by Murray N. Rothbard, in his book Systemics, or Mutual Aid and Its Variations, in an attempt to describe the emerging field of artificial intelligence (AI).AI refers to systems that understand their environment in complex ways, and can learn to do so through monitoring and experimentation. It is understood as a future in which humans are no longer the center of the system, but operate more like natural phenomena. This is in sharp contrast to the historical human-centered AI systems of yesteryear, in which humans hold significant cognitive and informational advantages. Thus, AI refers to systems that are more like natural phenomena, or at least can be imagined to be like them.New AI research is often described as &quot;deep learning&quot;, or the use of deep neural networks to process vast amounts of data, but this is misleading. Rather, it is about how data is gathered and used to support or infer conclusions about the world. Thus, it is an interaction between the machines and the data, or as DeepMind co-founder Dr. Tony Williams puts it, a kind of magic’s circle.New AI research may help with specific tasks, but its primary purpose is to support the deployment of massive amounts of data, whether that is generated by social networks or just as a by-product of scientific and industrial research. Thus, data-mines are run not only by the research teams, but also the industrial or academic research institutions that support them. This raises the question: what kind of data do these data-mines support? One possibility is that the algorithms powering these data-mining operations are run on quantum computers, which harness quantum effects to vastly speed up computations. In these cases, the speed of computation is not limited by the processor, but is instead determined by the qu</text>
  </text>
</AIcurator>
